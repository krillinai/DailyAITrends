## 资料合集

|序号|名称|描述|
|---|---|---|
|1|[科大讯飞AI大学堂](https://www.aidaxue.com/)|AI大学堂是科大讯飞打造的AI在线学习平台，为各行业各领域的技术人才提供人工智能培训,人工智能学习,编程入门自学,计算机编程入门,Python数据分析等课程，旨在为AI领域开发者、爱好者提供专业的课程、资源及服务支持|
|2|[ShowMeAI知识社区](https://www.showmeai.tech/)|ShowMeAI是人工智能领域的资料库和学习社区，覆盖Python、数据科学、机器学习、深度学习、自然语言处理、计算机视觉等方向。我们为学习、求职、项目落地、业务探索等场景，提供了结构化路径和全套资料库。构建AI解决方案，用知识加速每一次技术成长！ShowMeAI，只做精品。|
|3|[动手学深度学习](https://zh.d2l.ai/)|面向中文读者的能运行、可讨论的深度学习教科书。含 PyTorch、NumPy/MXNet、TensorFlow 和 PaddlePaddle 实现。被全球 70 多个国家 500 多所大学用于教学|
|4|[阿里云AI学习路线](https://developer.aliyun.com/learning/roadmap/ai)|阿里云出品，人工智能学习路线，算法原理、框架精讲、机器学习实战、图像识别实战、自然语言处理实战，人工智能技术一站式学习|
|5|[百度飞桨AI Studio](https://aistudio.baidu.com/learn/center)|飞桨星河社区是面向AI学习者的人工智能学习与实训社区。飞桨星河社区集成了丰富的免费AI课程，大模型社区及模型应用，深度学习样例项目，各领域经典数据集，云端超强GPU算力及存储资源，更有新手练习赛、精英算法大赛等你参与。|
|6|[英伟达深度学习培训中心](https://www.nvidia.cn/training/)|NVIDIA 深度学习培训中心 (DLI) 提供 AI 、加速计算和加速数据科学的应用开发实战培训。基于完全配置的云端实验环境，开发者、数据科学家、研究人员和院校师生可以快速获取端到端应用开发经验和提升专业技能。IT 专业人员可以学习设计和管理基础架构，支持企业的 AI、数据科学和高性能计算 (HPC) 工作负载。 同时获得全球通行的 NVIDIA DLI 培训证书，为您的能力和职业发展提供有力证明。|
|7|[微软面向初学者的生成式人工智能课程](https://microsoft.github.io/generative-ai-for-beginners/#/translations/cn/)|通过微软云技术布道师团队提供的十二章系列课程，了解构建生成式 AI 应用程序的基础知识。 每章都涵盖了生成式人工智能原理和应用程序开发的一个关键方面。 在整个系列课程中，我们将建立我们自己的生成式人工智能初创公司，以便您可以了解如何实现您的想法。|
|8|[fast.ai](https://www.fast.ai/)|深度学习正在改变世界。我们正通过以下方式使深度学习更易于使用，并让来自各种背景的更多人参与进来：为程序员提供的免费课程、软件库、前沿研究以及社区建设。|
|9|[Elements of AI](https://www.elementsofai.com/)|Elements of AI 是由MinnaLearn和赫尔辛基大学共同创建的一系列免费在线课程。我们旨在鼓励尽可能广泛的人群来学习什么是人工智能，人工智能能够（以及不能）做些什么，以及如何开始创建人工智能方法。这些课程将理论与实践练习相结合，并且可以根据个人节奏完成。|
|10|[MachineLearningMastery](https://machinelearningmastery.com/start-here/)|需要帮助开始实践机器学习吗？这些正是您一直在寻找的分步指南！|
|11|[Kaggle](https://www.kaggle.com/)|Kaggle是全球最大的数据科学社区，拥有强大的工具和资源，助您实现数据科学目标。|
|12|[Beginner: Introduction to Generative AI Learning Path](https://www.cloudskillsboost.google/paths/118)|本学习路径提供了生成式人工智能概念的概览，内容覆盖大型语言模型的基础知识到负责任的AI原则。|
|13|[101.school](https://101.school/courses/prompt-engineering-and-chatgpt)|人工智能（AI）已成为我们日常生活中不可或缺的一部分，它影响着从医疗保健到金融、从娱乐到交通等多个行业。本文旨在全面阐述人工智能及其在这一迷人领域中ChatGPT所扮演的角色。|
|14|[Udacity City Academy](https://www.udacity.com/school/artificial-intelligence)|人工智能（AI）是我们这个时代最具变革性和增长最快的技术之一。我们的人工智能学院提供了人工智能培训和机器学习课程，以及专注于深度学习、计算机视觉、自然语言处理和AI产品管理的项目。|
|15|[Experience AI](https://experience-ai.org/en/)|"Experience AI"是一个教育项目，专为11至14岁的师生提供关于人工智能和机器学习的尖端资源。该项目由Raspberry Pi基金会与Google DeepMind合作开发，旨在助力教师掌握AI这一激动人心且发展迅速的领域知识，同时激发年轻人对该学科的热情。|
|16|[神经网络入门（Introduction to Neural Networks）](https://brilliant.org/courses/intro-neural-networks/)|深入探索神经网络的内部机制，揭示这些灵活学习工具的实际工作原理。|
|17|[Coursera Best of Machine Learning & AI](https://www.coursera.org/collections/best-machine-learning-ai)|我们为您精心挑选了这个课程集合，旨在满足任何对机器学习和人工智能（AI）感兴趣的学习者的需求。无论您是这两个领域的初学者，还是希望进一步提升自己的知识水平，Coursera都能提供符合您学习目标的课程。通过本课程集合，您可以掌握机器学习的基础与高级技能，同时学习诸如Python、Google Cloud Platform、TensorFlow等实用工具和应用。您将了解到文本挖掘、自然语言处理、深度学习、神经网络、聚类和分类等热门话题，您可以将这些知识应用于数据科学家、机器学习工程师、软件工程师的日常工作中，解决实际问题，或帮助学生顺利过渡到这些领域。|
|18|[人工智能风云录之图灵开天香农辟地](https://www.xiaoyuzhoufm.com/episode/63f74a9c79d1c9aec859dfce)|坦白说，作为刘飞的主业，这个大的选题筹备很久，一直没有找到机会来聊。这次顺着大家对 AI 的兴趣，不妨就先从小选题「人工智能」入手，跟各位开启一段波澜壮阔的互联网、计算机和信息时代的历史长河的旅行。人工智能是科幻故事里老生常谈的话题，也是科学家们从计算机创造的伊始就讨论的问题，实际上，人工智能和计算机在早期就是一个领域。如今 ChatGPT 的体验已经与几十年前的机器不可同日而语，这过程中到底发生了什么？人工智能的过往有哪些伟大的科学家和企业家？为什么说图灵是人工智能之父？又为什么说香农也与人工智能有不可切割的关系？本期我们就先追溯到一切的开始，由图灵和香农他们打造的人工智能、计算机和信息领域的理论基础。它们成为了无数科学家和能人志士探索的终极目的。同时，这些理论在半个世纪时间里开花结果，成为了我们在使用的电脑、手机和 5G 通讯。|
|19|[从ChatGPT聊大厂竞争观：没有你，对我很重要](https://www.xiaoyuzhoufm.com/episode/6406f3d3752598c2b6a18e7a)|本期嘉宾分享：第一眼看到ChatGPT的感觉；属于技术的创业者自己的时代又来了吗？为什么中国互联网没有在类似ChatGPT赛道上有这么大投入？国内的过度竞争：你和钱对我都不重要，没有你，对我很重要。ChatGPT对于游戏体验有什么提升？对于字节跳动，AIGC可能会替换推荐引擎吗？ChatGPT会取代媒体人这个行业吗？|
|20|[大白话聊ChatGPT](https://www.xiaoyuzhoufm.com/episode/641183b5bb1fc0cb68f810c6)|这次建硕和我聊的是一个充满未知和想象力的话题——ChatGPT。就在今天凌晨（2023/3/15），OpenAI 发布了多模态预训练大模型 GPT-4，它比之前的产品更加可靠、更有创意，能处理更细微的指令。在本期节目中，建硕科普了 ChatGPT 的定义和原理，澄清了关于它的常见误解，并从创业者的角度出发畅谈了 ChatGPT 的应用前景和创业机会。最后，我们还探讨了与 AI 相关的隐忧。|
|21|[跟傅盛和王俊煜聊：大模型、产品经理和热门AI应用](https://www.xiaoyuzhoufm.com/episode/64199cbe73768bea3509176a)|本期嘉宾分享：CPT-4与GPT-3.5使用感受与对比；GPT4与机器人的结合，未来可期；Notion AI：个人数据+GPT→个人助理？GPT发展太快，人类的数据将很快不够用了，怎么办？怎么看待New Bing把ChatGPT用到搜索里边？使用体验如何？Speak + OpenAI，可能会对教育行有什么影响？产品经理的春天来了还是冬天来了？OpenAI助力Descript影音剪辑；「助理」不再只是专门给老板配的了，每个人都要有！Mem与Notion，轻笔记与知识管理；产品经理在下一个时代会是什么样？巨头的淘汰赛开始了：在OpenAI和微软的联盟面前，所有巨头众生平等的落后了！|
|22|[投资人视角下的大模型和市场真实水温 ｜和梦秋聊ChatGPT](https://www.xiaoyuzhoufm.com/episode/6430e7c89361a4e7c3f586f0)|上次聊天是去年5月，刚好是北京疫情封锁正严的时候。这次是和她的catch-up。我们聊了今年一级市场投融资风向，也聊了聊目前正极速狂飙的ChatGPT、AI、大模型。她对这个话题有一定话语权。熟悉梦秋的人知道，她是清流资本创始合伙人，转型投资人以前是百度技术VP。我们重点聊了聊，大模型会带来新一轮巨头革命和格局重置吗？一级市场投资人如何看这轮AI创业？以及，市场的真实水温。你可以从这里听到，关于ChatGPT，来自投资人和前技术高管的视角。她说，我们进入了每天醒来如果AI没有新东西，都会隐约喘口气的时代。但与此同时，截至目前投资人们的投资标的其实没那么多。这中间的gap从何而来？|
|23|[AI大神贾扬清离职阿里后首次受访：创业为什么不做大模型 ｜硅谷徐老师](https://www.xiaoyuzhoufm.com/episode/6435422f6341155b5195ade3)|当下火热的大模型创业，与贾扬清无关。刚从阿里正式离职创业的，全球最有影响力的 AI 科学家之一贾扬清，吸引了无数媒体报道。从Facebook (现 Meta) 到阿里巴巴，贾扬清和他的团队已经做出了多个口碑产品，从 Caffe、PyTorch、TensorFlow，到阿里云大数据和 AI Paas 产品。在官宣离开阿里之后，贾扬清的去向也一度引起热议。在不少媒体报道中，他是因为时下大模型的热潮而选择创业。但贾扬清本人在本期节目中正式回应，ChatGPT 并非是推动自己创业的主要原因。如果做大模型不是创业的主要动力，那么什么才是呢? 本期节目，硅谷大佬系列节目再度启动，硅谷徐老师邀请他的好友在离职阿里后第二天进行一场及时而真诚的对话。AI框架大神贾扬清在第一时间分享了他关于这几年来关于职场成长、平衡技术和客户需求、离职阿里的动力、以及如今创业方向的深度思考。|
|24|[要做中国Open AI？李志飞劝各位同仁冷静点](https://www.xiaoyuzhoufm.com/episode/643c2af19361a4e7c3b4d2f8)|中国大模型经历了短暂沸腾后，一部分人骤然冷静下来。在过去1个月，行业已悄然分化。前Google科学家、出门问问创始人兼CEO李志飞就是其中之一。1个月前，他率先声称要做「中国OpenAI」，但现在，他却说：「中国是不是存在一个跟OpenAI一样的这种组织？我觉得大概率不存在。」他还希望劝大部分人不要去做大模型，包括大佬们。我很好奇，这中间到底发生了什么？为什么他的想法变化这么大？据我了解，他的变化不是这波大模型创业者的孤例。|
|25|[对话王小川：通用人工智能是一次文艺复兴](https://www.xiaoyuzhoufm.com/episode/6442527cfbc05629d3a0ac77)|曾经的清华计算机系天才少年王小川，在一年半前卸任搜狗CEO后，一直在生命科学的领域进行探索。但随着OpenAI发布ChatGPT、GPT-4后引领的这一波人工智能大语言模型的热潮，王小川按捺不住心中并未熄灭的火焰，前不久高调宣布带队成立新公司百川智能，即便引起了一些业内和外界的争议，也打定主意躬身入局。本期节目，「商业WHY酱」主播杨轩在王小川宣布创业后与他进行了一次对话。在这次对话中，王小川不吝分享了他对大模型的看法，对人工智能行业的观察，对创业方法论的研究，甚至对人类和人工智能关系的终极命题的思考。|
|26|[AI大爆发：OpenAI极早期历史，以及图像领域的GPT moment](https://www.xiaoyuzhoufm.com/episode/64486f68baaef727ec431ff3)|对于创业公司而言，前十个人员工最为重要，它会塑造一家公司的基因与文化。我们也想知道，除了信念，到底有没有一些实验上的数据反馈与方法，让OpenAI早期愿意坚定去堆算力。这期节目很幸运，我们找到了OpenAI的第一个实习生，他见证了OpenAI极早期的时刻。这期音频聊了聊OpenAI极早期的一小段历史，我们的同名视频节目《硅谷101》，也做了一个45分钟的视频，以讲故事的方法去梳理盘点OpenAI的整个成长历程，欢迎对后面的故事感兴趣的同学去关注。另外，在我们采访前，一篇叫做Segment Anything的论文又让沸腾了，我们这期嘉宾将之称为图像识别领域的“GPT- moment”。本期，我们也将解读这篇论文为什么如此有价值以及会如何改变无人驾驶与机器人行业。正如嘉宾所说，人工智能正在几何爆炸式发展，比前两场工业革命大很多，今天我们在播客里提到的难以解决的问题，可能明天就解决了。|
|27|[AI技术爆发的背后：安全、伦理与责任 ｜ 对话青年AI研究员符尧](https://www.xiaoyuzhoufm.com/episode/645b3fae94d78eb3f79a09af)|最近6个月，以ChatGPT为代表的生成式AI技术出现了「寒武纪大爆发」。每天我们都能看到生成式AI涌现出新能力、新场景、新应用。作为一直研究和从事科技创新的创业者和投资人，我既感到非常兴奋，又和很多同行一样产生深深的担忧。当一种新技术被创造出来的时候，其实被同时创造的还有相应的责任，但这种责任往往需要很长时间才会被人类所发现。历史教训告诉我们，在新技术造成大问题之前，人类世界往往是来不及去全面考虑新技术背后的责任的。这期播客录制于2023年4月，我邀请了很活跃的青年AI学者符尧交流关于AI安全和对齐（Alignment）的一系列话题。在本期播客里，你将听到我们讨论什么是 AI alignment？目前主流的研究和进展是什么？大语言模型的能力不断增强，AI 的能力边界在哪里？面对动态变化的价值观，怎么 align AI？针对AI safety的研究有什么大框架？AI 是否具有意识？大模型方面中美的差距在哪里?|
|28|[从20分迅速追到50分，国产大模型难在哪儿](https://www.xiaoyuzhoufm.com/episode/645996a7d0583dd168b99e7f)|4月是大模型频频迭代的一个月，也是中国大模型的集中发布期。这些模型更新迭代之后到底进化在哪儿，可能深度使用者最有发言权。本期嘉宾和他的团队也在过往的使用体验中，结合一些学术论文研究出了一套给大模型打分的标准——如果不是一个专业的技术人员，普通人也可以通过一些好玩的测试题目，区分国产大模型与GPT4到底有哪些不同。随着越来越多的大公司与创业公司加入到国产大模型的竞争中，本期节目我们也聊了聊，除了芯片困境，国产大模型到底怎么样，以及难在哪儿？|
|29|[特别放送：一个AI创业者的反思，观察和预测](https://www.xiaoyuzhoufm.com/episode/648ffa1886eb9d7e47b43fd0)|本期内容是「此话当真」的特别放送节目，内容截取自一次真格内部的闭门会议，我们邀请到了 Magi 创始人、真格基金 EIR 季逸超 Peak 和我们分享他作为 AI 创业者针对最近 AI 浪潮的反思、观察和预测。|
|30|[AI时代，增长黑客再开一局怎么玩？](https://www.xiaoyuzhoufm.com/episode/6490285b86eb9d7e47b88f1c)|本期节目是我在百姓 AI 和得到高研院联合举办的线下沙龙中，做的一场将近一个小时的分享。我聊了聊这两年创业经验给我的启发和失败复盘，并且分享了我为什么想在现在 AI 技术浪潮早期，重启「增长黑客」这个 IP。我还分享了这段时间，通过内部实践、项目合作与访谈，收集到的 AI 落地的真实案例和幕后洞察。希望对你有帮助。|
|31|[对话王建硕：不务虚不妄想，这次彻底聊透AI商业化落地思考](https://www.xiaoyuzhoufm.com/episode/64991979a5b2b405c6b8c579)|本期对谈嘉宾，请到了王建硕老师。他是 百姓AI 创始人、董事长，同时也是著名的 IT 评论者和专栏作家。我们分享了创业者在今年 AI 热潮爆发后的兴奋、工作/生活状态变化，交流了围绕这轮新技术趋势，看到的全新商业落地机会，披露了百姓 AI 刚启动内测的新产品 —— Chato 的开发内幕、商业定位、市场打法、定价策略、前景预期，并且还面向所有听众开放了若干个 AI 相关的工作岗位。|
|32|[对话真格基金戴雨森：有关创业、投资与AI的详细指南](https://www.xiaoyuzhoufm.com/episode/64a77e5cf4ccb12e0b43dfa8)|在本期节目中，我们邀请到了真格基金两位投资人，谢岩Monica和戴雨森，进行了一场深度对话。他们从Yusen的创业历程开始，探讨了现在创业与十五年前的差异，以及Yusen作为投资人判断创业者的标准。当然，他们也为希望参与正在发生的AI革命的创业者提供了许多实用的建议。|
|33|[对话梁建章：AI时代的旅游业，教育，人口经济与创新](https://www.xiaoyuzhoufm.com/episode/64a361f954c90a5bfb23ac4f)|6月30日，携程宣布每生一个娃，补贴5万元的新闻登上了当天热搜第一。正巧，我们在携程公布这个政策的前几天采访了携程集团联合创始人、董事局主席梁建章，他同时也是一位人口经济学家。这期播客，我们与梁建章聊一聊他是如何看待这次的AI浪潮，以及他如何看待长寿与永生、创造与传承。|
|34|[xAI vs OpenAI背后，揭开马斯克和Altman竞逐硅谷「顶流」的隐秘战争](https://www.xiaoyuzhoufm.com/episode/64b6842a316872a7a5cdda1f)|上周，马斯克对标 OpenAI 的新公司 xAI 终于浮出水面。公司愿景是让 AI 产生好奇心，并且解答宇宙的究极问题。马斯克在 Twitter Spaces 语音发布会上直言 OpenAI 的研究方式「危险」，并且已经被大公司所控制。出于对谷歌、FB 垄断 AI 科研的恐惧，由当时的 YC 掌门人奥特曼（Sam Altman）攒局、马斯克等人出资，OpenAI 得以成立。然而没过多久，马斯克就在内斗中离开。这次出走，也导致他错过了 OpenAI 改制后的成长，特别是今年 ChatGPT 带来的辉煌。马斯克和奥特曼缘何分道扬镳、反目成仇？马斯克为什么一边号召 OpenAI 停止研究，一边自己就开了一家 AI 公司？xAI 到底要做什么？在这期节目里，你将听到前硅谷记者讲述 OpenAI 史上不为人知的 AI 权力斗争。|
|35|[投AI最猛的人｜对谈绿洲资本合伙人张津剑](https://www.xiaoyuzhoufm.com/episode/64c542a399e1e7669e56d4da)|本期嘉宾张津剑是目前年轻一代 VC 里最有代表性的合伙人，他的绿洲资本是过去几年里少数募资到数亿美元的新基金，也是这波 AI 投资中出手最积极的机构，超过十家的 AI 企业投资数量在市场中绝对是数一数二。此外，津剑也是我多年的好友，他在 42章经 发表的《投资中的信号与噪声》系列文章也是脍炙人口、广为流传。在这期播客中，我和津剑聊了过去几年的投资市场、聊了最近的 AI 热潮以及对未来 AI 市场的看法、也讲了很多关于「生命力」的故事。其中，有人说听到生命力的部分感同身受被感动哭，这个我很理解。但竟然还有人说，被巨大的信息量和对未来 AI 世界的憧憬听哭了...我想，这大概就是我们播客的定位和价值吧，巨大的信息量、缜密的逻辑、给人启发的观点、以及带有人文关怀的对这个世界的解构和对未来的推演，好听到哭...|
|36|[对话贾扬清：大模型的开源之战与应用时代](https://www.xiaoyuzhoufm.com/episode/64c84d28c466508c7114aaf9)|7月19日，Meta发布了免费可商用版的开源大模型Llama2。这次的Llama2除了性能得到了极大的提升外，Meta还开源了它的预训练数据，使得企业能够以更低廉的价格和简便的方式开发自己的大模型。图灵奖获得者 Yann LeCun在推特上表示Meta 此举可能将改变大模型行业的竞争格局。本期播客我们邀请到了Lepton.ai 的创始人贾扬清，一同来聊聊Llama2开源后对行业的影响、GPT-4的泄密，以及他为什么更看好应用的创业方向。|
|37|[全英文对话Gamma联合创始人Grant Lee：AI如何改变视觉表达，生产力工具产品从-1到0的AI变革](https://www.xiaoyuzhoufm.com/episode/64e44be9e490c5dee520b7d5)|两位主理人 Monica 与高宁近期在硅谷与 Grant 展开了一次对话， Grant 站在创业者视角为大家带来了新的思考与增量经验。|
|38|[Open AI大会杀死了开发者？硅谷徐老师访谈4位现场活动参加人](https://www.xiaoyuzhoufm.com/episode/6553fccfc9e7cfe025a6e1e9)|11 月 6 日晚，OpenAI 在美国旧金山举行的首届开发者大会 DevDay 毫无疑问是本年度最重要的科技大会之一。然而，随着 GPT-4 Turbo、Assistant API、全新的多模态能力、GPT Store 等最新技术的发布，这究竟是为 OpenAI 的开发者带来更多机遇，还是断绝了他们的生路呢？此次大会是否真的消灭了一大批初创企业，甚至影响了全球知名孵化器 YC 在 2023 年的所有项目？硅谷徐老师在这期节目中，将会与四位参加开发者大会的业内人士进行访谈，其中包括两位 OpenAI 生态圈内的创业者岳天溦和 Kaicheng Zhou、棕榈资本创始人李厚明、阿里国际站买家 AI 产品负责人 Sharon。大家首先分享了参加完大会后的感受和思考，现场的花絮，以及与其他优秀的 AI 从业者交流的体验。随后，徐老师和四位嘉宾一起探讨了以下内容：OpenAI 员工对于通用人工智能 AGI 的理想主义，OpenAI 大会中采用的苹果式营销方式，OpenAI 如何促成技术平权及其可能带来的深远影响，以及关键技术背后存在的挑战和看点。通过这次访谈，我们期望能够更清晰地了解生成式人工智能行业的发展动向。|
|39|[GPT并非替代你，而是破除内卷加速创造：调研37位程序员后，我不再焦虑 with 科技乱炖](https://www.xiaoyuzhoufm.com/episode/656b3db20500be931c50ca00?s=eyJ1IjogIjYwMjNjY2M2ZTBmNWU3MjNiYjc0MDM0MiJ9)|Nixon 的毕业论文研究了37位程序员使用GPT 写代码的状态，我们邀请了懂编程 且 具备一定技术团队管理经验的科技乱炖朱峰、小白来讨论以下问题：GPT 是写代码必不可少的工具了吗？实际使用的状况怎么样？AI 是否会导致程序员以及我们失业？如何正确利用 LLM 工具提升效率？ 没想到的是，我们发现大家对于程序员的工作有所偏见；也发现了还不能使用AI 替代我们的真相；最重要的是，我们似乎发现了适合每一个人的“AI 时代职业观”。|
|40|[对话MyMap.AI创始人：创业1436天0收入，产品上线首月狂揽5万美金](https://www.xiaoyuzhoufm.com/episode/656ebc1fd6e0ff5822ba4c59)|我们邀请到了国际知名 AI 项目 MyMap.AI 的创始人 Victor  参与了我们新一期节目的访谈录制，通过收听本期节目你将了解到： Victor 如何在花光亲爹的 100 万后，又花光 “后爹” （投资人） 1000 万的精彩故事；在不幸遭遇硅谷银行暴雷的时候，作为一个徘徊在 “生死” 边缘的 founder 又是如何应对？多年创业，多次的 Pivot ，最终又是如何将 MyMap.AI 在45天内一举做到 $10K MRR，同时实现高速增长？收听完本期节目，你除会了解到 Victor 和 MyMap.AI 不寻常的创业故事以外，你还将从中收获一些关于创业、出海以及 AI 产品方面的心得和经验。|
|41|[口述全球大模型这一年：人类千亿科学豪赌与参差的中美景观](https://www.xiaoyuzhoufm.com/episode/65910adb991e2ee60880f151)|这是《商业访谈录》的跨年特辑。我邀请拾象创始人李广密口述全球大模型这一年——当顶级商业领袖、顶尖科学家这些人类最聪明的大脑，手握数以千万计的资本狂卷一年，2023年全球大模型卷出了什么？人类这场以大模型为名的豪赌实验，能否将世界带到新的摩尔时代？简单说，模型产业的发展规律会不会极类似半导体行业：未来，模型能力每1-2年提升一代，模型训练成本每18个月是原来的1/4、推理成本每18个月是原来的1/10。广密今年一整年全身心泡在大模型，一大半时间肉身在硅谷，参与相关投资。这期信息量非常密集。我会在show notes里尽可能详细地标注播客中的专业词汇。|
|42|[24，25年会是下一代浪潮最关键的两年   AI年终复盘](https://www.xiaoyuzhoufm.com/episode/65a2a75fb5e4856c70801eba)|这期播客是 42章经 创始人 @曲凯 的个人年终总结。2023年，他聊过了市场上大部分的 AI 创始人和几乎所有的 AI 投资人，服务了十多家 AI 公司的融资并且参与了其中四家的投资，视角可谓一线且全面。在这期播客中，他毫无保留地分享了对于 23 年 AI 市场的总结观察，以及对 24 年及之后市场变化趋势的判断。他的一个核心观点是： 24年和25 年就是我们这代人最关键的两年的机会。|
|43|[特辑：AI科学家李飞飞自传新书《The Worlds I See》](https://www.xiaoyuzhoufm.com/episode/65a902ef8a47fd30c098ece9)|这期节目是非常特别的一期，我和朋友Joyce会一起聊聊AI科学家李飞飞博士的新书《The Worlds I see》（简体版《我看见的世界》，繁体版《AI科學家李飛飛的視界之旅》）。这本书以细腻的笔触回顾了李飞飞一家从中国成都到美国生活，她的成长与科学探索经历，以及她见证的AI发展历程。这本新书的英文版正式发布于2023年11月，很快登顶美国亚马逊最佳自传回忆录的排行榜，评是4.7分，被奥巴马、Pixar创始人、领英创始人等众多大咖推荐。中文译本不出意外也会在今年上半年由中信出版社推出，我们在节目的后半期也会聊到。这本书算是23年年末对我来讲非常有激励的一本，由于是一本女性传记，我自己收获的共鸣也超过了读《马斯克传》的感受。非常巧的是，和李飞飞一样是第一代移民的Joyce也在年底读完了这本书，所以找她一起录了期节目分享我们的读书笔记。由于这本书是本英文传记，所以我们在聊的时候会提到一些未带翻译的名词，我会尽量在节目show notes里做标注。这期录制时间是2023年的最后一周，我们都带着满满的正能量跨年了。也正好作为新年的第一期节目和大家分享，希望你会喜欢！|
|44|[如何用大模型提升学习效率？来自1100小时的深度使用体验](https://www.xiaoyuzhoufm.com/episode/65b444b8a14cb15fcc51a089)|转眼已经2024年了，这轮生成式人工智能大浪潮已经开始了16个月了。我们从各个角度聊过大模型给各行各业带来的变化，但是缺了一个视角：普通人是如何使用大模型的，尤其是学生。大概是一年以前的这个时候，在线课程供应商Study.com向1000名18岁以上的学生发起了一项调查，超过89%的学生使用ChatGPT来完成家庭作业，48%的学生用ChatGPT完成小测验，53%的学生用ChatGPT写论文，22%的学生用ChatGPT生成论文大纲。我就在好奇，大模型是如何帮助这些学生来学习的。但要找到真正把大模型用的好的学生嘉宾并不容易，直到同事给我推荐了本期嘉宾Siqi，他是从ChatGPT发布就开始使用，知道OpenAI和这些大模型公司的每一次宕机，准确来说他不算学生，但是抱着学生的心态在想学习，马上也要在大公司内部转到大模型的组，我们就来看看他是如何成为ChatGPT的高阶玩家的。这期节目我们录制于2023年11月，恰逢OpenAI开发者大会之后。跟他聊完的这两个月里，我种草了很多功能也解锁了很多新用法，有机会我再来跟大家聊一聊我们如何在播客和视频产品中用生成式人工智能技术来辅助我们做内容，欢迎持续关注我们。|
|45|[一年内做成北美Top1的AI教育产品，出海到底该咋干？｜对谈Answer.AI 张阳](https://www.xiaoyuzhoufm.com/episode/65be63d8cace72dff87dddc0)|这期又为大家带来一个优秀的水下项目。Answer.AI 的用户量级和收入都很出彩，可以算是目前北美 AI 教育赛道的第一名。这期我们请来了在公司负责产品和增长的联合创始人张阳来分享下他多年的经验，以及 Answer.AI 是如何从零到一的。张阳对于出海可以说有非常多一手的经验认知，他之前分别在小米、字节等公司做过多款出海产品，有的很快就做到了日活几千万量级。在这期播客里，他为我们分享了很多关于出海用研、增长和商业化的思考，比如是否本地化本质是用户研究做的怎么样，产品出海增长的三要素到底是什么，以及他是如何从零开始做出海渠道增长这件事的等等。其实聊的过程中，我发现有很多点都是普世的真理，很多人容易把出海这件事神话，或者自己天然在心理上创造了门槛，但其实我们花了很多时间在聊的还是怎么找用户需求、怎么做好产品和增长，是不是出海似乎也没有那么大的区别，相信大家听完以后也可以打破一些过往的迷思，所谓的出海，不算是什么艰难的远征，就只是一步步把该做的事情做好。对了，我们还在结尾探讨了一下 AI 原生产品的设计思路，这部分内容格外精彩，也不要错过|
|46|[和杨植麟聊大模型创业这一年：人类理想的增量、有概率的非共识和Sora](https://www.xiaoyuzhoufm.com/episode/65e16b5b6144a933b1d968b5)|今天的嘉宾是大模型公司月之暗面的创始人兼CEO杨植麟。杨植麟是去年成立的这批国产大模型公司创始人中，最年轻的一位，也是学术、工作履历和通用AI有最直接相关的一位。他毕业于清华和CMU，总计论文引用次数超过22000次。在人人喊PMF（产品/市场契合）、人人喊商业化的中国AI生态里，这位AI研究员出身的创始人倒不那么着急。国产大模型中，月之暗面是最坚定做to C、且只做to C的一家公司（于去年10月推出了智能助手Kimi），也是目前估值最高的一家中国大模型独角兽（投后估值超过25亿美元）。就在他们第三笔融资进行的过程中，我和杨植麟聊了聊他过去一年创业故事。这期节目由两次访谈组成。我们主要的访谈是在2024年1月完成，不过过年期间，OpenAI重磅发布Sora，所以我们又在2月补充了一次访谈。由于杨植麟有大模型创业者和AI科学家的两重身份，所以节目中包含了许多他对于AGI技术演进的关键技术判断。|
|47|[与戴雨森和季逸超聊，一幅Sora的信息拼图和大模型淘汰赛](https://www.xiaoyuzhoufm.com/episode/65ed45842d96b6aa80cba888)|今天的嘉宾是真格基金的戴雨森和季逸超。我们从开年AI届两件大事开始聊起：OpenAI发布Sora和Google推出开源模型Gemma。作为投资人和创业者，他们尽最大可能收集了各方的声音，试图搞清楚Sora在人才、算力和数据等各方面究竟是如何实现的。那么，这一期也是关于Sora的一幅信息拼图。同时，雨森是月之暗面和之前光年之外的天使投资人，所以我们也聊了聊国内的大模型生态及进展。|
|48|[02 年伯克利辍学生，千万美金融资额，FlowGPT 背后的从 0 到 1   对谈 FlowGPT 创始人 Jay](https://www.xiaoyuzhoufm.com/episode/65f16b236764957079157e9c)|J 大概会是42章经播客历史上（和可见的未来）最小的被访者。他是 02 年的，去年年初刚大二就从伯克利辍学创业，做了一家公司叫 FlowGPT。截止去年 11 月，FlowGPT  已经拥有了 300 万的月活用户，成为了全球最大的 Prompt 社区——或者用他现在给自己的定位 “AI 原生应用平台”。我其实在之前的播客里有提到过，我对于年轻、经验不足的创业者是倾向于悲观的，但 J 聊起来给我一种非常早熟、踏实的感觉，这和他的年龄非常不符合。从和他的对话中，我大概明白了为什么他能做得这么成功，以及为什么他是今年最常被投资人提及、讨论和喜爱的创业者之一。在这期播客中，你将听到他辍学创业的起因经过，也能从他的视角看到 300 万的月活用户都是怎么理解和使用 AI 的，以及他对于 AI、Prompt 等事情的理解，我相信他是全球对这件事最有发言权的人之一了。此外，我还和他聊了一些他融资中的趣事，和他中美两地融资的一些故事和感受。|
|49|[和王小川聊再创业这一年：回应朱啸虎与中国AGI第三种可能](https://www.xiaoyuzhoufm.com/episode/65f77b6e6764957079e5d8eb)|今天的嘉宾是百川智能创始人兼CEO王小川。大家可能注意到，我在3月写了三篇关于中国AI的报道，合称《2024 AI 三部曲》。在前两篇发布后，以杨植麟为代表的理想主义“技术信仰派”和以朱啸虎为代表的现实主义“市场信仰派”，双方观点引发广泛关注。而且，朱啸虎在报道中三次点名王小川和百川智能。几天以后，王小川接受了访谈。他试图阐释在技术和市场、理想和现实之外，中国AGI还有第三种可能性。|
|50|[对话Meta田渊栋：被Transformer改变的世界与人类AGI的野心](https://www.xiaoyuzhoufm.com/episode/6605fe71338c31204886d3f1)|2017年，谷歌一篇划时代的论文《Attention is all you need》掀开这一轮人工智能的开幕式，这篇论文就是大名鼎鼎的Transformer。7年过去了，我们看到在这篇论文的基础上加入算力、算法开启了AI时代的第三次科技浪潮。今天我们的嘉宾是来自Meta Fair的研究员田渊栋博士，他最近也发表了两片论文都在都与端侧小模型相关，一片论文是《 MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases》中开始卷 10 亿以下参数小模型，主打在移动设备上运行 LLM；另一片论文是《GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection》，由于离应用更近在解决更实际的问题，他的论文被业界很多人问到，而过去五年，他所有的研究都在回答一个问题：神经网络是如何工作的？今天我们就一起来解读田渊栋最近的两篇论文，也一起聊聊最近大火的Sora、Transformer与AGI。|
|51|[一个顶级AI产品经理的自我修养 ｜ 对谈光年之外产品负责人 Hidecloud](https://www.xiaoyuzhoufm.com/episode/6607a6961519139e4f7fd8a5)|最近一年经常和创业者聊到的话题就是 AI 产品经理到底该长什么样子，该怎么招、怎么培养，以及公司的组织结构该怎么调整成最适应 AI Native 的形态。我认为 Hidecloud 是目前国内最典型的做得最好的 AI 产品经理之一，他通过一年的探索，亲身试验了很多 AI 产品，在这期播客中我们一起探讨和解答了很多上述提到的问题，而且相信每个人在听过他的分享以后，都能有个大概的感觉：原来这就是好的 AI 产品经理的画像。此外，因为他的动手能力很强，真正实践过很多产品的落地，所以本期内容中也包括了大量一线的对技术判断的视角，以及对市场和产品现状的感受等。|
|52|[你们要的朱啸虎，来了](https://www.xiaoyuzhoufm.com/episode/66090a2c1519139e4fa97f99)|很多听众在后台留言，希望我们的播客也放出对金沙江主管合伙人朱啸虎的访谈，他在对于大模型的观点讲了一个中国现实主义的 AIGC 故事。那么今天你们要的 Allen Zhu 终于来了。访谈一共有两次，播客收录的是其中一次访谈。|
|53|[Suno 与 AI 重塑音乐的想象   对谈快音创始人李岩](https://www.xiaoyuzhoufm.com/episode/66116fd14f66d1c1da5f1541)|在这期播客中，我们就请到了快音的创始人李岩，他从 15 年到 18 年在字节负责整体增长策略，经历了抖音等各个平台的快速起量和增长阶段，后来他看到了音乐平台被推荐算法改变的机会，创业做了快音这个平台，最高峰达到了 300w+ 的日活，这两年他们也一直在思考和探索 AI 生成音乐这条路径。AI 音乐改变的不只是音乐产业的运作方式，大幅降低的音乐生产门槛其实还解锁了非常多的想象空间，比如现在已经有很多博主在用快音创作 AI 音乐解说电影等，这期内容中我和李岩一起探讨了音乐发展的几个历程（从版权之争、到短视频对音乐产业的改变、再到当下的 AI 浪潮），我们也开放性地探讨了 AI 音乐未来的想象空间。就像我们在播客中所说的，我相信 AI 生成音乐是所有 AI 生成类型的内容中最被大家低估的一个场景，而其成熟度其实已经非常之高，在这期音频中我们也插入了三段 AI 生成的音乐供大家感受。|
|54|[和广密聊AGI大基建时代：24 Q1全球大模型前沿手记](https://www.xiaoyuzhoufm.com/episode/661f21075dae7932c6f821d8)|3月，我们连续从多个角度关注了中国AGI进展，这集让我们把目光投向海外，对刚过去的 2024 Q1全球大模型的赛局做一个场上的复盘和点评。嘉宾是《商业访谈录》的老朋友、拾象CEO广密。他提出，我们正处于一场宏大的“AGI大基建”时期。正如上世时期纪90 年代克林顿推出美国信息高速公路建设，这才有了后面的美国互联网泡沫破裂和互联网黄金20年——如果没有基建，就不可能有应用大爆发。|
|55|[Suno引爆音乐圈，与音乐人聊聊AI生成音乐与艺术的随机数](https://www.xiaoyuzhoufm.com/episode/6621b1a57ea4dff3819fffe9)|AIGC的风终究是吹到了音乐圈——今年3月，“音乐届的ChatGPT” Suno V3粉墨登场，用户只需要在Suno上输入一句话的提示词，即可在数秒内生成两首两分钟的完整歌曲，从作词、作曲、演奏到人声演唱一气呵成，大大降低了普通人创作音乐的门槛。已经习惯了各类“AI歌手翻唱”的听众和用户迅速拥抱了Suno，从《宫保鸡丁咏叹调》到《让我们荡起双桨》重金属，从英语、日语、俄语到普通话甚至是粤语，网友们自发上传的作品包罗万象，网易云音乐、QQ音乐等平台也迅速上线了SunoAI音乐专区，甚至还推出了定期更新的官方推荐歌单。本期《硅谷101》邀请到了来自音乐和AI音乐生成领域的两位嘉宾，知名音乐博主“叨叨冯” 冯建鹏，美国哈特福德大学哈特音乐学院打击乐讲师，百老汇全职演奏家和Roger Chen, Meta Music Tech Lead，分享他们对以Suno为代表的文生音乐模型的看法，以及AI如何影响音乐产业的未来。|
|56|[AI 硬件的道、法、术   对谈三耳猫创始人谢羽佳](https://www.xiaoyuzhoufm.com/episode/6623ad66c3e09d8f374ff730)|最近 AI 硬件特别的如火如荼，但因为经历过上波消费出海的热潮，我对 AI 硬件的定位是本质上这还是一种消费电子。那既然是消费电子，仍然是众筹、Amazon、线下渠道等一系列打法，所以这期播客我们请来了有十多年出海消费电子经验的羽佳，她既是这个领域的专家，又是一位新入行的 AI 硬件的创业者，我们借由 AI 的话题，一起聊了下她多年来在这方面积累的经验和认知，以及她对于 AI 带来的新变化的一些看法。羽佳作为 Anker 的 CEO 助理，经历了 Anker 从几亿到几十亿的全过程，后来她又在出门问问负责整个海外业务的增长，之后她参与创立的公司 Global Oneclick 更是出海服务领域的绝对头部代表，他们服务了超过 40 家百万美金级别的众筹项目，包括近年来特别成功的 Ecoflow、云鲸、拓竹、追觅、华米，以及新时代的 AI 硬件公司 plaud 等等都是他们的客户，所以她在这方面的话语权毋庸置疑。这期内容中，我们其实反复围绕着道、法、术三个层面对 AI 硬件/消费电子展开了讨论，相信听完这期播客，你也能快速的掌握 AI 硬件其中的核心 know how。|
|57|[赚到 RMB 的 AiPPT、赚到美金的 ACE Studio 和赚到用户留存的捏Ta   AI PMF 系列创始人对话](https://www.xiaoyuzhoufm.com/episode/663f954caf1e22bb15b943d5)|本期的三家公司分别是 AiPPT、ACE Studio 和 捏Ta。AiPPT 上线半年达到单月几百万人民币的收入，算是在国内验证了付费 PMF 的公司，ACE Studio 开启付费半年，目前单月几十万刀的海外收入，算是在海外验证了付费 PMF 的公司，而 捏Ta 则是已经有了超出互联网时代平均水平的用户留存数据，验证了国内的用户使用行为 PMF。这几家公司各有各的特色，有 2B 也有 2C，创始人的风格、关注点、对 AI 和产品等的理解也都不尽相同。PMF 并没有一个官方的绝对的定义，但我们希望用这样的方式多介绍一些能实际使用、有实际场景、收入或用户留存的产品，给这个行业一些信心，也给关注 AI 领域的人一些启发。|
|58|[深度解析GPT4o、谷歌AI助理：留给OpenAI和Google的时间不多了 ｜ 硅谷徐老师](https://www.xiaoyuzhoufm.com/episode/6646b11461484b6319077ee6)|5 月 14 日，OpenAI 在产品发布会上发布了最新 GPT-4o 多模态大模型，通过实时的语音、视频和文本交互震撼了全世界。然而就在这场发布会后一天，谷歌举办了 2024 年 I/O 开发者大会，发布了令人眼花缭乱的 AI 产品，名字都快多的记不过来了。当然最令人瞩目的还是和 GTP-4o 对标的 Project Astra。本期节目邀请到三位业内人士进行访谈，其中包括两位 AI 领域的创业者：出门问问创始人兼 CEO 李志飞与 jobright.ai 联合创始人郑玉典。大家分享了在这两场发布会后的感受和思考，志飞从行业以及技术的角度大家分析了 AI 助理发展成真正可以日常使用的产品还需要解决的问题，以及 Open AI  和谷歌这两家科技公司各自现存的问题与挑战等。|
|59|[和李志飞聊IPO、GPT-4o和你不知道的前沿科技创业的痛](https://www.xiaoyuzhoufm.com/episode/664f2985c59d1e575733e1dd)|今天的嘉宾是李志飞，前不久他的公司出门问问刚作为“AIGC第一股”在港交所完成上市。（股票代码：2438.HK）他在节目里很坦诚地聊了聊，作为一家AI公司、一家前沿科技公司，在熬过12个年头终于站在交易所敲钟的那一刻，他到底想了些什么。还有那些你不知道的前沿科技创业中的狂妄与痛苦——他称，自己是一个看见过“创业死亡”的人。他的故事或许能给今天在大模型浪潮中冲浪的选手，一点启发。此外，我们也点评了最近的GPT-4o、Google AI助手和字节模型大降价等一系列AI最新进展。|
|60|[对话NVIDIA和五源资本：“具身智能”能带领这波机器人热走多远？](https://www.xiaoyuzhoufm.com/episode/66551fc075f2e39409f18cd4)|视觉、语言理解等多模态大模型和仿真训练技术的结合像是给机器人打了鸡血，让它们变得越来越聪明，行动能力越来越强，越来越像人。 “具身智能”的出现，让机器不再仅仅是被动的计算设备，而是能够主动与物理世界互动的智能体。从创业公司到科技巨头，从软件平台到硬件开发，这场机器人竞赛的参与者越来越多。从特斯拉的Optimus到波士顿动力的Atlas，这些类人形机器人展现了无与伦比的交互能力，实现了从视觉到动作的端到端神经网络闭环。这些进展似乎预示着“莫拉维克悖论”的终结，即机器人在感知和运动任务上的困难正逐步被克服。随着技术成本的降低和成熟度的提高，人形机器人的商业化应用是否已近在咫尺？在这场竞赛中，哪类玩家能够抢占先机？本期《硅谷101》邀请到了NVIDIA中国区机器人业务负责人李雨倩 (Lily Li) 和五源资本董事总经理陈哲 (Peter Chen)，与大家分享他们对机器人行业的见解，讨论AI加持下的机器人行业有哪些新的工具和技术，还需要经历哪些挑战，才能真正实现规模化和商业化。|
|61|[对话 Minimax 的 AI PM 橘子：聊聊 AI 行业的最新认知](https://www.xiaoyuzhoufm.com/episode/664b329c251bd96e6c90e3f2)|非常荣幸邀请到了 AI产品专家橘子（Orange）完成了本期节目的访谈录制，这一期节目将带你解密AI大模型的幕后：从开源到闭源，从训练到应用，深度探讨国内大模型发展现状，以及如何利用AI掘金海外市场等等。如果你也在关注AI、关注大模型以及AI应用，那本期节目不容错过。|
|62|[谈谈黄仁勋搭建的组织系统：分布式操作系统，“就像一台GPU”](https://www.xiaoyuzhoufm.com/episode/6659b98a94977a26ef497a5c)|很多企业家在过去一两年纷纷去英伟达“朝圣”，令他们最为吃惊的是黄仁勋的管理方法论。每一条都很反直觉，反共识——比如，老黄不裁员。今天我邀请前龙湖集团CSO、专注战略与组织研究的王亚军，来系统性梳理老黄搭建组织系统。先透露两条让我听完觉得非常激动的观点：1.一个组织的沟通结构会决定它的产品架构，英伟达组织就像它的产品一样，是分布式操作系统，“就像一台GPU”；2.如果一个企业没有爱，是不会有创新的；恐惧永远是创新的敌人。|
|63|[戴雨森：拥抱时代、乐观和年轻人的力量](https://www.xiaoyuzhoufm.com/episode/66723488b6a8412729c01e5e)|本期节目是近日 AI 科技评论对真格基金管理合伙人戴雨森的专访。2009年，雨森从斯坦福退学，并与陈欧共同创办了聚美优品。5年后，聚美优品成功上市，彼时雨森27岁。2017年，雨森加入真格基金，专注于早期投资。近一年多来，他主要关注AI领域，投资了包括月之暗面等头部AI项目。在本期节目里，我们探讨了AI投资泡沫下是否存在真正的机会，以及如何判断一个技术或产品是否具有长期价值。我们还分析了中美在AI发展上的差异，包括硅谷与中国市场在AI应用方面的不同。最后，雨森还真诚分享了自己从移动互联网时代创业者，转变为AI时代的一线投资人的心路历程。|
|64|[和MiniMax天使投资人聊，MiniMax幕后故事和大模型扑克牌](https://www.xiaoyuzhoufm.com/episode/66671ad194977a26ef6b8ed6)|今天的嘉宾是MiniMax天使投资人、云启资本合伙人陈昱。MiniMax是中国6家大模型创业公司中，除月之暗面之外，另一家估值比较高的独角兽企业。这集我们聊了聊MiniMax的创业、融资和团队故事。此外，最近很多投资人都去美国参加了GenAI大会，陈昱在现场聊了聊他的观察。|
|65|[对谈 MiniMax 闫俊杰：AI 语音助手的未来是大厂的，还是创业公司的？](https://www.xiaoyuzhoufm.com/episode/666a6a09b6a84127296783ad)|在看到 OpenAI 最新发布的GPT-4o 时，MiniMax 创始人、CEO 闫俊杰的第一感觉是「惊艳」，流畅的语音交互、实时的视觉理解、语言捕捉甚至包括了「呼吸声」。2021 年底，闫俊杰创立 MiniMax 时，ChatGPT 还没有出现、业内也没有人相信大模型，而促使他一定要创业的动力是，「把人工智能做成通用、服务大众这件事是很重要的」。在这个目标驱使下，MiniMax 是行业少有的同时做模型、产品的公司。在发布会结束两天后，这位以神秘、低调著称的从业者，罕见地做客FounderPark直播间，和极客公园创始人兼总裁张鹏进行了一场对谈。从这场发布会切入，他聊到了技术和成本、行业赛点、开源与闭源之争、投流和 PMF等关键问题。他认为，GPT-4o 的技术难度其实并不高，更重要的在于它的出现有望大幅提升AI的渗透率。|
|66|[英伟达的阳谋、破绽与野心   对话行云创始人 Mackler 季宇](https://www.xiaoyuzhoufm.com/episode/6666dd6a94977a26ef5e07b7)|季宇是清华物理本科、计算机体系结构方向博士，他也是我认识的几个华为天才少年之一。认识他是因为在不同的时间点，分别有几个人跟我说，你要聊英伟达一定要找他，他是最懂英伟达的人，后来我看了他知乎（Mackler）上的很多篇文章以后确实觉得很厉害，于是就有了这次的对话。其实关于英伟达已经有各种文章和播客讲过，但大多花费了大量的笔墨和时间在讲 CPU、GPU、CUDA 等名词解释，我们这次先用了几分钟时间快速科普了这些基础内容，然后用一个不太一样的视角讲英伟达背后的战略体系，讲英伟达是怎么从 Intel 的垄断地位中杀出来，并有了今天绝对领先的生态地位的。我敢保证，这期的内容和视角是你从来没有看过听过的。在收听过这期内容之后，你会更理解英伟达在过去几十年里都做了什么，现在正在做什么，也更能理解老黄的 NB 和精妙之处，而且还会对芯片产业历史沿袭及各个公司的战略选择有更多的体会和启发。|
|67|[口述全球大模型这半年：Perplexity突然火爆和尚未爆发的AI应用生态](https://www.xiaoyuzhoufm.com/episode/6679537fb6a8412729f89145)|AI搜索是大模型在应用端达成的第一个共识。这次，我们详细聊了聊AI搜索企业Perplexity，关于它的创业、数据、竞争与护城河。Perplexity最新一轮估值已达30亿美元。此外，我们聊了一些业界关心的重要话题：AI应用为什么还没有大爆发？GPT-5为什么那么慢？大模型的商业模式和壁垒究竟是什么？我们也对美国科技巨头过去半年的状况一一作了点评。|
|68|[《气球人》第 2 集 —— 失落](https://www.bilibili.com/video/BV16H4y1G7Ep/)|《失落》是《气球脑袋》的姊妹篇；Shykids 利用 OpenAI 的 Sora 进行的首次尝试 —— 在这次尝试中，他们将真实的演员和场景与由 Sora 创造的视频融合在一起。在一次深入的访谈中，气球人桑尼分享了他的成名之路、他突然退出公众视野的经历，以及现在是什么让他保持清醒和脚踏实地。👀🎈|
|69|[开启 AI 未来时刻 - 中文字幕版黄仁勋 COMPUTEX 2023主题演讲](https://www.bilibili.com/video/BV1Fm4y1t7sZ/)|2023 年 5 月 29 日，NVIDIA CEO 黄仁勋在 COMPUTEX2023 上发表了现场主题演讲，带来适用于各个行业的生成式 AI 平台。观看中文字幕版主题演讲，听 NVIDIA 创始人兼 CEO 黄仁勋分享 AI、图形及其他领域的最新进展，及时了解这些技术创新如何影响当今各行各业，及助力实现更高效的工作流程的新系统、软件和服务。|
|70|[【对话】梁建章：AI时代的旅游业、教育、人口经济与创新](https://www.bilibili.com/video/BV1Dx4y1o7j1/)|AI来了，人类还需要多生娃吗？携程董事长梁建章说：正因为AI来了，中国提高生育率迫在眉睫。2023年7月1日起，携程集团推出针对全球员工的“程二代程长礼金”生育补贴政策：入职满3年的全球员工，不论性别，每新生育一个孩子，将获得每年一万元的现金补贴，发放至孩子满5周岁为止，这项对员工的福利投资会达到10亿人民币。可见，梁建章对生育率这件事情的重视程度。而与《硅谷101》的对话中，梁建章强调，在AI时代，人口和创新的关系更为紧密，也关系到国家之间的财富分配。我们也针对最近的科技进展，特别是AI如何影响旅游业，会替代哪些工作，AI对未来国际财富分配的影响，以及AI时代生育率和创新的关系，以及未来人类价值这几个方向都进行了深度的讨论。|
|71|[[TED演讲] AI+教育：为学生和老师提供令人惊叹的人工智能超级导师](https://www.bilibili.com/video/BV1bh411L7xS/)|Khan Academy（可汗学院）的创始人兼首席执行官 Sal Khan 认为，人工智能可以引发前所未有的最积极的教育变革。 他分享了他看到的学生和教育工作者与 AI 工具合作的机会——包括为每个学生配备个人 AI 导师和为每位教师配备 AI 助教的潜力——并演示了他们的教育聊天机器人 Khanmigo 的一些令人兴奋的新功能。|
|72|[Pika 1.0 局部修改教程](https://www.bilibili.com/video/BV14b4y1V7u2/)|Modify Region可以更改特定选框中的内容|
|73|[OpenAI首席执行官(Sam Altman)和首席技术官(Mira Murati)谈论AI的未来和ChatGPT   华尔街日报(WSJ)科技直播2023](https://www.bilibili.com/video/BV1gh4y1i795/)|OpenAI的山姆·阿尔特曼(Sam Altman)和米拉·穆拉蒂(Mira Murati)讨论了他们未来的GPT模型的能力，以及随着技术的进步，人类与AI的关系如何改变，以及关于安全性、责任和工作的担忧。|
|74|[【官方】看看让Copilot帮你做PPT有多快？](https://www.bilibili.com/video/BV1cc41117cn/)|PPT能自己做PPT了！你可以在新版PPT尝试“基于文件生成”，只需几秒，就能生成一份Copilot设计美化的PPT内容！Copilot还能对标题颜色等细节润色，以前需要逐页调整的操作也瞬间完成了！|
|75|[从Sora展开，全面解读AI视频大模型发展史【深度】](https://www.bilibili.com/video/BV14F4m1c7RC/)|Sora，OpenAI的人工智能AI生成式视频大模型，在2024年2月15日一经发布就引发了全球关注。Sora好在哪里？GAN、VAE、扩散模型、LLM技术生成AI视频的优劣势都是什么？OpenAI的视频模型一定是正确的路线吗？这期视频，我们通过与硅谷一线AI从业者的采访，深度聊聊生成式AI视频大模型的不同派系发展史，相关争议和未来发展路线。|
|76|[Zapier 的联合创始人 Mike Knoop 演示新的 AI 自动化工作流](https://www.bilibili.com/video/BV1Et421n7oa/)|Zapier 新的工作流改成了类似于 GPT Builder 的聊天界面，通过自然语言的聊天对话让 AI 帮你创建自动化工作流，并且可以对创建的结果进行人工修改，以及测试，如果对测试结果不满意，可以继续输入提示词让 AI 进行修改。|
|77|[【李宏毅】2024最新课程【生成式AI导论】](https://www.bilibili.com/video/BV1BJ4m1e7g8/)|该课程的目标受众为初学者，不需要任何先验知识，也不要求学生事先修过机器学习或人工智能课程，欢迎每个感兴趣的同学参加|
|78|[NVIDIA CEO 黄仁勋 SIGGRAPH 2023 主题演讲：探索 AI 的未来](https://www.bilibili.com/video/BV14N41187Eb/)|观看 SIGGRAPH 2023 黄仁勋主题演讲，了解英伟达的新技术，包括屡获殊荣的研究，通用场景描述（OpenUSD）开发，以及最新的 AI 内容创作解决方案。|
|79|[Ilya TED演讲：兴奋又危险的AGI之路](https://www.bilibili.com/video/BV1Eu4y1j73v/)|就在OpenAI的管理动荡震撼硅谷并成为国际新闻的几周前，该公司的联合创始人兼首席科学家Ilya Sutskever探讨了人工通用智能（AGI）的变革潜力，强调它如何超越人类智能并深刻改变生活的方方面面。听他对AGI承诺和危险的看法，并乐观地阐述了独一无二的合作将确保其安全和有益发展。|
|80|[两只 GPT-4o，一只看不见，另一只帮它描述发生了什么](https://www.bilibili.com/video/BV1As421P7dN/)|两只老虎两只老虎跑的快，一只没有眼睛一只没有尾巴真奇怪！ 哦，不对，是两只 GPT-4o，一只看不见，另一只帮它描述发生了什么，甚至于1分钟之前出现的意外小插曲也能完整记录，最后两只 AI 把整个过程编成了一首歌唱起来|
|81|[【官方】如何用Copilot变身文案高手?](https://www.bilibili.com/video/BV19p421D7p7/)|你的职场专属助手Copilot又变得更强了，在Word、PPT、OneNote和Teams中都能时刻向它寻求帮助！只需像聊天一样和它进行头脑风暴，就能快速得到你想要的文案、创作提纲、工作汇报等内容，并一键转换成排版精美的PPT，让你快速达成目标、掌控全局。高效工作，从Copilot开始！|
|82|[【TED】AI 如何赋能各行各业](https://www.bilibili.com/video/BV1f2421M7wA/)|人工智能系统造价昂贵，需要技术高超的工程师来维护，通常只有拥有大量数据的大型科技公司可以不做 AI 的赔本买卖。但是如果你当地的披萨店也能用上 AI 预测每天哪个口味的披萨卖得最好，会怎么样？吴恩达（Andrew Ng）给我们分享了让每个人用上 AI 的畅想，让每个企业做出提升收入和生产力的决定。来听听我们该如何创造一个更富有的社会，你需要做的仅仅是提供一些数据。|
|83|[Pika Sound Effects音效功能介绍！](https://www.bilibili.com/video/BV1cZ421h7S3/)|音效能直接生成添加到你的视频中啦！你可以通过提示词生成想要的声音，或者让Pika根据你的视频内容自动生成音效，是不是很酷呢？|
|84|[人工智能的可能性   Sam Altman 4月24日 在斯坦福大学创业思想领袖研讨会](https://www.bilibili.com/video/BV1eC411J7rT/)|在与斯坦福大学兼职讲师 Ravi Belani 的对话中，Altman 为有抱负的人工智能企业家提供了建议，并分享了他对人工智能工具和通用人工智能的机遇和风险的见解。|
|85|[【官方】Dreamina介绍](https://www.bilibili.com/video/BV18D421N7Q5/)|只需简单的文字指令，即梦便能激发无限创造力，生成精彩的图片和视频，AI作图和AI视频生成功能现已正式上线|
|86|["基础智能体" 人工智能的下一个重大挑战   Jim Fan @NVidia   TED](https://www.bilibili.com/video/BV1Tb4y1A7SW/)||
|87|[“让我们构建GPT Tokenizer”AI大神Andrej Karpathy最新大模型技术讲座 ](https://www.bilibili.com/video/BV1wt421h7Cx/)|分词器（Tokenizer）是大型语言模型（LLMs）中不可或缺且广泛应用的组件，它负责在字符串和令牌（文本块）之间进行转换。分词器是LLM处理流程中一个完全独立的阶段：它们拥有自己的训练数据集、训练算法（如字节对编码 Byte Pair Encoding），并在训练后实现两个基本功能：encode()，即将字符串转换为令牌；以及decode()，将令牌还原为字符串。本次讲座中，我们将从零开始构建OpenAI的GPT系列模型所使用的分词器。在此过程中，我们会发现许多LLMs中的奇怪行为和问题实际上都可以追溯到分词这一环节。我们将探讨一系列这类问题，讨论为什么分词是问题的根源，以及为什么有人理想中会找到方法完全去除这一处理阶段。|
|88|[【Sora官方介绍】OpenAI文字生成视频模型](https://www.bilibili.com/video/BV1ey421b7xy/)|介绍Sora，我们的文本转视频模型。Sora能够创建长达60秒的视频，呈现高度精细的场景、复杂的摄像机运动，以及带有生动情感的多个角色。在将Sora应用于OpenAI产品的前提下，我们将采取多项重要的安全措施。我们正与“红队”专家合作——这些专家在虚假信息、恶意内容和偏见等领域具有专业能力，他们将以对抗性的方式测试该模型。本视频中的所有片段都是由Sora直接生成，未经任何修改。|
|89|[【TED】OpenAI联合创始人Greg Brockman解惑ChatGPT惊人潜力的幕后故事](https://www.bilibili.com/video/BV1jg4y1A7AU/)|在一场处于技术前沿的演讲中，OpenAI联合创始人Greg Brockman探讨了ChatGPT的基本设计理念，并展示了几个令人震撼、尚未发布的插件，这些插件是为了那款在全球范围内引起轰动的聊天机器人设计的。演讲之后，TED负责人Chris Anderson与Brockman进行了交流，深入了解ChatGPT开发的时间线，并就科技行业内外许多人提出的担忧进行了探讨：即向世界发布如此强大工具所带来的风险，以及Brockman对此的看法。|
|90|[【TED】李飞飞   空间智能让AI理解真实世界](https://www.bilibili.com/video/BV19T421S7jt/)|知名「AI 教母」李飞飞正在创建一家初创公司，并完成了种子轮融资。在介绍这家初创公司时，一位消息人士引用了李飞飞在温哥华 TED 会议上的一次演讲。她在演讲中表示，该前沿的研究涉及一种可以合理地推断出图像和文字在三维环境中的样子的算法，并根据这些预测采取行动，这种算法概念叫做「空间智能」。|
|91|[【上集】向量数据库技术鉴赏](https://www.bilibili.com/video/BV11a4y1c7SW/)||
|92|[【吴恩达】给所有人的AI课程](https://www.bilibili.com/video/BV1yL411u7q6/)|由人工智能先驱吴恩达教授指导的《人人可掌握的生成式AI》课程，为您提供了利用生成式AI增强自我及工作的独特视角。安德鲁将引导您了解生成式AI的工作原理，以及它的能力范围（包括能做什么和不能做什么）。课程包含实践练习，您将学会如何在日常工作中运用生成式AI，并获得有关高效提示构建的建议，同时学习如何超越基础提示，探索AI的更高级应用。您将深入探讨真实世界的应用实例，了解常见的使用场景，并有机会亲自操作生成式AI工具，将所学知识付诸实践，同时深入了解AI对商业和社会影响的深刻洞见。此课程旨在确保每个人都能成为我们人工智能驱动未来的一份子。|
|93|[【堆友AI】的宝藏九大参考图玩法详细教程](https://www.bilibili.com/video/BV1Nz421o7eQ/)|一个视频搞懂堆友参考图，附上堆友AI的宝藏九大参考图玩法详细教程，各种风格各种造型各种形式全都囊括其中！ 不用本地部署，不用4090，设计师小白也能轻松上手|
|94|[【官方】 GPTs 介绍](https://www.bilibili.com/video/BV1ZN4y1S7qZ/)|GPTs为任何人创造了一个新途径，使他们能够定制ChatGPT，以便在日常生活、特定任务、工作或家庭中提供更加贴心的帮助，并且可以将此定制版本与他人分享。任何人都能轻松构建自己的GPT——无需编程知识。您可以为自己制作，仅限公司内部使用，或是面向所有人。创建过程就像开始一次对话一样简单，给它提供指导和额外的知识，并选择它能做的事情，比如搜索网络、制作图像或分析数据。|
|95|[【官方】1分钟教你玩转Dreamina首尾帧技巧](https://www.bilibili.com/video/BV1Xr421G7Kc/)|学会了这个独一无二的首尾帧技巧，瞬间就能让你的AI视频多出上百种不同玩法，作品直接提升一个level！|
|96|[【官方】Verse新手引导](https://www.bilibili.com/video/BV1te4y1e7Q3/)|Verse是印象笔记全新推出的面向未来的智能化生产力工具！|
|97|[【官方】如何用Copilot轻松处理长文档?](https://www.bilibili.com/video/BV1Kb421Y7Ci/)|当你又收到一份又长又复杂的文档时，会不会感觉很头疼？别担心，跟着这个简短的视频操作一遍，在Word中用Copilot轻松搜索、简化那些繁琐、大篇幅的文档内容，把时间留给你更重要的工作！|
|98|[【官方】有道速读   文献阅读神器演示](https://www.bilibili.com/video/BV1YG411v7kS/)|有道速读可自动将用户上传的pdf原文逐段翻译为自然、流畅的中文译文，支持跨栏、跨页段落的拼接与扫描页的识别解析。支持译文与原文的段落匹配高亮和自动跳转，新一代科研神器。|
|99|[【李沐】GPT-4论文精读](https://www.bilibili.com/video/BV1vM4y1U7b5/)||
|100|[【李沐】GPT，GPT-2，GPT-3 论文精读](https://www.bilibili.com/video/BV1AF411b7xQ/)||
|101|[【渐构】万字科普GPT4为何会颠覆现有工作流；为何你要关注微软Copilot、文心一言等大模型](https://www.bilibili.com/video/BV1MY4y1R7EN/)|视频是关于GPT的底层原理和未来影响。将抛开技术细节，少用专业名词，在整体功能上讲解 ChatGPT 的「工作原理」「制造过程」「涌现的能力」「未来的影响」以及「如何应对」：1、ChatGPT是如何回答问题的2、它是怎么被制造的，为什么它不是搜索引擎3、它有哪些惊人能力，为什么它不只是聊天机器人4、它将给社会带来什么样的冲击5、我们该如何维持未来的竞争力|
|102|[【陆奇】《新范式 新时代 新机会》演讲](https://www.bilibili.com/video/BV1mM4y147qw/)|在奇绩创坛举办的以《新范式 新时代 新机会》为主题的分享活动上，陆奇博士以“新范式”为核心，分享了他对当前技术变革的观点|
|103|[3分钟了解通义听悟核心功能](https://www.bilibili.com/video/BV1WP411D79F/)|聚焦音视频内容的AI新品“通义听悟”接入了通义千问大模型的理解与摘要能力，可成为用户工作学习中的得力AI助手，帮助随时随地高效完成对音视频内容的转写、检索、摘要和整理，比如用大模型自动做笔记、整理访谈、提取PPT等。|
|104|[Yann LeCun：关于Meta人工智能、开源、大型语言模型的局限性、通用人工智能与AI的未来](https://www.bilibili.com/video/BV1px421C7Z7/)|Yann LeCun, Meta的首席人工智能科学家、纽约大学教授、图灵奖得主，以及人工智能历史上的关键人物，在Lex Fridman播客的第三次访谈中分享了他对人工智能领域的深刻见解。LeCun认为，通过专有AI系统集中的权力带来的危险比其他任何威胁都要大。他担心如果出于安全考虑将AI系统封闭起来，仅由少数公司控制，将会导致信息来源被这些拥有专有系统的公司严格把控，这是一个非常糟糕的未来景象。他与Lex Fridman都相信开放源代码AI可以赋予人们更多的力量，尤其是当人们本质上是善良的时候，开放AI能够促进这种善良。LeCun和Meta AI一直是开源AI发展的大力倡导者，他们通过开源包括Llama 2在内的许多重要模型，以实际行动支持这一理念，并计划最终开放Llama 3。LeCun对于那些警告AGI（通用人工智能）即将带来的潜在危险和生存威胁的声音持批评态度。他认为尽管有一天AGI会被创造出来，但它将会是好的，不会逃脱人类的控制，也不会主宰并消灭全人类。尽管在这个AI迅速发展的时代，他的观点颇具争议，但LeCun仍然积极参与到各种激烈且引人入胜的在线讨论中。|
|105|[Andrej Karpathy大神亲授：大语言模型入门](https://www.bilibili.com/video/BV1Hj41177fb/)|这是一个面向大众的、时长一小时的大规模语言模型入门介绍：这是诸如ChatGPT、Claude和Bard等系统背后的核心技术组成部分。介绍它们是什么，它们的发展方向，与现今操作系统之间的比较和类比，以及这种新的计算范式带来的一些安全相关挑战。|
|106|[Andrej Karpathy微软Build大会精彩演讲： GPT状态和原理 - 解密OpenAI模型训练](https://www.bilibili.com/video/BV1ts4y1T7UH/)|了解类似ChatGPT这样的GPT助手的训练流程，从分词到预训练，监督微调，以及基于人类反馈的强化学习(RLHF)。更深入地探讨有效使用这些模型的实际技术和思维模式，包括提示策略、微调、快速发展的工具生态系统，以及它们未来的扩展方向。|
|107|[Anthropic联创Daniela Amodel 红杉AI活动访谈](https://www.bilibili.com/video/BV1T1421U7Uo/)|Daniela Amodei，Anthropic的联合创始人兼总裁，与红杉资本(Sequoia Capital)的Sonya Huang一起，在AI Ascent活动中就Claude 3的发布、解决AI在业务中面临的信任与可靠性问题、研究透明度的重要性，以及实施技术安全方法以使AI更符合人类价值观等议题进行了讨论。|
|108|[ChatGPT之父奥特曼：年轻人如何抓住未来](https://www.bilibili.com/video/BV18k4y187K3/)|对OpenAI首席执行官Sam Altman的采访涵盖了个人与职业发展相关的广泛话题。Sam分享了关于如何优先排序任务及决定专注项目的见解，他就如何选择合适的合作者提供建议，强调与支持性团队保持一致的重要性，讨论了实现重大成就的策略。Sam谈及在职业生涯初期如何管理工作和个人生活，提供了关于何时退出项目或努力的决策指导，讨论了人们的动机是什么以及动机如何随时间演变。Sam区分了保持势头与过度劳累的风险，提出了对风险采取的不同视角，以及个人应该如何应对，关于明确自己的愿望并积极追求的建议，突显了长久坚持目标和想法的价值。Sam讨论了持有坚定观点同时在细节上保持灵活性的重要性，以针对初入职场的年轻人量身定制的指导作为结束。整个访谈中，Sam借鉴了自己作为企业家、投资者和科技行业领导者的丰富经验，提供了促进职业成长与成功的实用智慧。|
|109|[面向开发者的ChatGPT提示工程](https://www.bilibili.com/video/BV1Z14y1Z7LJ/)|在《面向开发者的ChatGPT提示工程》课程中，你将学习如何利用大型语言模型（LLM）快速构建新颖而强大的应用程序。通过使用OpenAI API，你能够迅速构建出以前因成本过高、技术复杂或根本不可能实现的、具备学习、创新及创造价值能力的功能。这门由Isa Fulford（OpenAI）和Andrew Ng（DeepLearning.AI）讲授的短期课程将介绍LLMs的工作原理，提供提示工程的最佳实践，并展示如何在各种任务的应用程序中使用LLM API，包括：概括总结（例如，为了简明扼要地概括用户评论）推理（例如，情感分类、主题提取）转换文本（例如，翻译、拼写与语法修正）扩展内容（例如，自动撰写电子邮件）此外，你还将学习编写有效提示的两个关键原则，如何系统性地设计优质提示，并学会构建自定义聊天机器人。|
|110|[GPT-4o，充当你的“第三只眼睛”，帮助盲人描述当前环境，打车](https://www.bilibili.com/video/BV1Kr421E7cS/)|GPT-4o，OpenAI的新一代旗舰模型，它能够实时跨音频、视觉和文本进行推理，本视频特别介绍来自@bemyeyes的安迪。|
|111|[GTC2023英伟达CEO黄仁勋主题演讲：AI、加速计算及其他领域的突破性进展 ](https://www.bilibili.com/video/BV1Y24y1E7sj/)|英伟达CEO黄仁勋揭晓一系列加速计算领域的突破性成果——涵盖从人工智能训练到部署，半导体到软件库，系统到云服务——这些成果将助力转型各行各业。|
|112|[Ilya 塑造世界的AI科学家](https://www.bilibili.com/video/BV14b4y1u7o3/)|Ilya Sutskever，作为ChatGPT背后的主要人工智能科学家之一，回顾了他的创始愿景和价值观。在2016年至2019年期间，当他参与开发聊天语言模型时，与电影制作人Tonje Hessen Schei的对话中，他阐述了自己的个人哲学，并对这项已经在塑造我们世界的科技做出了惊人的预测。在当前全球就安全与监管问题进行辩论的背景下，反思他的理念，我们既考虑到了人工智能技术带来的机遇，也考虑到了其可能产生的后果。Ilya讨论了他最终目标——人工通用智能（AGI），即“一个能在任何工作或任务上媲美甚至超越人类的计算机系统”，并质疑AGI的军备竞赛对人类而言是好是坏。|
|113|[LangChain 作者 Harrison 谈 AI 智能体](https://www.bilibili.com/video/BV1Wq421A7ZU/)|Harrison 对于智能体发展的三个热门领域“规划、用户体验和记忆”给出了自己的观点和疑问,虽然还没有明确的答案,但这些领域值得我们继续探索。他非常期待与大家讨论这些问题。|
|114|[NVIDIA CEO 黄仁勋 GTC Fall 2022 主题演讲](https://www.bilibili.com/video/BV1Te4y1H7i4/)|英伟达CEO黄仁勋发布新的Ada Lovelace GPU架构，其计算平台的最新进展，以及推动AI时代与元宇宙发展的新云服务——这些都将助力于变革各行各业。|
|115|[OpenAI CEO Sam Altman 谈 GPT-4、ChatGPT 和 AI 的未来](https://www.bilibili.com/video/BV1cM4y1U7WV/)|2023年3月26日，在 Lex Fridman的一期播客中，OpenAI CEO Sam Altman 谈论了 GPT-4、ChatGPT 和 AI 的未来。|
|116|[OpenAI CEO Sam Altman在彭博科技峰会谈AI的未来](https://www.bilibili.com/video/BV1Hk4y1T7hR/)|6月23日，OpenAI的首席执行官及联合创始人Sam Altman在彭博科技峰会上与彭博社的Emily Chang讨论了OpenAI及其产品的爆炸式增长，以及一个人工智能普及的未来可能呈现的图景。|
|117|[OpenAI CEO 山姆·阿尔特曼访谈-AI将带来更多新机会](https://www.bilibili.com/video/BV1vh4y1o73d/)|OpenAI的首席执行官萨姆·阿尔特曼（Sam Altman）在接受ABC新闻的丽贝卡·贾维斯（Rebecca Jarvis）采访时说，人工智能将重塑社会，并承认了其中的风险：“我认为人们应该感到高兴，我们对这一点有些害怕。”|
|118|[OpenAI CEO&COO Sam Altman&Brad Lightcap 最新20vc播客访谈](https://www.bilibili.com/video/BV1rq421c7Ac/)|Sam Altman担任OpenAI的首席执行官，该公司致力于确保通用人工智能惠及全人类。OpenAI是历史上扩张速度最快的公司之一，估值达到900亿美元，年收入超过20亿美元。在加入OpenAI之前，Sam曾担任Y Combinator的总裁兼首席执行官，并对Airbnb、Stripe、Reddit、Pinterest、Asana等公司进行了天使投资。Brad Lightcap担任OpenAI的首席运营官，负责销售、市场拓展、合作与商业运作的惊人增长，目前公司收入已超过20亿美元。加入OpenAI之前，Brad是Y Combinator的投资人，正是在那里他结识了Sam。在此之前，他在Dropbox领导财务和运营工作。|
|119|[OpenAI DevDay 主题演讲 by Sam Altman](https://www.bilibili.com/video/BV1ca4y1Q7cs/)|OpenAI DevDay的开幕主题演讲。这是OpenAI首次举办的开发者大会，我们召集全球各地的开发者，共同参与这场线下盛会，学习最前沿的人工智能进展，并探索未来的无限可能。|
|120|[OpenAI GPT-4o 的实时翻译](https://www.bilibili.com/video/BV16t421M7qB/)||
|121|[OpenAI Sam Altman最新访谈：GPT-4o和AI未来](https://www.bilibili.com/video/BV19y411Y7oc/)||
|122|[OpenAI Sora视频生成模型团队最新访谈](https://www.bilibili.com/video/BV1JZ421H7Bg/)||
|123|[OpenAI 传奇AI科学家Andrej Karpathy深度访谈：AI和生命的意义](https://www.bilibili.com/video/BV1tN41117vE/)|Andrej Karpathy是一位传奇的人工智能研究者、工程师及教育家。他曾任特斯拉的AI部门总监，是OpenAI的创始成员之一，同时也是斯坦福大学的教育工作者。|
|124|[OpenAI大神首席科学家Ilya 2023年11月访谈](https://www.bilibili.com/video/BV1Kz4y1K7zR/)||
|125|[Suno.AI CEO红杉大会发言&现场音乐创作](https://www.bilibili.com/video/BV1iz421y7Cd/)|Suno联合创始人Mikey Shulman展示如何仅通过基于文本的提示来利用人工智能生成任何风格或流派的音乐。|
|126|[埃隆·马斯克：战争、人工智能、外星人、政治、物理、电子游戏与人类   Lex Fridman 播客](https://www.bilibili.com/video/BV1zu4y1t7LU/)|在Lex Fridman播客第400集中，Lex Fridman与Elon Musk进行了一场内容广泛的对话，涉及战争、人工智能（AI）、外星生命、政治、物理学、电子游戏以及人类的未来等多个领域。以下是一些关键点概述：战争与和平：Musk反思历史教训，特别是两次世界大战之后的情况，指出将一战责任单一归咎于德国是导致二战的部分原因。他认为，明显的善意行为可以作为一种地缘政治策略来防止战争和促进和平。他还讨论了人性的复杂性，提出完全消除仇恨可能并不理想，因为仇恨的存在有其进化的原因。AI与社会：Musk探讨了AI对社会产生积极影响的潜力，提及了Grok AI助手批评他并提供深刻分析的能力。他还触及了根据个人喜好推荐电影等用户偏好的准确预测，这对于AI系统来说是一个挑战。特斯拉与技术：Musk谈论了设计Cybertruck等产品所涉及的工程壮举，以及制造方面的挑战，目标是让Optimus机器人等产品价格低于汽车。他还提到了一个有趣的轶事，即测试音爆对海豹的影响，以确保火箭发射时不会干扰野生动物。维基百科与社区笔记：Musk将维基百科的等级结构与社区笔记的去中心化性质进行对比，他认为社区笔记是一个更为民主的信息共享平台。他强调了社区笔记的开源特性，使其不易受到操纵。个人挑战与观点：Musk坦诚面对自己所遇到的困难，承认尽管外界普遍看法不同，但他的生活并非总是令人羡慕。他讨论了AI超越人类理解的潜力，以及在发展AI时需要谨慎行事。从错误中学习：Musk承认了自己在产品发布时间预测等方面的失误，并谈到了从Grok那里收到的既幽默又批判性的反馈。生成式AI及其局限性：虽然总结中没有直接提及，但从上下文推断，对话很可能触及了大型语言模型（LLMs）和生成式AI的能力及局限性，鉴于Musk对AI及其社会影响的兴趣。整体而言，这场对话概括了Musk对全球问题、技术进步以及个人哲学的多面思考，提供了一个坦率而全面的探索，反映了他广泛的兴趣和事业。|
|127|[从头开始用代码构建GPT - 大神Andrej Karpathy 的“神经网络从Zero到Hero 系列”之七](https://www.bilibili.com/video/BV1CP41147Cw/)|我们构建了一个生成性预训练的变压器模型（Generatively Pretrained Transformer，简称GPT），这一模型遵循了论文《注意力就是你所需要的》（"Attention is All You Need"）以及OpenAI的GPT-2和GPT-3的设计理念。我们讨论了这一模型与ChatGPT之间的联系，后者已经风靡全球。我们还见证了GitHub Copilot（本身也是一个基于GPT的工具）协助我们编写GPT模型的过程（Meta :D）。我建议大家先观看之前的“makemore”系列视频，以便熟悉自回归语言建模框架以及张量和PyTorch神经网络(nn)的基础知识，这些内容在本视频中被视为已知。|
|128|[Andrej Karpathy最新红杉AI活动演讲问答](https://www.bilibili.com/video/BV1jq421P7HH/)|Andrej Karpathy，OpenAI的创始成员及前特斯拉人工智能高级总监，在红杉资本的AI Ascent活动中与Stephanie Zhan对话，讨论了构建一个更加开放和充满活力的人工智能生态系统的的重要性，分享了与Elon Musk共事的经历，并探讨了如何使利用人工智能进行创造变得更加普及和易访问。|
|129|[Stephen Wolfram 2023年8月MIT讲座“ChatGPT影响讨论会”](https://www.bilibili.com/video/BV1RN41187Yd/)|"ChatGPT及其他大型语言模型对物理研究与教育的影响（2023）"活动组织者：Kevin Burdge, Joshua Borrow, Mark Vogelsberger 第三场会议："大型语言模型在教学与管理中的应用"|
|130|[阿里云最新的AI绘画创作大模型，通义万相核心功能演示](https://www.bilibili.com/video/BV1vk4y1P7ai/)|作为阿里云最新的AI绘画创作大模型，通义万相具备语义理解和图片生成实力，不仅支持水彩、扁平插画、油画、中国画等风格图像生成，还能实现相似图片创作和图像风格迁移，并将应用于艺术设计、电商、游戏和文创等多种场景。快来看看这位AI绘画界的新将表现如何叭~！|
|131|[跟 GPT-4o 分享自家狗狗的喜悦！](https://www.bilibili.com/video/BV1Kf42117Hv/)||
|132|[谷歌首席执行官桑达尔·皮查伊（Sundar Pichai）与人工智能的未来](https://www.bilibili.com/video/BV1wC41177iE/)|2024年5月9日，谷歌和Alphabet首席执行官桑达尔·皮查伊（Sundar Pichai）与彭博原创主持人兼执行制片人艾米丽·张（Emily Chang）独家坐下来讨论搜索的未来，从头开始重建谷歌的AI模型Gemini，与Microsoft和OpenAI竞争，谷歌的文化挑战，以及他的成长经历如何为这一刻做好准备。|
|133|[黄仁勋揭示塑造未来的 AI 技术   NVIDIA GTC 2024 主题演讲](https://www.bilibili.com/video/BV1rt421G7SJ/)|观看NVIDIA首席执行官黄仁勋的GTC主题演讲，了解正在塑造我们未来的AI进展的所有公告。|
|134|[黄仁勋与OpenAI首席科学家Ilya Sutskever的炉边谈话](https://www.bilibili.com/video/BV1Tc411L7UA/)|这是“炉边对话：Ilya Sutskever与Jensen Huang共话当今AI与未来愿景（2023年3月）”的精华版。在这个视频中，我精心挑选了原时长一小时谈话中的前10个问题，并将其浓缩至大约30多分钟。此外，我还为Jensen向Ilya提出的这些问题制作了一个时间轴，并附上了相关的研究论文。|
|135|[揭秘OpenAI成长史：顶级资本与科技大佬的理想主义，冲突，抉择与权力斗争；马斯克、奥特曼、纳德拉与比尔·盖茨等人的背后故事](https://www.bilibili.com/video/BV1ka4y1V7uP/)|OpenAI成长史：顶级资本与科技大佬的理想主义，冲突，抉择与权力斗争；马斯克、奥特曼、纳德拉与比尔·盖茨等人的背后故事。这期视频我们再深度回顾OpenAI崛起的成长史：这是一个充满了细节的精彩故事，关于一群拥有纯粹信仰的顶级AI研究员，关于马斯克间接触发了OpenAI的商业化路径，关于OpenAI核心领导人物Sam Altman放弃理想主义去投靠微软，关于微软CEO纳德拉与创始人比尔-盖茨之间的较量，关于ChatGPT惊艳世人背后不为人知的故事。OpenAI崛起这个故事，将是决定人类未来最重要的故事之一|
|136|[李沐 DALL·E 2（内含扩散模型介绍）【论文精读】](https://www.bilibili.com/video/BV17r4y1u77B/)||
|137|[马克·扎克伯格：元宇宙中的首次采访 - Lex Fridman播客](https://www.bilibili.com/video/BV1qN4y1f7Sg/)|Lex Fridman与Mark Zuckerberg在元宇宙中进行了一次对话，他们讨论了在线人际交往的未来以及虚拟现实(VR)和混合现实(MR)技术的能力。尽管物理上相隔甚远，Lex和Mark却以逼真的虚拟形象在一个共享的虚拟空间中互动，通过先进的空间音频和面部表情复制技术强调了现场感和真实感的实现。Mark Zuckerberg提到，每一次新头戴设备的发布都带来了显著的升级，最近的焦点集中在混合现实的集成上。这项技术允许用户将数字对象和人物叠加到现实世界中，创造出沉浸而安全的体验，让用户在享受三维沉浸式环境的同时，不必担心物理环境的限制。Zuckerberg指出，MR可以通过减少在享受3D沉浸式环境时意外碰到实体物体的担忧，来增强游戏和健身体验。他们还讨论了虚拟交互的社会心理层面，包括可能加深亲密感和信任感，模拟面对面交流的能力。Zuckerberg强调了社交网络从基于文本的平台发展到图片分享，再到如今越来越丰富和生动的媒介，如视频和交互式VR环境的演变。他思考了在未来数字通信中，逼真与富有表现力的卡通虚拟形象之间的平衡，以及在一个匿名可能降低积极行为动机的世界里，确保健康网络行为的挑战。总的来说，这次对话强调了元宇宙在改变我们社交、工作和自我表达方式方面的变革潜力，模糊了数字世界与物理世界的界限，同时也认识到需要谨慎考虑伦理和社会影响。|
|138|[马克·扎克伯格：Meta公司、Facebook、Instagram和WhatsApp的人工智能未来 - Lex Fridman播客](https://www.bilibili.com/video/BV17V4y1m7CW/)||
|139|[彭博社探秘OpenAI总部   访谈CTO Mira Murati和早期投资人Reid Hoffmanp](https://www.bilibili.com/video/BV1jW4y1Q7jU/)|在本期《The Circuit》节目中，Emily Chang造访了OpenAI未来感十足的办公室，与公司首席技术官Mira Murati（在Sam Altman于2023年11月离职后接任首席执行官）会面。OpenAI是热门产品ChatGPT和Dall-E的背后推手。Murati探讨了人工智能普及带来的光明前景以及潜在风险。为了深入了解席卷硅谷的人工智能热潮，Chang与OpenAI的早期投资者及LinkedIn联合创始人Reid Hoffman会面，获取他对OpenAI早期历程的见解，以及风险投资资金的下一个流向。|
|140|[山姆奥特曼：OpenAI, GPT-5, Sora, Board Saga, 马斯克，伊利亚, 权利 和 AGI   - Lex Fridman播客](https://www.bilibili.com/video/BV1DC411h7oZ/)|Lex Fridman与OpenAI首席执行官Sam Altman的访谈深入探讨了人工智能(AI)的发展及其影响的广泛主题。以下是访谈要点概览：AI安全与目标一致性：Sam Altman表达了对AI安全的关注，以及确保AI目标与人类价值观相一致的重要性。他强调AI研究应优先考虑安全措施，以防潜在的误用，并确保对社会有益的结果。经济颠覆性影响：Altman讨论了AI对各行业乃至整个经济造成重大颠覆的可能性，预测了因特定任务自动化而导致的就业市场转变。他建议社会应通过考虑诸如全民基本收入(UBI)政策和教育体系的重新思考等方式，为这一转型做好准备。AI进展：对话突出展示了AI领域的最新进展，包括自然语言处理、图像识别和决策算法的突破。Altman认可了像GPT和DALL-E这样的模型的惊人能力，同时也警告了这些系统中存在的局限性和潜在偏见。伦理考量：Altman强调了开发AI过程中的伦理考量，特别是在数据隐私、算法公平性和防止AI生成的误导信息方面。他提倡透明的AI开发和负责任的部署实践。OpenAI的未来：Altman谈论了OpenAI的愿景，即在推动AI研究边界的同时，注意社会影响。他提到，目标是创建能够增强而非替代人类智能的AI系统，促进协作和创新。AI治理：讨论触及了全球协调和监管框架的需求，以规范AI的开发和使用。Altman建议政府、私营组织和公众应共同制定标准和指南，确保AI的安全和道德部署。个人反思：Altman分享了自己在科技行业的个人历程，回顾了在Y Combinator的时光以及在领导角色中学到的教训。他还谈到了在利用AI潜力行善时，理想主义与实用主义之间的平衡。总体而言，这次访谈全面概述了Sam Altman对于AI当前状态及未来前景的看法，强调了负责任的创新和积极规划对于正面利用AI潜力的必要性。|
|141|[微软Build2024   CEO萨提亚·纳德拉主旨演讲完整版](https://www.bilibili.com/video/BV1Dn4y1d7tL/)|Satya Nadella在2024年微软Build大会上的全程主题演讲|
|142|[吴恩达、李飞飞探讨以人为本的人工智能](https://www.bilibili.com/video/BV19d4y1f7F7/)|吴恩达与李飞飞教授坐下来讨论人工智能的过去和现状，以及一些仍有待回答的“大胆问题”。 如果您想开始学习 AI，那么由 Stanford Online 和 DeepLearning.AI 开发的新 Coursera 机器学习专业化是一个完美的起点。|
|143|[吴恩达2023年最新演讲：人工智能将带来哪些机遇？](https://www.bilibili.com/video/BV1Yu411A7v9/)|人工智能（AI）领域的著名学者、斯坦福大学客座教授、前百度首席科学家吴恩达，在题为“Opportunities in AI - 2023”的最新演讲中，详细介绍了生成式 AI 将带来的诸多机遇与挑战/风险。这场在斯坦福大学 Cemex 礼堂举行的讲座内容包括：1）人工智能技术和工具的发展趋势2）监督学习3）生成式人工智能4）人工智能的应用5）人工智能的机遇6）创建初创企业的过程7）人工智能的风险与社会影响|
|144|[吴恩达最新红杉AI活动演讲 ：AI智能代理工作流的下一步](https://www.bilibili.com/video/BV19D421V7mc/)|DeepLearning.AI及AI Fund创始人吴恩达在红杉资本的AI Ascent活动中发表演讲，探讨了AI代理工作流程的下一步发展及其推动AI进步的巨大潜力——或许这一潜力甚至能超越即将到来的新一代基础模型的影响。|
|145|[一口气了解英伟达，芯片新王凭什么是他？](https://www.bilibili.com/video/BV18j411S7ST/)|在AI领域还处在一片混战当中时，一个亚洲人穿着皮夹克从乱军丛中杀出重围，靠卖"铲子"成了2023上半场的最大赢家。这是怎么回事儿？咱们来看看黄仁勋和英伟达的崛起之路，当然也少不了硬核的商业分析~|
|146|[智能崛起：生成式AI的未来](https://www.bilibili.com/video/BV1kr4y1o7ih/)|这个视频讨论了生成式人工智能的发展和应用。它强调了人类在评价和启发AI方面的重要性，以及人工智能对各行各业的影响。视频还探讨了智能助手、人机交互和机器创作的挑战和潜力。最后，视频提出了关于AI的安全性和伦理问题的思考，并呼吁人类与机器共同发展。|
|147|[Lester Holt 对话 OpenAI 的 Sam Altman 和 Airbnb 的 Brian Chesky](https://www.bilibili.com/video/BV1Xf421B73V/)|OpenAI的首席执行官Sam Altman和Airbnb的联合创始人及首席执行官Brian Chesky一同参加了NBC新闻主播Lester Holt的节目，讨论了人工智能带来的益处。他们探讨了深度伪造（deep fakes）、ChatGPT以及人工智能是如何演进的。|
|148|[【保姆级教程】百度文心智能体平台零基础AI开发课程](https://www.bilibili.com/video/BV1m64y1K7Pi)|文心智能体平台推出《百度文心智能体开发课程》，意在帮助开发者们顺利开发出自己的AI产品，课程中为大家提供了文心智能体平台介绍、智能体开发与上线、智能体快速冷启获流等详细的开发教程|
|149|[GPT-4官方介绍视频](https://www.bilibili.com/video/BV1KP411Z7be/)|OpenAI开发的多模态大型语言模型，是其GPT基础模型系列中的第四代产品。|
|150|[Pika 1.0官方介绍](https://www.bilibili.com/video/BV1tQ4y1x7Q5/)|用视频来实现灵感，让生活更富有创造力！|
|151|[《线性代数》教学视频 宋浩老师（2024年更新）](https://www.bilibili.com/video/BV1aW411Q7x1/)|线性代数是数学的一个分支，它的研究对象是向量，向量空间（或称线性空间），线性变换和有限维的线性方程组。向量空间是现代数学的一个重要课题；因而，线性代数被广泛地应用于抽象代数和泛函分析中；通过解析几何，线性代数得以被具体表示。线性代数的理论已被泛化为算子理论。由于科学研究中的非线性模型通常可以被近似为线性模型，使得线性代数被广泛地应用于自然科学和社会科学中。在机器学习中，线性代数主要用于构建和训练各种模型，如线性回归、逻辑回归、支持向量机等。这些模型在数据的特征提取、降维处理以及分类等方面发挥了重要作用。此外，线性代数也是构建神经网络的重要基础，特别是在深度学习中，矩阵运算和线性变换是处理复杂数据的关键步骤。|
|152|[《失控》](https://book.douban.com/subject/5375620/)|《失控》成书于1994年，作者是《连线》杂志的创始主编凯文·凯利。这本书所记述的，是他对当时科技、社会和经济最前沿的一次漫游，以及借此所窥得的未来图景。书中提到并且今天正在兴起或大热的概念包括：大众智慧、云计算、物联网、虚拟现实、敏捷开发、协作、双赢、共生、共同进化、网络社区、网络经济，等等。说它是一本“预言式”的书并不为过。其中必定还隐藏着我们尚未印证或窥破的对未来的“预言”。|
|153|[《奇点临近》](https://book.douban.com/subject/6855803/)|人工智能作为21世纪科技发展的最新成就，深刻揭示了科技发展为人类社会带来的巨大影响。本书结合求解智能问题的数据结构以及实现的算法，把人工智能的应用程序应用于实际环境中，并从社会和哲学、心理学以及神经生理学角度对人工智能进行了独特的讨论。本书提供了一个崭新的视角，展示了以人工智能为代表的科技现象作为一种“奇点”思潮，揭示了其在世界范围内所产生的广泛影响。本书全书分为以下几大部分：第一部分人工智能，第二部分问题延伸，第三部分拓展人类思维，第四部分推理，第五部分通信、感知与行动，第六部分结论。本书既详细介绍了人工智能的基本概念、思想和算法，还描述了其各个研究方向最前沿的进展，同时收集整理了详实的历史文献与事件。适合于不同层次和领域的研究人员及学生，是高等院校本科生和研究生人工智能课的课外读物，也是相关领域的科研与工程技术人员的参考书。|
|154|[《思考，快与慢》](https://book.douban.com/subject/10785583/)|在书中，卡尼曼会带领我们体验一次思维的终极之旅。他认为，我们的大脑有快与慢两种作决定的方式。常用的无意识的“系统1”依赖情感、记忆和经验迅速作出判断，它见闻广博，使我们能够迅速对眼前的情况作出反应。但系统1也很容易上当，它固守“眼见即为事实”的原则，任由损失厌恶和乐观偏见之类的错觉引导我们作出错误的选择。有意识的“系统2”通过调动注意力来分析和解决问题，并作出决定，它比较慢，不容易出错，但它很懒惰，经常走捷径，直接采纳系统1的直觉型判断结果。为了使读者真切体会到系统1和系统2这两个主角的特点，卡尼曼介绍了很多经典有趣的行为实验，指出我们在什么情况下可以相信自己的直觉，什么时候不能相信；指导我们如何在商场、职场和个人生活中作出更好的选择，以及如何运用不同技巧来避免那些常常使我们陷入麻烦的思维失误。本书将会彻底改变你对思考的看法。|
|155|[《图灵的秘密》](https://book.douban.com/subject/10779604/)|图灵机是英国数学家阿兰•图灵提出的一种抽象计算模型，本书深入剖析了图灵这篇描述图灵机和可计算性的原始论文《论可计算数及其在判定性问题上的应用》。书中在详解论文的同时，也附带了大量的历史背景资料、图灵的个人经历，以及图灵机对于人们理解计算机、人类意识和宇宙所产生的影响。 本书适合所有计算机科学专业的学生、程序员或其他技术人员，同时也适合欲了解图灵生平及其构建图灵机的思维的读者阅读。|
|156|[《数学之美 （第二版）》](https://book.douban.com/subject/26163454/)|几年前，“数学之美”系列文章原刊载于谷歌黑板报，获得上百万次点击，得到读者高度评价。读者说，读了“数学之美”，才发现大学时学的数学知识，比如马尔可夫链、矩阵计算，甚至余弦函数原来都如此亲切，并且栩栩如生，才发现自然语言和信息处理这么有趣。在纸本书的创作中，作者吴军博士几乎把所有文章都重写了一遍，为的是把高深的数学原理讲得更加通俗易懂，让非专业读者也能领略数学的魅力。读者通过具体的例子学到的是思考问题的方式 —— 如何化繁为简，如何用数学去解决工程问题，如何跳出固有思维不断去思考创新。第二版增加了针对大数据和机器学习的内容，以便满足人们对当下技术的学习需求；同时，根据专家和读者的反馈更正了一些错漏，并更新了部分内容。|
|157|[《超级智能》](https://book.douban.com/subject/26308917/)|当机器智能超越了人类智能时会发生什么？人工智能会拯救人类还是毁灭人类？作者提到，我们不是这个星球上速度最快的生物，但我们发明了汽车、火车和飞机。我们虽然不是最强壮的，但我们发明了推土机。我们的牙齿不是最锋利的，但我们可以发明比任何动物的牙齿更坚硬的刀具。我们之所以能控制地球，是因为我们的大脑比即使最聪明的动物的大脑都要复杂得多。如果机器比人类聪明，那么我们将不再是这个星球的主宰。当这一切发生的时候，机器的运转将超越人类。人类大脑拥有一些其他动物大脑没有的功能。正是这些独特的功能使我们的种族得以拥有主导地位。如果机器大脑在一般智能方面超越了人类，那么这种新兴的超级智能可能会极其强大，并且有可能无法控制。正如现在大猩猩的命运更多的掌握在人类手中而不是自己手中一样，人类未来的命运也会取决于机器超级智能的行为。但是，我们有一项优势：我们有机会率先采取行动。是否有可能建造一个种子人工智能，创造特定的初始条件，使得智能爆发的结果能够允许人类的生存？我们如何实现这种可控的引爆？作者相信，超级智能对我们人类将是一个巨大的威胁。在这本书中，作者谈到了超级智能的优势所带来的风险，也谈到了人类如何解决这种风险。作者认为，他的这本书提到的问题将是我们人类所面临的最大风险。这本书目标宏大，且有独创性，开辟了人工智能领域的新道路。本书会带你开启一段引人入胜的旅程，把你带到对人类状况和智慧生命未来思索的最前沿。尼克•波斯特洛姆的新书为理解人类和智慧生命的未来奠定了基础，不愧是对我们时代根本任务的一次重新定义。|
|158|[《科技想要什么》](https://book.douban.com/subject/26685018/)|《科技想要什么》一书中，凯文·凯利预测了未来数十年科技的12种趋势，包括创造大脑这一得寸进尺之举。不过，为了让人类创造的世界实现收益最大化，需要对这种全球体系产生的问题和代价保持敏感。凯利详细讲述了值得我们学习的阿米什“早期使用者”和其他批判科技自我主义倾向的人所具有的智慧。凯利的新科技理论提供了三种实践经验：通过倾听科技的需求，我们和我们的孩子可以更加出色地做好准备，迎接必将到来的科技；通过采用主动融合原则，我们可以驾驭科技，使之发挥大作用；通过遵从这种类生命系统的长期规则，我们可以获得它的全部馈赠。凯利令人吃惊地宣称，现在人类已定义的生命形态仅包括植物、动物、原生生物、真菌、原细菌、真细菌六种，但技术的演化和这六种生命体的演化惊人相似。技术应该是生命的第七种存在方式。技术是生命的延伸，它不是独立于生命之外的东西。|
|159|[《机器学习》](https://book.douban.com/subject/26708119/)|机器学习是计算机科学与人工智能的重要分支领域。本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础知识的各方面。为了使尽可能多的读者通过本书对机器学习有所了解，作者试图尽可能少地使用数学知识。然而，少量的概率、统计、代数、优化、逻辑知识似乎不可避免。因此，本书更适合大学三年级以上的理工科本科生和研究生，以及具有类似背景的对机器学习感兴趣的人士。为方便读者，本书附录给出了一些相关数学基础知识简介。全书共16章，大致分为3个部分：第1部分（第1～3章）介绍机器学习的基础知识；第2部分（第4～10章）讨论一些经典而常用的机器学习方法（决策树、神经网络、支持向量机、贝叶斯分类器、集成学习、聚类、降维与度量学习）；第3部分（第11～16章）为进阶知识，内容涉及特征选择与稀疏学习、计算学习理论、半监督学习、概率图模型、规则学习以及强化学习等。前3章之外的后续各章均相对独立，读者可根据自己的兴趣和时间情况选择使用。根据课时情况，一个学期的本科生课程可考虑讲授前9章或前10章;研究生课程则不妨使用全书。书中除第1章外，每章都给出了十道习题。有的习题是帮助读者巩固本章学习，有的是为了引导读者扩展相关知识。一学期的一般课程可使用这些习题，再辅以两到三个针对具体数据集的大作业。带星号的习题则有相当难度，有些并无现成答案，谨供富有进取心的读者启发思考。本书可作为高等院校计算机、自动化及相关专业的本科生或研究生教材，也可供对机器学习感兴趣的研究人员和工程技术人员阅读参考。|
|160|[《情感机器》](https://book.douban.com/subject/26683602/)|大脑如何产生新想法？思维如何产生，又是如何运作的？意识缘何形成？什么是情感、感觉、想法？如果将人类大脑看成一台机器，那么这是否有益于我们设计出能够像人一样能理解、会思考的高级人工智能——情感机器？情感是人类特有的一种思维方式，如果机器具备了情感，是不是就可以取代人类？在本书中，人工智能之父马文·明斯基有力地论证了：情感、直觉和情绪并不是与众不同的东西，而只是一种人类特有的思维方式。也同时揭示了为什么人类思维有时需要理性推理，而有时又会转向情感的奥秘。通过对人类思维方式建模，他为我们剖析了人类思维的本质，为大众提供了一幅创建能理解、会思考、具备人类意识、常识性思考能力，乃至自我观念的情感机器的路线图。|
|161|[《机器之心》](https://book.douban.com/subject/26745150/)|微软创始人比尔·盖茨曾经称雷·库兹韦尔是“我知道在预测人工智能上最厉害的人”。过去30年他对未来预测的准确率超过了86%。在这本书中，雷·库兹韦尔阐述了极其令人信服的大胆预测：未来的世界，人类和机器将难分彼此，人类将不再是万物之灵。电脑将比人脑有高一万倍的智能。量子计算将引爆技术未来。机器不仅拥有智能，而且拥有心灵，将具有人类的意识、情绪和欲望。人类身体中植入了用生物工程和纳米材料制成的电脑芯片、人造器官，将比现代人类更长寿（甚至长生不老），有更强的学习能力，更灵敏的视觉和听觉。虚拟现实有可能使人机发生“恋爱”……你会认为这不可能？当人类不再继续生活在树上，并且吃烤熟了的东西的时候，有某个猴子也是和你一样看待人类进化的。|
|162|[《未来简史》](https://book.douban.com/subject/26943161/)|进入21世纪后，曾经长期威胁人类生存、发展的瘟疫、饥荒和战争已经被攻克，智人面临着新的待办议题：永生不老、幸福快乐和成为具有“神性”的人类。在解决这些新问题的过程中，科学技术的发展将颠覆我们很多当下认为无需佐证的“常识”，比如人文主义所推崇的自由意志将面临严峻挑战，机器将会代替人类做出更明智的选择。更重要的，当以大数据、人工智能为代表的科学技术发展的日益成熟，人类将面临着从进化到智人以来zui大的一次改变，绝大部分人将沦为“无价值的群体”，只有少部分人能进化成特质发生改变的 “神人”。未来，人类将面临着三大问题：生物本身就是算法，生命是不断处理数据的过程；意识与智能的分离；拥有大数据积累的外部环境将比我们自己更了解自己。如何看待这三大问题，以及如何采取应对措施，将直接影响着人类未来的发展。|
|163|[《人工智能》](https://book.douban.com/subject/27015112/)|当人工智能时代成为必然，《人工智能》一书告诉我们：个人应该做些什么，才能避免被AI取代？企业应该如何升级，才能在新的商业变局到来前抓住先机？我们无需担忧和惧怕人工智能时代的到来，我们所要做的，应当是尽早认清AI与人类的关系，了解变革的规律，更好地拥抱新时代的到来。|
|164|[《深度学习》](https://book.douban.com/subject/27087503/)|《深度学习》由全球知名的三位专家Ian Goodfellow、Yoshua Bengio 和Aaron Courville撰写，是深度学习领域奠基性的经典教材。全书的内容包括3个部分：第1部分介绍基本的数学工具和机器学习的概念，它们是深度学习的预备知识；第2部分系统深入地讲解现今已成熟的深度学习方法和技术；第3部分讨论某些具有前瞻性的方向和想法，它们被公认为是深度学习未来的研究重点。《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。|
|165|[《游戏人工智能》](https://book.douban.com/subject/27154117/)|游戏中的人工智能（AI）开发是游戏研发中最具挑战性的任务之一，而本书汇集了与游戏人工智能开发有关的知识，借助这些知识，程序员能够开发出有趣的AI 角色，为玩家带来美妙的游戏体验。本书分为7 个部分共48 章，分别讨论了通用智能、体系架构、运动与寻路、战略与战术、agent 意识与知识表征、竞速以及其他领域的游戏AI 技术。读者可以以本书作为路线图，了解在智能游戏方面哪些技术已经被成功使用，哪些具有很大的潜力。本书的作者都是游戏人工智能的专家，在此行业摸爬滚打多年，其观点和技术均在自身产品中做过验证，因而有很高的参考价值。其中有一些甚至提供了源码，可供读者方便地应用到自己开发的游戏程序中。对于希望为玩家带来引人入胜的游戏体验的开发者，本书非常值得一读。|
|166|[《智慧的疆界》](https://book.douban.com/subject/30379536/)|这是一部对人工智能充满敬畏之心的匠心之作，由《深入理解Java虚拟机》作者耗时一年完成，它将带你从奠基人物、历史事件、学术理论、研究成果、技术应用等5个维度全面读懂人工智能。本书以时间为主线，用专业的知识、通俗的语言、巧妙的内容组织方式，详细讲解了人工智能这个学科的全貌、能解决什么问题、面临怎样的困难、尝试过哪些努力、取得过多少成绩、未来将向何方发展，尽可能消除人工智能的神秘感，把阳春白雪的人工智能从科学的殿堂推向公众面前。|
|167|[《复杂》](https://book.douban.com/subject/30171338/)|蚂蚁在组成群体时为何会表现出如此的精密性和具有目的性？数以亿计的神经元是如何产生出像意识这样极度复杂的事物？是什么在引导免疫系统、互联网、全球经济和人类基因组等自组织结构？这些都是复杂系统科学尝试回答的迷人而令人费解的问题的一部分。理解复杂系统需要有全新的方法.需要超越传统的科学还原论，并重新划定学科的疆域。借助于圣塔菲研究所的工作经历和交叉学科方法，复杂系统的前沿科学家米歇尔以清晰的思路介绍了复杂系统的研究，横跨生物、技术和社会学等领域，并探寻复杂系统的普遍规律，与此同时，她还探讨了复杂性与进化、人工智能、计算、遗传、信息处理等领域的关系。|
|168|[《生命3.0》](https://book.douban.com/subject/30262617/)|《生命3.0》一书中，作者迈克斯·泰格马克对人类的终极未来进行了全方位的畅想，从我们能活到的近未来穿行至1万年乃至10 亿年及其以后，从可见的智能潜入不可见的意识，重新定义了“生命”“智能”“目标”“意识”，并澄清了常见的对人工智能的误解，将帮你构建起应对人工智能时代动态的全新思维框架，抓住人类与人工智能共生演化的焦点。迈克斯·泰格马克不仅以全景视角探讨了近未来人工智能对法律、战争、就业和社会带来的影响，还将目光投向了这场变革更为深远之处：在未来的1万年乃至10亿年及其以后，我们能否与人工智能实现共生与繁荣？宇宙生命发展的终极物理极限是什么？更为重要的是，我们如何在这场变革中迎来重生，同时又不会陷入危机，丧失生而为人的意义？《生命3.0》这本书将是你人工智能时代的思考利器。此书对未来生命的终极形式进行了大胆的想象：生命已经走过了1.0生物阶段和2.0文化阶段，接下来生命将进入能自我设计的3.0科技阶段。|
|169|[《深度学习入门》](https://book.douban.com/subject/30270959/)|本书是深度学习真正意义上的入门书，深入浅出地剖析了深度学习的原理和相关技术。书中使用Python3，尽量不依赖外部库或工具，从基本的数学知识出发，带领读者从零创建一个经典的深度学习网络，使读者在此过程中逐步理解深度学习。书中不仅介绍了深度学习和神经网络的概念、特征等基础知识，对误差反向传播法、卷积神经网络等也有深入讲解，此外还介绍了深度学习相关的实用技巧，自动驾驶、图像生成、强化学习等方面的应用，以及为什么加深层可以提高识别精度等“为什么”的问题。|
|170|[《万物皆数》](https://book.douban.com/subject/30281339/)|你观察过鹦鹉螺的外壳吗？注意过松果表面的螺纹吗？侦探剧中确定嫌疑人位置的三角定位是什么原理？阿尔法狗的算法与数学有哪些关联？在史前时代，数学是为了实际应用而出现的。数字被用来计算羊群的数量，几何图形被用来测量田地并绘制道路。自那时以来，很多艺术家、创作者、匠人或者单纯的梦想家和好奇者，在无意中踏入了数学的领地。他们是不自觉的数学家，是人类历史上最早的提问者、最早的研究者、最早的头脑风暴践行者。如果想了解数学到底是什么，我们就必须追随他们的脚步，因为一切正是因为他们而起。本书将引领我们穿越回史前时代、四大文明古国、欧洲中世纪与文艺复兴时期，也会带领我们漫步于巴黎卢浮宫与发现宫。作者巧妙运用历史学的方法，构建了无数历史或现今的场景，将数学从亭台楼阁之上带入我们的日常生活，将数学之美化为一篇篇优美的文字，娓娓道来。“大部分人是喜欢数学的，但问题在于很多人并不了解这门学科。”如果你从来没有了解过数学，如果你讨厌数学，何不考虑给这门学科第二次机会呢？跟随作者回顾这门人类历史上最不可思议、最迷人的学科发展至今的曲折历程，认识那些通过意外发现和奇思妙想而创造了历史的人。你一定不会后悔的。|
|171|[《深度学习-智能时代的核心驱动力量》](https://book.douban.com/subject/30425822/)|全球科技巨头纷纷拥抱深度学习，自动驾驶、AI医疗、语音识别、图像识别、智能翻译以及震惊世界的AlphaGo，背后都是深度学习在发挥神奇的作用。深度学习是人工智能从概念到繁荣得以实现的主流技术。经过深度学习训练的计算机，不再被动按照指令运转，而是像自然进化的生命那样，开始自主地从经验中学习。本书作者特伦斯·谢诺夫斯基是全球人工智能十大科学家之一、深度学习先驱及奠基者，亲历了深度学习在20世纪70年代到90年代的寒冬。但他和一众开拓者，利用大数据和不断增强的计算能力，终于在神经网络算法上取得重大突破，实现了人工智能井喷式的发展。作为深度学习领域的通识作品，本书以恢弘的笔触，通过3个部分全景展现了深度学习的发展、演变与应用，首次以亲历者视角回溯了深度学习浪潮在过去60年间的发展脉络与人工智能的螺旋上升，并前瞻性地预测了智能时代的商业图景。|
|172|[《大脑的故事》](https://book.douban.com/subject/33383607/)|人体是一个复杂而精美的杰作，而大脑是其中最为神秘的存在。我们通过它在世界上来往穿梭、做决策，放飞想象力。 我们的美梦、清醒时的人生，都源自它飞速运动的数十亿细胞。我们历经悲喜、绚丽多彩的完整人生，都发生在这区区 1.4 千克重的东西里。而如此重要的大脑，一直像一个难解的谜题，困住了无数顶尖的科学家，也被我们所忽视。在《大脑的故事》中，享誉全球的脑科学家，《西部世界》科学顾问大卫·伊格曼，用一篇篇引人入胜的故事，为你展现脑科学领域的前沿成果，带你领略大脑宇宙的奇妙之处。|
|173|[《认知》](https://book.douban.com/subject/34917699/)|本书是著名心理学家和人工智能开创者赫伯特·西蒙关于人类认知的作品。本书介绍了人的认知结构，包括注意力、记忆等方面，然后分析了人们思维过程中问题解决的途径和策略。书中进一步分析了对于复杂问题，专家和普通人不同的心理表征，以及应该如何应对复杂问题。最后，作者介绍了学习的基本原理和过程，并说明如何探索发现新规律。无论是关注人工智能还是关注心理学的读者，本书都是不可多得的经典读物。|
|174|[《创造性思维》](https://book.douban.com/subject/35009860/)|所有教育都是面向未来的，在人工智能时代呼啸而来之际，作为教育工作者，我们有必要重新思考，什么才是适应未来发展教育理念？马文·明斯基作为人工智能领域的开创者，曾投身于 OLPC（每个孩子一台笔记本电脑）项目，试图将计算机技术交到全世界儿童手中。本书中有五篇文章来自这个项目，在这些文章中，马文提出了他对于未来教育的理念和见解，指出传统教育更多的是提供思维的内容，而学习者更需要的其实是思维的方法与工具。在马文看来，学习者是完全活跃的主体，是他们自己思维的创造者。正因为如此，学习者需要在完成任务的过程中，不断磨砺自己的思维技巧，从而养成创造性思维，提升自己解决新问题的能力。|
|175|[《深入浅出神经网络与深度学习》](https://book.douban.com/subject/35128111/)|本书深入讲解神经网络和深度学习技术，侧重于阐释深度学习的核心概念。作者以技术原理为导向，辅以贯穿全书的MNIST手写数字识别项目示例，介绍神经网络架构、反向传播算法、过拟合解决方案、卷积神经网络等内容，以及如何利用这些知识改进深度学习项目。学完本书后，读者将能够编写Python代码解决复杂的模式识别问题。这是一本非常好的深度学习入门书，相信一定会得到大家的喜爱。|
|176|[《机器学习实战（原书第2版）》](https://book.douban.com/subject/35218199/)|这本机器学习畅销书基于TensorFlow 2和Scikit-Learn的新版本进行了全面更新，通过具体的示例、非常少的理论和可用于生产环境的Python框架，从零帮助你直观地理解并掌握构建智能系统所需要的概念和工具。全书分为两部分。第一部分介绍机器学习基础，涵盖以下主题：什么是机器学习，它试图解决什么问题，以及系统的主要类别和基本概念；第二部分介绍神经网络和深度学习，涵盖以下主题：什么是神经网络以及它们有什么用，使用TensorFlow和Keras构建和训练神经网络的技术，以及如何使用强化学习构建可以通过反复试错，学习好的策略的代理程序。第一部分主要基于Scikit-Learn，而第二部分则使用TensorFlow和Keras。通过本书，你会学到一系列可以快速使用的技术。每章的练习可以帮助你应用所学的知识，你只需要有一些编程经验。所有代码都可以在GitHub上获得。|
|177|[《人工智能简史（第2版）》](https://book.douban.com/subject/35292505/)|《人工智能简史》全面讲述人工智能的发展史，几乎覆盖人工智能学科的所有领域，包括人工智能的起源、自动定理证明、专家系统、神经网络、自然语言处理、遗传算法、深度学习、强化学习、超级智能、哲学问题和未来趋势等，以宏阔的视野和生动的语言，对人工智能进行了全面回顾和深度点评。第2版中每章都有新增内容，并增加了全新的第13章，整理了人工智能几大派别的演化路线和人物的继承关系，有助读者阅读方便。本书极具专业性、思想性和趣味性，既适合缺少专业背景的读者了解人工智能的来龙去脉，作为人工智能的启迪之书，也适合专业人士了解人工智能鲜为人知的历史，提供深入学习的指导。|
|178|[《未来呼啸而来》](https://book.douban.com/subject/35272152/)|作者彼得·戴曼迪斯和史蒂芬·科特勒全面展示了商业创业风口上的9大指数型技术——量子计算、人工智能、网络、机器人、虚拟现实与增强现实、3D打印、区块链、材料科学与纳米技术、生物技术，并洞察这9大指数型技术的互相融合会带来巨大的变革力量，将会完全重塑我们的生活方式与商业模式。两位作者结合9大指数型技术的融合，充分预测和描述了零售业、广告业、娱乐业、教育、医疗保健、长寿、商业、食品业等8大行业指数型变革的未来。指数型技术融合的背后是掌握指数型思维这一认知逻辑。当下人和组织的增长逻辑都在发生改变，线性增长正在被指数型增长取代。每一个人和组织，只有掌握指数型思维，利用大趋势的确定性来抵抗自己小波动的不确定性，才能应对呼啸而来的未来！指数型技术的融合将如何改变今天的传统产业和思维模式？商业、教育、医疗健康等行业将发生怎样的剧变？当人工智能、机器人技术、虚拟现实、材料技术、量子计算与3D打印、区块链和全球千兆网络相互叠加时会发生什么？此刻即未来，科技进步的速度远超任何人的想象，从现在开始的下一个10年，我们将经历比过去一百年更多的动荡并创造更多的财富，这本书给所有人提供了一张扣人心弦、富有洞察力的商业发展寻宝图！|
|179|[《AI 3.0》](https://book.douban.com/subject/35351678/)|人工智能现在正深刻地影响着我们的生产与生活，甚至关系到人类未来的前途命运，但究竟什么是人工智能？人工智能背后的原理是什么？从问世到演化至今，人工智能经历了怎样的历史变迁？当下人工智能的能力边界在哪里？人工智能与人类智能的差异是什么？未来人工智能又将面对什么样的挑战和机遇？关于这些疑问，本书将为你一一揭晓答案。本书是超级畅销书《复杂》作者、复杂系统前沿科学家梅拉妮·米歇尔历经10年思考，厘清人工智能与人类智能的全新力作。本书源自米歇尔多年来对人工智能领域发展真实状态的记录，她在书中通过5个部分揭示了“现在的人工智能可以做什么，以及在未来几十年我们能从它们身上期待什么”。在描述了人工智能的发展历史之后，作者通过对视觉识别、游戏与推理、自然语言处理、常识判断这4大人工智能领域的热门应用的发展现状和局限性的探究，厘清了人工智能与人类智能的关系，书中关于人脸识别、无人驾驶、机器翻译等方面的案例分析都充满了巨大的启示！而这些，都是当下人工智能发展所面临的困境、人工智能想要取得突破性进展所必须重新思考的。看懂这本书，你将对人工智能领域有一个全景式的认知。|
|180|[《贝叶斯的博弈：数学、思维与人工智能》](https://book.douban.com/subject/35383731/)|本书从数学、哲学、计算机科学、神经科学和人工智能等角度，全面阐述了贝叶斯理论背后的基础知识、思维方式和丰富哲理。贝叶斯定理一旦与算法相结合，就不再是一套枯燥的数学理论或认识论，而变成了应用广泛的知识宝库，催生了众多现代数学定理，以及令人称道的实践成果。作者一改传统的数学探讨模式，不仅展现了贝叶斯理论背后的科学思想，还阐述了它与人类思维之间的深刻关系，并对各相关领域和人工智能的发展进行了展望。本书适合喜爱数学、算法、机器学习、人工智能、逻辑学和哲学的大众读者，读者无须过多数学和算法知识就能读懂。|
|181|[《AI 2041》](https://book.douban.com/subject/35462685/)|AI能创造前所未有的财富与价值，能彻底改变医学和教育，能提升人类的工作、娱乐和交流的品质，能把人类从日常工作中解放出来。不过，AI也会带来无数挑战和风险，例如演算法偏见、安全隐患、深度伪造、对隐私资料的侵犯、对自主武器的使用，以及取代人类员工等。不过，这些情況并非AI主导造成的，其根源在于恶意或草率使用AI技术的幕后黑手。全球AI领军人物李开复最关切的是，AI正飞速发展，人类的未来将通往何方？他放眼20年后的新世界，架构10幅「技术蓝图」，再由科幻小说家陳楸帆据此构思10个故事。虚构的叙事与非虚构的科技评论完美结合，展现20年后被AI 技术深刻改变的未来世界。欢迎来到2041！|
|182|[《科学之路》](https://book.douban.com/subject/35560368/)|“图灵奖”得主、“深度学习三巨头”之一、“卷积神经网络之父”……由于在人工智能领域的突出贡献，杨立昆被中国计算机科学界和企业界所熟知。杨立昆的科学之路，谱写了一段关于勇气的宣言。他为了知识本身求学，而不是文凭，他用自己的经历，证明了通过激烈的考试竞争进入名校不是科学成功的窄门。他广泛阅读，为他科学思维的形成奠定了坚实的理论基础。他特立独行，做自己感兴趣的事情，即便那件事在短时间里不被人看好。在人工神经网络研究的低谷期，他寂寞地坚持，终于取得了举世瞩目的成就。人工智能正在颠覆人类社会，未来机器能思考吗？杨立昆的这部著作，讲述正是人工智能在我们面前崛起——这个历史上仅有的时刻发生的故事。|
|183|[《技术陷阱》](https://book.douban.com/subject/35668363/)|每一次重大的技术变革，都会给社会的主要工作形态带来深刻的影响。本书系统而全面地回顾了近几百年技术进步的历史，以及它如何从根本上改变了社会成员之间的经济和政治权力分配。本书作者将带领读者们遍览各个时代技术进步对人们工作形态的影响，揭示不同时代“打工人”的处境，并最终将目光转向未来，试图分析当前的AI革命将对我们的工作造成何种影响，以及我们该如何做出应对。作者力图说明，技术进步对收入造成何种影响，将决定人们对它的态度。工业革命是历史上的重大时刻，但当时几乎没有人意识到它的巨大后果。正如本书所表明的那样，工业革命从长远来看创造了前所未有的财富和繁荣，但机械化的直接后果对大量人口来说是毁灭性的。中等收入岗位减少，工资停滞不前，劳动收入占比下降，利润激增，经济不平等加剧。本书作者卡尔·贝内迪克特·弗雷证明，这些趋势大体上反映了我们现在这个始于计算机革命的自动化时代的趋势。正如工业革命最终为社会带来非同寻常的利益一样，人工智能系统也有潜力做到这一点。《技术陷阱》表明，在眼下这场新的技术革命中，过去的教训可以帮助我们更有效地面对现在的状况。|
|184|[《大脑传》](https://book.douban.com/subject/35785602/)|我们的感觉和身体活动的指令来自何方，情绪、意识、学习与记忆等认知活动的居所又在哪里？自有文字记载起，人 类对这些问题就从未停止过好奇。漫漫几千年来，我们对这些问题的认识从朴素、粗浅的心灵中心观，走到了精细、深入的脑中心观。脑，这个“已知宇宙中最复杂的物体”，吸引了人类历史上无数最聪颖的头脑去破解它的秘密。在认识脑工作机制的过程中，人类一直在使用各种隐喻，这些隐喻无一不受技术、时代以及人类当时对脑认知水平的限制，在完成自己的历史使命后会被新的隐喻所取代。在《大脑传》中，作者马修·科布以脑的隐喻为切入点，介绍了人类脑的认识史上一个又一个里程碑以及那些做出伟大发现的科学家。从心智源自心脏的观点到把脑视作机器的机械观，从电与神经活动的关系到神经系统的神经元学说，从神经信号如何表征信息到脑功能的局域化定位与分散式分布之争，从把脑看作一成不变的电路到把脑视作一个具有可塑性的网络，作者历数了人类对脑认识的曲折演进历程，讲述了脑科学研究对计算机、人工智能等领域的诞生和发展产生的深远影响，勾勒出了一部群星闪耀、波澜壮阔的科学史诗。|
|185|[《AI未来进行式》](https://book.douban.com/subject/35731252/)|人工智能专家李开复与科幻作家陈楸帆创造性合作，畅想了 20 年后在人工智能等科技影响下的人类世界。书中 10 个引人入胜的短篇故事，展示了一系列令人大开眼界的未来场景——身临其境的沉浸式娱乐方式、自如使用人类语言的虚拟伴侣、 没有“司机”的完全自动驾驶汽车、能够以假乱真的照片和视频，以及基于量子计算、计算机视觉和其他 AI 技术的展开应用。在这些故事给读者带来惊奇体验的同时，每一个故事之后的科技评论则让我们进行突破性的深度思考——人工智能能否帮助人类从根源上预防疫情？人们该如何应对未来的职场挑战？在人工智能主导的世界中，该如何确保文化多样性？人们如何教导下一代适应人类与人工智能共存的新社会？如何面对人工智能带来的社会问题，及其所隐含的人性拉锯战？……通过阅读这些有关未来的技术蓝图与分析，相信你我将能更真切地看到人类未来将要前进的方向。欢迎进入 AI 未来进行式！|
|186|[《涌现》](https://book.douban.com/subject/35813178/)|复杂的事物是由小而简单的事物发展而来的，而这正是涌现现象的特征。涌现现象产生的根本原因在于，事物各组成部分之间相互作用产生的复杂性，远非个体行为的叠加可以相比，也就是我们常说的“整体大于部分之和”。“整体大于部分之和”这一特性也成为涌现研究道路上的阻碍。许多哲学家和一些科学家坚定地认为对涌现的研究不可能还原为对明确定义的机制及其相互作用的研究。他们认为，机器的能力不可能超越人类在制造它时赋予它的能力。复杂自适应系统理论提出者约翰·霍兰德借助模型和还原思想，建立了研究涌现现象的普适框架，扫清了研究道路上的障碍，推动了复杂自适应系统、机器学习、人工智能等领域的长足发展。你可能会认为，涌现现象只出现在特定的系统中，在日常生活中并不常见。但实际上，具有涌现现象的系统随处可见且与我们息息相关，比如神经元网络系统、人体免疫系统、互联网和全球经济系统等。因此，研究涌现现象具有重要的现实意义。凭借霍兰德提出的普适理论框架，我们可以找出某些复杂现象背后的根本规律，从而更好地认识世界、开拓世界以及预测未来。|
|187|[《协同进化》](https://book.douban.com/subject/35911428/)|在《协同进化》中，借鉴达尔文进化论的思想，作者爱德华·阿什福德·李从生物学、计算机、人工智能、哲学等多个领域的理论和研究出发，提出机器与生命在很多方面都存在相似之处，因此在探索人机关系时可以将机器视作一种“生命”。两者间并不是简单的 创造与被创造、主宰与被主宰的关系，而是更像两种不断进化、 相互影响和塑造的生命间的共生关系。作者认为，随着人机关系越来越紧密，两者正在从互利共生走向任何一方都离不开另 一方的专性共生。|
|188|[《千脑智能》](https://book.douban.com/subject/36080515/)|科技界的一代传奇人物、计算机科学家与神经科学家杰夫·霍金斯在《千脑智能》中揭示了一种关于大脑和智能的理论——千脑智能理论，这将彻底改变我们对大脑和人工智能的未来的理解。就像人类最终不是通过模仿鸟类，而是通过理解空气动力学而发明了飞行一样，在我们改进机器和深度学习的同时，我们需要首先了解大脑是如何工作的。杰夫·霍金斯和他的团队发现，大脑使用类似地图的结构来建立一个世界的模型——不仅仅是一个模型，而是成千上万个我们所知道的一切的模型，也就是千脑智能理论。这一发现为创造机器智能提供了清晰的路线图。霍金斯多年深耕于大脑研究的领域，终于在这本书中给出了答案。|
|189|[《神奇的连接组》](https://book.douban.com/subject/36070168/)|每个人都有一次生命，以及一颗大脑，伴随我们度过整个一生。而人生中所有重要的目标，归根结底都要从改变大脑开始。我们虽然有自然的改变机制，但它的局限性令人失望。除了满足好奇心和求知欲以外，神经科学到底能不能为我们带来新的启发和技术，让我们改变大脑？好消息是，连接组学带来了希望。作为连接组学的主要倡导者，普林斯顿大学知名神经科学家承现峻认为，连接组其实是由先天基因和后天经历共同塑造的。连接组理论相信，我们的连接组可以由我们的行为与思维来塑造。换言之，我们能够通过影响大脑的连接结构，来塑造我们的大脑。在本书中，承现峻以生动的笔触介绍了连接组学、连接主义、基因对连接组的影响、如何找到连接组，以及如何利用关于连接组的一切发现去改造连接组。这些内容回答了，我们为何与众不同。同时，它们将帮我们改善自己的记忆、摆脱大脑疾病的困扰，甚至将一些科学幻想变成现实。|
|190|[《新机器智能》](https://book.douban.com/subject/36104119/)|人工智能领域一直以来坚信：只要人工智能系统能产生类似于人类的行为，它就是智能的。于是，我们看到了能够打败国际象棋冠军的计算机棋手，能够根据路况选择行驶路线的无人驾驶汽车，能够做手术的“医生”……人们甚至开始担忧：有朝一日，机器人会不会超越人类，进而奴役人类？在本书中，科技界一代传奇杰夫·霍金斯指出，如今的人工智能并不智能。要想创造真正的机器智能，最快的途径是理解大脑的工作原理，然后在计算机中模仿这些原理。霍金斯一生痴迷两件事——计算机和大脑。早在几十年前，他创建的Palm掌上电脑就在商业上取得了巨大成功，也成为现代智能手机的原型。但霍金斯一心想弄清楚大脑的工作原理。经过数十年的不懈努力，他终于发现了其中的奥秘：大脑学习世界的一个模型，并使用这个模型来预测未来。人类的创造力、意识都是通过这个模型产生的。这一全新的智能理论框架被命名为“记忆-预测模型”，它改变了人们对智能的看法，也为开发真正的机器智能奠定了坚实的基础。本书深入探讨了智能的核心问题：计算机真的智能吗？大脑是如何工作的？为什么弄清大脑的工作原理如此困难？如果不以行为来定义，那应该怎样定义智能呢？“记忆-预测模型”的含义是什么？如果你想了解自身、了解智能、了解机器智能，那么一定不要错过霍金斯的这一本里程碑式作品。|
|191|[《人工智能（第4版）》](https://book.douban.com/subject/36152133/)|本书全面、深入地探讨了人工智能（AI）领域的理论和实践，以统一的风格将当今流行的人工智能思想和术语融合到引起广泛关注的应用中，真正做到理论和实践相结合。全书分7个部分，共28章，理论部分介绍了人工智能研究的主要理论和方法并追溯了两千多年前的相关思想，内容主要包括逻辑、概率和连续数学，感知、推理、学习和行动，公平、信任、社会公益和安全；实践部分完美地践行了“现代”理念，实际应用选择当下热度较高的微电子设备、机器人行星探测器、拥有几十亿用户的在线服务、AlphaZero、人形机器人、自动驾驶、人工智能辅助医疗等。本书适合作为高等院校人工智能相关专业本科生和研究生的教材，也可以作为相关领域专业人员的参考书。|
|192|[《深度学习革命》](https://book.douban.com/subject/36171345/)|长期以来，人工智能一直被视为一种遥远的未来技术，它是一个被委托给科学界边缘的项目，甚至在历史上两次走入绝境，陷入寒冬，直到一些孤注一掷的研究人员用一场新的变革打破了宁静——深度学习革命。近年来，让人工智能受到全世界瞩目的高调事件，基本上都是基于深度学习的。比如，AlphaGo击败了世界围棋冠军，自然语言处理催生了智能语音助手，自动驾驶、人脸识别在世界范围内得到广泛应用，AI绘画更是以假乱真、火遍全球……可以说，深度学习已经浸入了我们的日常生活，从边缘走到了舞台的中心，正蓄势待发，即将掀起一场惊人的变革。这是一本讲述人工智能，尤其是深度学习的历史与未来的书。在这本书中，作者讲述了一群将深度学习带给全世界的企业家和科学家的故事，从谷歌、Facebook、百度等大公司的决策者讲到学术界的领军人物——“深度学习三巨头”，再讲到DeepMind、OpenAI等知名实验室的开创者。读者可以通过这些人的故事，跟随现代人工智能的发展脚步，从人工智能研究的萌芽阶段开始，穿过两次人工智能的寒冬，一直了解到当下全新的前沿进展。通过描绘人工智能的发展脉络和各大科技公司在前沿趋势方面的布局，这本书阐释了人工智能如何走到了今天，以及它在未来将如何发展。|
|193|[《动手学深度学习（PyTorch版）》](https://book.douban.com/subject/36142067/)|本书是《动手学深度学习》的重磅升级版本，选用经典的PyTorch深度学习框架，旨在向读者交付更为便捷的有关深度学习的交互式学习体验。 本书重新修订《动手学深度学习》的所有内容，并针对技术的发展，新增注意力机制、预训练等内容。本书包含15章，第一部分介绍深度学习的基础知识和预备知识，并由线性模型引出最简单的神经网络——多层感知机；第二部分阐述深度学习计算的关键组件、卷积神经网络、循环神经网络、注意力机制等大多数现代深度学习应用背后的基本工具；第三部分讨论深度学习中常用的优化算法和影响深度学习计算性能的重要因素，并分别列举深度学习在计算机视觉和自然语言处理中的重要应用。 　　本书同时覆盖深度学习的方法和实践，主要面向在校大学生、技术人员和研究人员。阅读本书需要读者了解基本的Python编程知识及预备知识中描述的线性代数、微分和概率等基础知识。|
|194|[《AIGC：智能创作时代》](https://book.douban.com/subject/36238822/)|在人工智能发展的漫长历程中，如何让机器学会创作一直被视为难以逾越的天堑，“创造力”也因此被视为人类与机器最本质的区别之一。然而，人类的创造力也终将赋予机器创造力，把世界送入智能创作的新时代。人工智能绘画作品的夺冠、超级聊天机器人ChatGPT的出现，无疑拉开了智能创作时代的序幕。从机器学习到智能创造，从PGC、UGC到AIGC，我们即将见证一场深刻的生产力变革，而这份变革也会影响到我们工作与生活的方方面面。本书将结合生动的比喻和有趣的案例，向所有关注未来科技的从业者、创业者、投资人、政府部门科普AIGC的商业落地场景和行业应用案例。让我们一起迎接全新的智能创作时代。|
|195|[《何为人类》](https://book.douban.com/subject/36369885/)|GPT回应的192个生命大议题中英双语对照，揭示ChatGPT原始模型的底层语言逻辑一次大胆的人机交互实验，机器模拟自然语言的惊人之作深入探究GPT的“创作本能”透过机器之心探寻人类与AI共存的未来|
|196|[《5000天后的世界》](https://book.douban.com/subject/36331624/)|K.K.预测未来将会是一切都与AI相连的世界，他将其称为镜像世界（Mirror-world）。智能手机和社交媒体已经超越国界，并对国际经济和政治产生影响。GAFA的规模扩展到可以左右国际社会命运的程度。为什么会出现这样的巨变，世界到底要向什么方向发展？物理世界将与虚拟世界融合，同时将产生新的平台，进而形成新的工作方式和组织形式，我们将迎来以中国和印度为中心的亚洲世纪。除了对未来科技发展的预测，K.K.也对社会形态变化进行了预测，涉及商业变革、地缘政治、社会学等。K.K.没有因不断出现新的技术、产品或流行趋势而迷失方向，而是执着地对科技本质的深层结构进行观察，他在书中指明了产生科技的世界本身具有何种发展趋势。|
|197|[《为什么伟大不能被计划》](https://book.douban.com/subject/36357804/)|两位作者持续多年扎根人工智能前沿领域，这本书是他们在科学研究的过程中蹦出的意外火花。因为这一全新发现并不是直接回馈于他们本身所处的人工智能领域，而是“无心插柳”收获了对人类约定俗成的思维方式的全新颠覆。这一研究打破了人类世界延续多年、难以撼动的、依靠目标和计划成事的文化基因，真正开启了人类伟大创新的惊喜之旅。他们在学校、TED、科研论坛等场合公开演讲，让这一新思维方式影响并激励了许多人。他们自身也凭借写入本书的“寻宝者思维”“踏脚石模型”“新奇性探索”等具体思维方法，在人工智能研发领域取得了飞跃式的突破和进展，产生了一系列惠及人类的伟大创造。|
|198|[《生成式人工智能》](https://book.douban.com/subject/36368084/)|ChatGPT一经问世，在全球范围内引起巨大轰动，GPT-4接入未来办公软件更是让人震惊，而且技术正在以前所未有的速度快速迭代。那么，以这些技术为代表的生成式人工智能（AIGC）是否为新一轮的技术革命？它到底能做什么，具有哪些优势和场景应用趋势？面对新技术，未来商业的机会在哪里，对我们个人又有着什么样的影响？……这些问题h对于我们理解当下，面向未来都十分重要。本书基于作者的专业背景和长期实践，系统介绍生成式人工智能的内在逻辑与应用，并将其与产业发展，理论和实际相结合，帮助读者从本源了解生成式人工智能，结合未来趋势和发展为读者指明方向。|
|199|[《人工智能时代与人类未来》](https://book.douban.com/subject/36420550/)|人工智能时代来临，将带来划时代的变革。人工智能正改变我们的社会、经济、政治和外交政策，这一切影响远远超过任何领域的传统范畴，而我们做好准备了吗？在本书中，来自政府、企业和学术界的三位顶尖思想家——著名外交家基辛格、谷歌前CEO施密特和麻省理工苏世民计算机学院院长胡滕洛赫尔齐聚一堂，探讨人工智能对我们所有人的意义。本书通过梳理人工智能的发展现状、人类思想及技术演进的历程，进一步讨论了人工智能赋能的网络平台给个人、企业、政府、社会、国家和地区带来的影响，以及人工智能将在重塑世界秩序和安全格局方面所起的作用。同时，该书反思了人工智能的发展对于人类自我身份认同产生的巨大冲击，以客观的视角提出人类在未来几年所必须面对的问题以及解答工具。|
|200|[《芯片战争》](https://book.douban.com/subject/36350632/)|芯片是现代世界赖以生存的稀缺资源，就像石油一样。如今，军事、经济和地缘政治力量都建立在芯片的基础上。从制导导弹到微波炉，从智能手机到股票市场，一切都离不开芯片。谁在芯片设计和制造领域保持领先地位，谁就能在科技和经济等领域产生巨大的优势。长期以来，美国、日本、韩国以及欧洲各国，都在芯片设计和制造领域进行激烈的竞争，以图赢得这场立足于科技之上的战争。经济历史学家克里斯·米勒在书中较为完整地描述了各国为控制芯片技术而进行的长达数十年的斗争历程，解释了半导体在现代生活中发挥的关键作用，以及美国是如何在芯片设计和制造中占据主导地位，并将这种技术应用于军事系统的。本书集科技冒险、商战故事、大国博弈于一体，分析了芯片崛起的历史，以及以控制芯片行业的未来为目的的日益复杂的地缘政治权力斗争，对理解当今的政治、经济和和科技至关重要。|
|201|[《人机对齐》](https://book.douban.com/subject/36432977/)|如今的“机器学习”系统已具备非凡能力，能够在各种场合代替我们看和听，并代表我们做决定。但是警钟已经敲响。随着机器学习飞速发展，人们的担忧也在与日俱增。如果我们训练的人工智能（AI）做的事情与我们真正的目的不符，就会引发潜在的风险和伦理问题。研究人员称之为对齐问题（the alignment problem）。畅销书作家布莱恩•克里斯汀用生动的笔调，清晰阐释了AI与我们息息相关的问题。在书中，我们将认识第一批积极应对对齐问题的学者，了解他们为了避免AI发展的局面失控，付出的卓绝努力和雄心勃勃的计划。克里斯汀不仅精练地描绘了机器学习的发展史，并且亲自深入科研一线同科学家对话，准确呈现了机器学习最前沿的进展。读者可以清晰认识到，对齐问题研究的成败，将对人类的未来产生决定性影响。对齐问题还是一面镜子，将人类自身的偏见和盲点暴露出来，让我们看清自己从未阐明的假设和经常自相矛盾的目标。这是一部精彩纷呈的跨学科史诗，不仅审视了人类的科技，也审视了人类的文化，时而让人沮丧，时而又柳暗花明。|
|202|[《GPT时代人类再腾飞》](https://book.douban.com/subject/36455667/)|在人工智能时代，谁能率先接入机器能力，谁就将赢得未来。那么，对于所有人而言，我们要如何在自己的生活和工作中利用好AI带来的巨大变革性影响力？《GPT时代人类再腾飞》就将给出回答。本书探讨了AI，尤其是像ChatGPT、GPT-4这样的大语言模型，如何在教育、商业、创造力、社交媒体、新闻、劳动方式等方面提升人类的能力与强化人类的特质。可以说，AI是我们应对挑战、提升生活的重要途径。AI技术的进步可以被视为人类智慧和创造力的体现，而ChatGPT可以帮助全人类获得更大的助益和福祉。|
|203|[《这就是ChatGPT》](https://book.douban.com/subject/36449803/)|ChatGPT是OpenAI开发的人工智能聊天机器人程序，于2022年11月推出，能够自动生成一些表面上看起来像人类写出的文字的东西，是一件很厉害且出乎大家意料的事。那么，它是如何做到的呢？又是为何能做到的呢？本书会大致介绍ChatGPT的内部机理，然后探讨一下为什么它能很好地生成我们认为是有意义的文本。本书适合想了解ChatGPT的所有人阅读。|
|204|[《计算》](https://book.douban.com/subject/36615448/)|计算已经成为人们生活中不可或缺的组成部分，人类社会享受了计算技术的红利得以飞速发展。可以说当今的计算机科学和产业应用的成就是人类文明有史以来所有智慧的结晶。解释、澄清和发展“计算”这一重要概念，即本书之写作目的。本书从探索数学的起源开始，细数了数学史上三次危机的来龙去脉 ，逐渐引出计算理论的诞生和发展，以及这些过往是如何影响当今计算机科学最前沿方向的。最后本书从哲学层面探讨了计算的边界，将其视为人类需要继续探索的未解之谜。本书横跨了人类近3000年的文明史，综合了数学、哲学、物理学、计算机科学、人工智能、复杂系统科学等多门学科，呈现出一种独特的计算主义的世界观。|
|205|[《我看见的世界》](https://book.douban.com/subject/36672955/)|《我看见的世界》既是李飞飞的个人史，也是一部波澜壮阔、跌宕起伏的人工智能发展史。在这本书里，李飞飞回忆了自己从底层移民成长到顶尖科学家的经历。她度过了困顿艰辛的青少年时代，但对科学的热爱不断激励着她持续追寻人生的“北极星”，并最终走进科学的殿堂。当李飞飞和家人努力适应在美国的生活时，恰逢现代人工智能开始不断取得突破。她不断开启新的科学征程，并确立了自己在计算机视觉领域的科学使命，取得了非凡的成就。在这本书里，她详细记录了这些重大时刻的关键细节。同时，李飞飞也对未来人工智能的发展方向提出了自己的判断和警醒，核心就是“以人为本”，让人工智能真正推动人类的发展，而不是成为威胁。这本书既是对重大科学突破幕后的精彩窥探，也是一位女性用好奇心和勇气突破人生困境的故事。它不仅证明了即使是最技术性的学术研究也需要激情，更加表明永不停歇的好奇心可以激发无尽的科技创新。|
|206|[《人工智能时代》](https://book.douban.com/subject/26776547/)|当机器人霸占了你的工作，你该怎么办？机器人犯罪，谁才该负责？人工智能时代，人类价值如何重新定义？在《人工智能时代》一书中，智能时代领军人、硅谷连续创业者杰瑞·卡普兰指出：智能时代的到来，给人类社会带来了两大灾难性冲击：持续性失业与不断加剧的贫富差距。机器正在很大程度上替代人类的工作，不管你是蓝领还是白领。而针对未来社会将要发生的这些问题，卡普兰在《人工智能时代》一书中从企业、税收和保险等机制上构建起了一个有益的经济生态，让社会中的每一个人都能从技术发展中获益，带领我们一窥人机共生下财富、工作与思维的大未来。《人工智能时代》一书提出的建议和解决方案给遭遇挑战的人们更多抚慰和安全感！拥抱人工智能时代必读之作，引爆人机共生新生态。|
|207|[《智能时代》](https://book.douban.com/subject/26838557/)|大数据和机器智能的出现，对我们的技术发展、商业和社会都会产生重大的影响。作者吴军在《智能时代：大数据与智能革命重新定义未来》中指出，首先，我们在过去认为非常难以解决的问题，会因为大数据和机器智能的使用而迎刃而解，比如解决癌症个性化治疗的难题。同时，大数据和机器智能还会彻底改变未来的商业模式，很多传统的行业都将采用智能技术实现升级换代，同时改变原有的商业模式。大数据和机器智能对于未来社会的影响是全方位的。|
|208|[《刷新》](https://book.douban.com/subject/27614523/)|互联网时代的霸主微软，曾经错失了一系列的创新机会。但是在智能时代，这家科技公司上演了一次出人意料的“大象跳舞”。2017年，微软的市值已经超过6000亿美元，在科技公司中仅次于苹果和谷歌，高于亚马逊和脸谱 网。除了传统上微软一直占有竞争优势的软件领域，在云计算、人工智能等领域，微软也获得强大的竞争力。通过收购领英，微软还进入社交网络领域。自萨提亚·纳德拉2014年接任首席执行官以来，微软的市值翻番，超过了互联网泡沫以来的高点。《刷新》全景回顾了萨提亚的变革路径，如在硬件Surface电脑上的投入，在混合现实、人工智能和量子计算三大领域的战略布局等；系统总结了他的核心管理思想，即任何组织和个人，达到某个临界点时，都需要自我刷新。为了迎接智能时代的挑战，他提出自我刷新的三个关键步骤：拥抱同理心，培养“无所不学”的求知欲，以及建立成长型思维。|
|209|[《AI新生》](https://book.douban.com/subject/35149258/)|从比尔·盖茨、埃隆·马斯克到霍金，众多企业家和科学家都曾表示担心AI对人类生存造成的威胁。真的有一天，人类会成为自己发明的机器的受害者吗？在过去相当长的一段时间里，人类之所以能控制地球，是因为人类的大脑比其他动物的大脑要复杂得多。但如果AI变得比人类更聪明，我们要如何掌控这个世界？智能是一种权力，我们能否控制智能，决定了我们未来的命运。这本书讲述了我们为理解和创造智能，在过去、现在和未来所做的尝试。这很重要，并不是因为AI正迅速成为当前的一种普遍现象，而是因为它是未来的主导技术。世界上的各个大国正在意识到这一事实，各家大公司也早就知道这一点。作者在书中提出了一个大问题：如何破解人机共存密码，掌控比我们强大得多的智能，让AI获得新生？这可能是人类面临的最后一个大问题。这本书的目的是解释为什么这可能是人类历史上的最后一件事，以及如何确保这不会成为现实。|
|210|[《深度医疗》](https://book.douban.com/subject/35245625/)|● 医疗资源紧缺、医生看诊时间越来越短、医生无法真正地与患者进行沟通……人工智能将增强医生的专业能力，彻底改变这些窘迫现状。在本书中，埃里克·托普揭示了人工智能在医学上的各种应用前景，为人工智能如何实现医疗变革提供了一幅全景图。● 全书共包括13个部分，分别讲述了深度医疗的模型、浅度医疗的概况、人工智能对医疗诊断的影响、人工智能的成功先例、深度学习的局限、人工智能对三类“有模式”医生的影响、人工智能对“无模式”医生的影响、人工智能在心理健康领域的应用、人工智能对医疗系统的影响、人工智能如何改变生物医学、人工智能在个性化饮食方案制定上的应用前景、虚拟医疗助手的发展现状，以及深度共情如何让医疗回归人文。● 本书展示了人工智能在医学领域的应用现状和前景，适合医疗政策制定者、医疗产业圈的企业家和专家，人工智能及大数据领域人士阅读。|
|211|[《大模型应用解决方案》](https://book.douban.com/subject/36696373/)|Transformer正在颠覆AI领域。市面上有这么平台和Transformer模型，哪些最符合你的需求？ 将引领你进入Transformer的世界，将讲述不同模型和平台的优势，指出如何消除模型的缺点和问题。本书将引导你使用Hugging Face从头开始预训练一个RoBERTa模型，包括构建数据集、定义数据整理器以及训练模型等。本书分步展示如何微调GPT-3等预训练模型。研究机器翻译、语音转文本、文本转语音、问答等NLP任务，并介绍解决NLP难题的技术，甚至帮助你应对假新闻焦虑(详见第13章)。 从书中可了解到，诸如OpenAI的高级平台将Transformer扩展到语言领域、计算机视觉领域，并允许使用DALL-E 2、ChatGPT和GPT-4生成代码。通过本书，你将了解到Transformer的工作原理以及如何实施Transformer来决NLP问题。|
|212|[Attention Is All You Need](https://arxiv.org/abs/1706.03762)|主流的序列转换模型基于复杂的循环或卷积神经网络，采用编码器-解码器配置。表现最佳的模型也通过注意力机制将编码器和解码器相连。我们提出了一种新的简单网络架构——Transformer，该架构完全基于注意力机制，摒弃了循环和卷积。在两项机器翻译任务的实验中，这些模型展现出更优的质量，同时具有更高的并行化程度，并且训练所需时间大幅减少。我们的模型在WMT 2014英德翻译任务上达到了28.4的BLEU分数，超越了现有最佳成绩，包括集成模型在内的成绩提高了超过2个BLEU。针对WMT 2014英法翻译任务，我们的模型在八个GPU上仅训练3.5天后，建立了新的单模型最先进BLEU得分41.8，这仅占文献中最佳模型训练成本的一小部分。我们还展示了Transformer能够很好地泛化到其他任务上，通过成功将其应用于英语句法分析，无论是在大量还是有限的训练数据情况下。|
|213|[LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)|自然语言处理的一个重要范式是在通用领域数据上进行大规模预训练，然后适应特定任务或领域。随着我们对更大模型进行预训练，全微调——即重新训练所有模型参数——变得越来越不可行。以GPT-3 175B为例，部署独立的、针对特定任务微调过的模型实例，每个实例都拥有175B参数，成本高昂到难以承受。我们提出了低秩适配（Low-Rank Adaptation，简称LoRA），该方法冻结预训练模型的权重，并向Transformer架构的每一层注入可训练的秩分解矩阵，从而大幅减少了下游任务所需的可训练参数数量。与使用Adam微调GPT-3 175B相比，LoRA可以将可训练参数数量减少1万倍，GPU内存需求减少3倍。尽管具有更少的可训练参数、更高的训练吞吐量，并且与适配器不同，没有额外的推理延迟，LoRA在模型质量上表现与微调相当或更优，这在RoBERTa、DeBERTa、GPT-2和GPT-3上得到了验证。我们还对语言模型适应中的秩不足现象进行了实证研究，这进一步阐明了LoRA的有效性。我们发布了一个工具包，便于将LoRA与PyTorch模型集成，并提供了我们对RoBERTa、DeBERTa和GPT-2的实现和模型检查点。|
|214|[High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752)|通过将图像生成过程分解为去噪自编码器的顺序应用，扩散模型（DM）在图像数据及其他领域实现了最先进的合成效果。此外，它们的架构允许采用引导机制来控制图像生成过程，而无需重新训练。然而，由于这些模型通常直接在像素空间操作，强大DM的优化往往需要数百个GPU天，且由于顺序评估，推断成本高昂。为了在有限计算资源下仍能保持DM的质量和灵活性进行训练，我们将其应用于强大预训练自编码器的潜在空间中。与以往工作不同的是，在这样的表示上训练扩散模型首次能够在复杂度降低与细节保留之间达到近乎最优的平衡，极大地提升了视觉保真度。通过在模型架构中引入交叉注意力层，我们将扩散模型转变为针对诸如文本或边界框等通用条件输入的强大而灵活的生成器，并以卷积方式实现了高分辨率合成。我们的潜在扩散模型（LDMs）在图像修复方面达到了新的最先进水平，并在各种任务上展现出极具竞争力的表现，包括无条件图像生成、语义场景合成和超分辨率，同时相比基于像素的DM显著降低了计算需求。|
|215|[Stable Diffusion 2.0 Release](https://stability.ai/news/stable-diffusion-v2-release)|Stability AI 发布了 Stable Diffusion 2.0，相较于原版有显著提升。主要改进包括使用 OpenCLIP 的新文本生成图像模型以提升图像质量、提高分辨率4倍的放大模型、保留结构的深度生成图像模型，以及用于智能图像编辑的更新版修复模型。这些改进使模型更具可访问性和多功能性，适用于各种创意应用。|
|216|[Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/abs/2302.05543)|我们介绍ControlNet，一种神经网络架构，旨在向大型预训练的文本到图像扩散模型中添加空间条件控制。ControlNet锁定生产就绪的大型扩散模型，并复用其深层和稳健的编码层，这些编码层通过数十亿张图像预训练作为强大的后端，以学习多样化的条件控制集。神经架构通过“零卷积”（零初始化卷积层）连接，逐步从零增长参数，并确保在微调过程中没有有害噪声影响。我们使用Stable Diffusion测试了多种条件控制，例如边缘、深度、分割、人体姿态等，采用单一或多个条件，以及是否带有提示。我们展示ControlNet的训练对于小型（<50k）和大型（>1m）数据集都是健壮的。广泛的实验结果显示，ControlNet可能促进对图像扩散模型更广泛的应用控制。|
|217|[ReVersion: Diffusion-Based Relation Inversion from Images](https://arxiv.org/abs/2303.13495)|扩散模型因其生成能力而日益受到欢迎。近期，出现了大量需求，希望通过示例图像反转扩散模型来生成定制化图像。然而，现有的反转方法主要集中在捕捉物体外观上，如何反转物体关系——视觉世界中另一个重要的支柱，尚未得到探索。本工作中，我们为“关系反转”任务提出了ReVersion，旨在从示例图像中学习一个特定的关系（表现为“关系提示”）。具体而言，我们从一个冻结的预训练文本到图像扩散模型中学习关系提示。学到的关系提示随后可用于生成具有新物体、背景和风格的关系特定图像。我们的关键洞察是“介词先验”——现实世界中的关系提示可以稀疏地激活一组基础介词词项。具体来说，我们提出了一种新颖的关系引导对比学习方案，以施加关系提示的两个关键属性：1) 关系提示应捕获物体间的互动，这由介词先验强制执行；2) 关系提示应与物体外观解耦。我们进一步设计了关系聚焦重要性采样，以强调高层互动而非低层外观（如纹理、颜色）。为了全面评估这一新任务，我们贡献了ReVersion基准，它提供了具有多样化关系的各种示例图像。广泛的实验证实了我们的方法相对于现有方法在广泛视觉关系上的优越性。|
|218|[Exploiting Diffusion Prior for Real-World Image Super-Resolution](https://arxiv.org/abs/2305.07015)|我们提出了一种新方法，利用预先训练好的文本到图像扩散模型中封装的先验知识来进行盲目的超分辨率(SR)处理。具体来说，通过采用我们的时间感知编码器，我们能够在不改变预训练合成模型的情况下获得有希望的恢复结果，从而保留生成先验并最小化训练成本。为了弥补由扩散模型固有的随机性导致的保真度损失，我们采用了一个可控的特征包裹模块，用户只需在推理过程中简单调整一个标量值，就可以平衡质量和保真度。此外，我们开发了一种渐进式聚合采样策略，以克服预训练扩散模型的固定尺寸限制，使模型能够适应任何大小的分辨率。综合使用合成和现实世界基准的评估表明，我们的方法优于当前最先进的方法。|
|219|[Mix-of-Show: Decentralized Low-Rank Adaptation for Multi-Concept Customization of Diffusion Models](https://arxiv.org/abs/2305.18292)|像Stable Diffusion这样的大型公开文本到图像扩散模型已经引起了社区的极大关注。这些模型可以借助低秩适应（LoRAs）轻松地针对新概念进行定制。然而，利用多个概念LoRAs来共同支持多个定制概念带来了挑战。我们将这种情况称为去中心化的多概念定制，它涉及到单客户端概念微调和中心节点概念融合。在本文中，我们提出了一种名为Mix-of-Show的新框架，该框架旨在解决去中心化多概念定制的挑战，包括由于现有的单客户端LoRA微调导致的概念冲突以及模型融合期间的身份信息损失。Mix-of-Show采用嵌入分解的LoRA（ED-LoRA）进行单客户端微调，并利用梯度融合为中心节点保留单个概念的领域本质，理论上支持无限的概念融合。此外，我们引入了区域可控采样，该技术扩展了空间可控采样（如ControlNet和T2I-Adaptor），以解决多概念采样中的属性绑定和对象缺失问题。广泛的实验证明，Mix-of-Show能够以高保真度组合多个定制概念，包括角色、物体和场景。|
|220|[TaleCrafter: Interactive Story Visualization with Multiple Characters](https://arxiv.org/abs/2305.18247)|精确的故事可视化需要几个必要元素，包括帧间身份一致性、纯文本与视觉内容的对齐，以及图像中物体的合理布局。以往的多数工作致力于通过在具有相同风格和角色的视频集（例如，FlintstonesSV数据集）上拟合文本到图像（T2I）模型来满足这些要求。然而，所学习到的T2I模型通常难以适应新角色、场景和风格，并且往往缺乏修改合成图像布局的灵活性。本文提出了一种通用的交互式故事可视化系统，能够处理多个新角色并支持布局和局部结构的编辑。该系统通过利用大型语言和T2I模型在海量语料库上的先验知识进行开发，包含四个相互连接的组件：故事到提示生成（S2P）、文本到布局生成（T2L）、可控文本到图像生成（C-T2I）以及图像到视频动画（I2V）。首先，S2P模块将简要的故事信息转化为后续阶段所需的详细提示。接下来，T2L基于这些提示生成多样且合理的布局，使用户能够根据自己的喜好调整和细化布局。核心组件C-T2I允许在布局、草图和角色特定标识符的指导下创建图像，以保持可视化过程中的连贯性和细节。最后，I2V通过动画化生成的图像来丰富可视化过程。通过广泛实验和用户研究，验证了所提出的系统在交互式编辑方面的有效性和灵活性。|
|221|[Specialist Diffusion: Plug-and-Play Sample-Efficient Fine-Tuning ofText-to-Image Diffusion Models to Learn Any Unseen Style](https://openaccess.thecvf.com/content/CVPR2023/html/Lu_Specialist_Diffusion_Plug-and-Play_Sample-Efficient_Fine-Tuning_of_Text-to-Image_Diffusion_Models_To_CVPR_2023_paper.html)|尽管文本生成视频技术近期取得了进展，但现有研究通常忽略了文本仅控制空间内容而不控制合成视频中的时间运动这一问题。为应对这一挑战，本研究提出了一个名为LivePhoto的实用系统，允许用户用文本描述为感兴趣的图像添加动画。我们首先建立了一个强大的基线，帮助训练良好的文本生成图像模型（如Stable Diffusion）以图像作为进一步输入。随后，我们为改进的生成器配备了用于时间建模的运动模块，并提出了精心设计的训练管道，以更好地连接文本和运动。特别是，考虑到（1）文本只能粗略描述运动（例如，不考虑运动速度）和（2）文本可能包括内容和运动描述，我们引入了运动强度估计模块以及文本重权重模块，以减少文本到运动映射的模糊性。实验证据表明，我们的方法能够很好地将与运动相关的文本指令解码为视频，例如动作、相机移动，甚至从无到有地创造新内容（例如，将水倒入空玻璃杯）。有趣的是，由于提出的强度学习机制，除了文本之外，我们的系统还为用户提供了一个额外的控制信号（即运动强度）用于视频定制。|
|222|[Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation](https://arxiv.org/abs/2306.07954)|大型文本到图像扩散模型在生成高质量图像方面已展现出令人印象深刻的熟练度。然而，当将这些模型应用于视频领域时，确保视频帧间的时间一致性仍是一个严峻的挑战。本文提出了一种新颖的零样本文本引导的视频到视频翻译框架，以使图像模型适应视频。该框架包含两部分：关键帧翻译和完整视频翻译。第一部分使用经过改编的扩散模型来生成关键帧，并应用层次化的跨帧约束来强制形状、纹理和颜色的一致性。第二部分通过时间感知的斑块匹配和帧混合技术，将关键帧传播到其他帧上。我们的框架以低成本（无需重新训练或优化）实现了全局风格和局部纹理的时间一致性。该适应方法与现有的图像扩散技术兼容，使得我们的框架能够利用这些技术，例如使用LoRA定制特定主题，以及借助ControlNet引入额外的空间引导。广泛的实验结果证明了我们提出的框架相较于现有方法，在渲染高质量且时间连贯的视频方面的有效性。|
|223|[AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning](https://arxiv.org/abs/2307.04725)|随着文本到图像（T2I）扩散模型（如Stable Diffusion）的发展，以及DreamBooth和LoRA等个性化技术的出现，每个人都能以可承受的成本将自己的想象转化为高质量的图像。然而，给已有的高质量个性化T2I添加动态效果，使它们能够生成动画，仍是一个待解的挑战。在本文中，我们提出了AnimateDiff，一个实用的框架，用于动画化个性化T2I模型，无需进行特定模型的调整。我们框架的核心是一个即插即用的运动模块，该模块只需训练一次，就能无缝融入任何源自相同基础T2I的个性化T2I中。通过我们提出的训练策略，运动模块能有效地从真实世界的视频中学习可转移的运动先验知识。一旦训练完成，运动模块即可嵌入个性化T2I模型中，形成一个个性化的动画生成器。我们进一步提出了MotionLoRA，这是一种针对AnimateDiff的轻量级微调技术，能让预训练的运动模块以较低的训练和数据收集成本适应新的运动模式，比如不同的镜头类型。我们在从社区收集的几个公共代表性个性化T2I模型上评估了AnimateDiff和MotionLoRA。结果显示，我们的方法帮助这些模型生成了时间平滑、同时保留视觉质量和运动多样性的动画片段。|
|224|[AnyDoor: Zero-shot Object-level Image Customization](https://arxiv.org/abs/2307.09481)|本工作介绍了一项名为AnyDoor的技术，这是一种基于扩散的图像生成器，能够以和谐的方式将目标物体“瞬间移动”到用户指定的新场景中的位置。与为每个物体单独调整参数不同，我们的模型仅需训练一次，就能在推理阶段轻松地泛化到多样化的物体-场景组合上。这样一种富有挑战性的零样本设置要求对特定物体有充分的表征。为此，我们在常用的标识特征基础上，补充了细节特征。这些细节特征经过精心设计，既能保持纹理细节，又能允许多样的局部变化（例如，光照、方向、姿态等），从而支持物体与不同环境的有利融合。我们进一步提议从视频数据集中借用知识，在这些数据集中，我们可以观察到单一物体的各种形态（即沿着时间轴的变化），这使得模型具有更强的泛化能力和鲁棒性。广泛的实验验证了我们方法相对于现有替代方案的优越性，及其在虚拟试穿、物体迁移等现实应用中的巨大潜力。|
|225|[Announcing SDXL 1.0](https://stability.ai/news/stable-diffusion-sdxl-1-announcement)|Stability AI 宣布发布 SDXL 1.0，这是文本生成图像模型的最新版本。与仅限研究的 SDXL 0.9 版本相比，SDXL 1.0 提供了更好的图像质量，包括各种艺术风格和高真实感的图像生成，特别是在色彩、对比度和光影方面有显著提升。该模型具有 3.5 亿参数的基础模型和 6.6 亿参数的模型集合管道，能够在消费者级 GPU 上高效运行。此外，用户可以轻松微调模型以适应自定义数据。|
|226|[IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models](https://arxiv.org/abs/2308.06721)|近年来，大型文本到图像扩散模型展现了强大的生成能力，能够创造出高保真度的图像，令人印象深刻。然而，仅使用文本提示来生成期望的图像十分具有挑战性，因为它通常涉及复杂的提示工程。作为文本提示的替代方案，“一幅图胜过千言万语”，图像提示应运而生。尽管现有的直接从预训练模型进行微调的方法有效，但它们需要大量的计算资源，并且不兼容其他基础模型、文本提示及结构化控制。在这篇论文中，我们介绍了一种称为IP-Adapter的有效且轻量级的适配器，它为预训练的文本到图像扩散模型实现了图像提示功能。IP-Adapter的核心设计是解耦的交叉注意力机制，该机制将用于文本特征和图像特征的交叉注意力层分开。尽管我们的方法简单，但仅带有2200万参数的IP-Adapter就能达到与完全微调的图像提示模型相当甚至更优的表现。由于我们冻结了预训练的扩散模型，所提出的IP-Adapter不仅能够应用于从同一基础模型微调出的其他自定义模型，还能应用于利用现有可控工具的可控生成。得益于解耦的交叉注意力策略，图像提示也能与文本提示良好协同，实现多模态图像生成。|
|227|[Pixel-Aware Stable Diffusion for Realistic Image Super-resolution and Personalized Stylization](https://arxiv.org/abs/2308.14469)|扩散模型已经在多种图像生成、编辑、增强和转换任务中展现出令人印象深刻的性能。特别是，预训练的文本到图像稳定扩散模型，凭借其强大的生成先验，为解决具有挑战性的现实图像超分辨率（Real-ISR）和图像风格化问题提供了潜在解决方案。然而，现有的沿此方向的方法往往未能保持图像像素级结构的忠实性。如果使用额外的跳过连接来重现细节，则需要在图像空间中进行额外训练，这限制了其在诸如图像风格化等潜在空间任务中的应用。在这项工作中，我们提出了一种像素感知的稳定扩散（PASD）网络，以实现稳健的Real-ISR和个人化图像风格化。具体而言，引入了一个像素感知的交叉注意力模块，使扩散模型能够在像素级别上感知图像的局部结构，同时使用一个退化去除模块来提取对退化不敏感的特征，与图像的高层信息一起指导扩散过程。引入了一个可调整的噪声调度进一步提升图像恢复效果。仅需将基础扩散模型替换为风格化的模型，PASD即可在无需收集成对训练数据的情况下生成多样化的风格化图像；通过将基础模型调整为审美导向的模型，PASD还能使旧照片重焕新生。在多种图像增强和风格化任务中的广泛实验验证了我们提出的PASD方法的有效性。|
|228|[DiffBIR: Towards Blind Image Restoration with Generative Diffusion Prior](https://arxiv.org/abs/2308.15070)|我们提出了DiffBIR，这是一种通用的修复管道，能够在统一的框架下处理不同的盲目图像修复任务。DiffBIR将盲目的图像修复问题分为两个阶段：1) 降质去除：移除与图像内容无关的部分；2) 信息再生：生成丢失的图像内容。每个阶段独立开发，但它们以级联的方式无缝协作。在第一阶段，我们使用修复模块来移除退化并获得高保真度的修复结果。对于第二阶段，我们提出了IRControlNet，它利用潜在扩散模型的生成能力来生成逼真的细节。具体来说，IRControlNet是基于特别制作的条件图像进行训练的，这些图像没有分散注意力的噪声内容，以实现稳定的生成性能。此外，我们设计了一种区域自适应的修复指导方法，该方法能够在推理过程中修改去噪过程而无需重新训练模型，允许用户通过可调节的指导尺度来平衡真实感和保真度。广泛的实验已经证明，DiffBIR在合成和现实世界数据集上，对于盲目图像超分辨率、盲脸修复和盲目图像去噪任务，相比最先进方法具有优越性。|
|229|[FreeU: Free Lunch in Diffusion U-Net](https://arxiv.org/abs/2309.11497)|在本文中，我们揭示了扩散U-Net中未被挖掘的潜力，它作为一种“免费午餐”，能够实时显著提升生成质量。我们首先研究了U-Net架构在去噪过程中的关键贡献，并发现其主要骨干主要负责去噪，而跳过连接则主要将高频特征引入解码器模块，导致网络忽视了骨干语义。基于这一发现，我们提出了一种简单而有效的方法——称为“FreeU”——无需额外训练或微调即可增强生成质量。我们的核心洞察是策略性地重新权衡来自U-Net跳过连接和骨干特征图的贡献，以利用U-Net架构两个部分的优势。在图像和视频生成任务上的有希望的结果表明，我们的FreeU可以轻松地集成到现有的扩散模型中，例如Stable Diffusion、DreamBooth、ModelScope、Rerender和ReVersion，仅通过几行代码即可提高生成质量。您只需在推理期间调整两个缩放因子即可。|
|230|[Navigating Text-To-Image Customization: From LyCORIS Fine-Tuning to Model Evaluation](https://arxiv.org/abs/2309.14859)|文本到图像的生成模型因其能根据文本提示生成高保真图像而获得了巨大关注。在这些模型中，Stable Diffusion作为这一快速发展的领域中的一个领先的开源模型脱颖而出。然而，微调这些模型的复杂性带来了从新方法整合到系统评估的多重挑战。为了解决这些问题，本文介绍了LyCORIS（Lora超越传统方法，Stable Diffusion的其他秩适应实现）[此链接](https URL)，这是一个开源库，为Stable Diffusion提供了广泛的微调方法选择。此外，我们提出了一套全面的框架来系统地评估各种微调技术。该框架利用了多样化的指标集合，并深入探讨了微调的多个方面，包括超参数调整以及使用不同类型提示跨不同概念类别进行的评估。通过这种综合方法，我们的工作为理解微调参数的细微效果提供了关键洞察，弥合了最前沿研究与实际应用之间的差距。|
|231|[Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference](https://arxiv.org/abs/2310.04378)|潜在扩散模型（LDMs）在合成高分辨率图像方面取得了显著成果。然而，迭代采样过程计算密集型导致生成速度缓慢。受到一致性模型（Song等人提出）的启发，我们提出了潜在一致性模型（LCMs），使任何预训练的LDMs，包括Stable Diffusion（Rombach等人提出）都能以最少的步骤进行快速推理。将引导的反向扩散过程视为求解增强的概率流偏微分方程（PF-ODE），LCMs旨在直接预测该方程在潜在空间中的解，减少了对众多迭代的需求，从而允许快速、高保真度的采样。高效地从预训练的无分类器引导扩散模型中提炼而出，一个高质量的768x768分辨率、只需2~4步的LCM仅需32个A100 GPU小时进行训练。此外，我们引入了潜在一致性微调（LCF）方法，这是专门为在定制图像数据集上微调LCMs而设计的新技术。在LAION-5B-Aesthetics数据集上的评估显示，LCMs凭借少量步骤的推理达到了文本到图像生成的最先进性能。|
|232|[Cross-Image Attention for Zero-Shot Appearance Transfer](https://arxiv.org/abs/2311.03335)|最近的文本到图像生成模型在捕获图像的深层语义理解方面显示出了惊人的能力。在这项工作中，我们利用这种语义知识来转移具有相似语义但在形状上可能有显著差异的物体之间的视觉外观。为了实现这一目标，我们基于这些生成模型的自注意力层，并引入了一种跨图像注意力机制，该机制隐式地建立了图像间的语义对应。具体而言，给定一对图像——一幅描绘目标结构，另一幅指定所需外观——我们的跨图像注意力将与结构图像对应的查询与外观图像的键和值相结合。当在去噪过程中应用此操作时，它利用建立的语义对应关系生成结合了所需结构和外观的图像。此外，为了提高输出图像的质量，我们利用了三种机制，这些机制要么在去噪过程中操控噪声潜码，要么操控模型的内部表示。重要的是，我们的方法是零样本的，无需优化或训练。实验表明，我们的方法在广泛的对象类别中有效，并且对于两幅输入图像在形状、大小和视角上的变化具有鲁棒性。|
|233|[Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models](https://arxiv.org/abs/2311.12092)|我们提出了一种创建可解释性概念滑块的方法，该方法使用户能够精确控制从扩散模型生成图像时的属性。我们的方法识别出与单个概念相对应的低秩参数方向，同时最大限度地减少对其他属性的干扰。滑块通过一小组提示或样本图像创建；因此，滑块方向可以针对文本或视觉概念创建。概念滑块具有即插即用的特点：它们可以被高效地组合并进行连续调节，从而实现对图像生成的精确控制。在与先前编辑技术的定量实验对比中，我们的滑块展现出更强的针对性编辑能力且干扰更小。我们展示了用于控制天气、年龄、风格和表情的概念滑块，以及滑块组合的应用。我们演示了如何使用滑块转移StyleGAN中的潜在代码，以便于直观编辑那些难以用文本描述的视觉概念。同时，我们也发现我们的方法能帮助解决Stable Diffusion XL中持续存在的质量问题，包括修复物体形变和修正扭曲的手部。|
|234|[Diffusion Model Alignment Using Direct Preference Optimization](https://arxiv.org/abs/2311.12908)|大型语言模型（LLMs）通过使用基于人类反馈的强化学习（RLHF）方法和人类比较数据进行微调，以更好地与用户偏好保持一致。相比之下，人类偏好学习在文本到图像扩散模型中的应用并不广泛；现有的最佳方法是使用精心策划的高质量图像和说明文字来微调预训练模型，以提升视觉吸引力和文本一致性。我们提出了Diffusion-DPO这一方法，通过直接优化人类比较数据来使扩散模型与人类偏好保持一致。Diffusion-DPO借鉴了最近开发的直接偏好优化（DPO），这是RLHF的一种更简单替代方案，它直接优化在分类目标下最能满足人类偏好的策略。我们将DPO进行了调整，以考虑扩散模型中的似然性概念，利用证据下界来推导出可微分的目标函数。利用包含85.1万个众包成对偏好的Pick-a-Pic数据集，我们使用Diffusion-DPO对最先进的Stable Diffusion XL（SDXL）-1.0模型的基础模型进行了微调。经过微调的基础模型在人类评估中显著优于基础SDXL-1.0模型及更大的SDXL-1.0模型（该模型包含一个额外的细化模型），提升了视觉吸引力和提示一致性。此外，我们还开发了一个使用AI反馈的变体，其性能可与基于人类偏好的训练相媲美，为扩散模型对齐方法的规模化开辟了道路。|
|235|[DemoFusion: Democratising High-Resolution Image Generation With No $$$](https://arxiv.org/abs/2311.16973)|利用生成式人工智能（GenAI）进行高分辨率图像生成具有巨大潜力，但由于所需的巨额资本投入，这一领域日益集中在少数几家大公司手中，并隐藏在付费墙之后。本论文旨在通过推进高分辨率生成的前沿同时保持对广大受众的可及性，来使高分辨率的GenAI民主化。我们证明了现有的潜在扩散模型（LDMs）在高分辨率图像生成方面拥有未被充分利用的潜力。我们新颖的DemoFusion框架无缝扩展了开源的GenAI模型，采用逐步上采样、跳过残差和膨胀采样机制以实现更高分辨率的图像生成。DemoFusion的渐进性质需要更多的处理过程，但中间结果可作为“预览”，便于快速迭代提示。|
|236|[Image Super-Resolution with Text Prompt Diffusion](https://arxiv.org/abs/2311.14282)|图像超分辨率（SR）方法通常通过建模退化过程来提升在复杂和未知退化场景下的重建准确性。然而，从低分辨率图像中抽取退化信息极具挑战性，这限制了模型的表现。为了提升图像超分辨率性能，一个可行的途径是引入额外的先验知识。受多模态方法及基于文本提示的图像处理技术进步的启发，我们将文本提示引入图像超分辨率中，用以提供退化先验信息。具体而言，我们首先设计了一个文本-图像生成流程，通过文本退化表示和退化模型将文本整合到SR数据集中。文本表示采用了一种基于分箱方法的离散化方式来抽象描述退化情况，这种方法保持了文本的灵活性且用户友好。同时，我们提出了PromptSR来实现文本提示驱动的超分辨率。PromptSR利用预训练的语言模型（如T5或CLIP）来加强恢复效果，并在生成的文本-图像数据集上训练该模型。广泛的实验表明，将文本提示引入超分辨率处理，在合成图像和真实世界图像上均能取得优异的成果。|
|237|[MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model](https://arxiv.org/abs/2311.16498)|本文研究了人物图像动画任务，该任务旨在根据特定的动作序列生成具有某一参考身份的视频。现有的动画作品通常采用帧扭曲技术，使参考图像朝目标动作进行动画处理。尽管这些方法取得了合理的效果，但由于缺乏时间建模和对参考身份保存不佳，它们在动画全程维持时间一致性方面面临挑战。在本工作中，我们引入了MagicAnimate，这是一个基于扩散的框架，旨在增强时间一致性，忠实保留参考图像，并提高动画保真度。为此，我们首先开发了一个视频扩散模型来编码时间信息。其次，为了在帧间保持外观一致性，我们引入了一个新颖的外观编码器来保留参考图像的复杂细节。利用这两项创新，我们进一步采用了一种简单的视频融合技术，以促进长时间视频动画的平滑过渡。实证结果在两个基准上证明了我们方法相对于基线方法的优越性。特别地，在具有挑战性的TikTok舞蹈数据集上，我们的方法在视频保真度方面比最强的基线高出超过38%。代码和模型将会公开提供。|
|238|[SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution](https://arxiv.org/abs/2311.16518)|由于强大的生成先验，预训练的文本到图像（T2I）扩散模型在解决现实世界的图像超分辨率问题上日益受到欢迎。然而，由于输入低分辨率（LR）图像的质量严重退化，导致局部结构破坏，可能引起图像语义的模糊。因此，重建的高分辨率图像内容可能含有语义错误，从而影响超分辨率性能。为了解决这一问题，我们提出了一种语义感知的方法，以更好地保持生成的现实世界图像超分辨率的语义保真度。首先，我们训练了一个退化感知的提示提取器，即使在强烈的退化条件下也能生成准确的软性和硬性语义提示。硬性语义提示指的是图像标签，旨在增强T2I模型的局部感知能力，而软性语义提示则作为补充，提供额外的表征信息。这些语义提示能够促使T2I模型生成既详细又语义准确的结果。此外，在推理过程中，我们将LR图像融入初始采样噪声中，以减轻扩散模型产生过多随机细节的倾向。实验表明，我们的方法能够重现更真实的图像细节，并更好地保持图像的语义。|
|239|[CoSeR: Bridging Image and Language for Cognitive Super-Resolution](https://arxiv.org/abs/2311.16512)|现有的超分辨率（SR）模型主要侧重于恢复局部纹理细节，常常忽视场景中的全局语义信息。这一疏忽可能导致关键语义细节的遗漏或在恢复过程中引入不准确的纹理。在我们的工作中，我们引入了认知超分辨率（CoSeR）框架，使超分辨率模型具备理解低分辨率图像的能力。我们通过结合图像外观和语言理解来生成认知嵌入，这不仅激活了来自大型文本到图像扩散模型的先验信息，还促进了高质量参考图像的生成，从而优化超分辨率过程。为进一步提升图像保真度，我们提出了一种名为“全注意力注入”的新颖条件注入方案，将所有条件信息整合到单一模块中。因此，我们的方法成功地恢复了语义正确且逼真的细节，展示出在多个基准测试上的前沿性能。|
|240|[Adversarial Diffusion Distillation](https://stability.ai/research/adversarial-diffusion-distillation)|Stability AI 推出了对抗扩散蒸馏（ADD），一种新颖的训练方法，使大型图像扩散模型可以在仅1到4步内高效采样，同时保持高图像质量。通过使用评分蒸馏结合对抗性损失，在低步数采样（如一步或两步）中确保高图像保真度。SDXL Turbo 采用此技术，实现了单步图像生成，大幅减少了从50步到1步的需求，且仍保持前所未有的图像质量。|
|241|[Ranni: Taming Text-to-Image Diffusion for Accurate Instruction Following](https://arxiv.org/abs/2311.17002)|现有的文本到图像（T2I）扩散模型往往在解释复杂提示时遇到困难，特别是涉及到数量、对象-属性绑定及多主体描述的情况。在这项工作中，我们引入了一个语义面板作为从文本解码到图像的中间件，以支持生成器更好地遵循指令。该面板是通过大型语言模型辅助解析输入文本中的视觉概念并进行排列得到的，随后被注入去噪网络作为一种详细的控制信号，以补充文本条件。为了促进从文本到面板的学习，我们设计了一套精心设计的语义格式化协议，并辅以全自动的数据准备流程。得益于这样的设计，我们的方法——我们称之为Ranni，成功地增强了预训练的T2I生成器在文本可控性方面的能力。更重要的是，生成中间件的引入带来了一种更便捷的交互形式（即，直接调整面板中的元素或使用语言指令），并进一步允许用户精细定制他们的生成内容。基于此，我们开发了一个实用系统，并展示了其在连续生成和基于聊天的编辑方面的潜力。|
|242|[LEDITS++: Limitless Image Editing using Text-to-Image Models](https://arxiv.org/abs/2311.16711)|最近，文本到图像的扩散模型因其仅从文本输入就能生成高保真图像的惊人能力而受到越来越多的关注。随后的研究努力旨在利用并将其功能应用于实际的图像编辑中。然而，现有的图像到图像的方法往往效率低下，不精确，并且多功能性有限。它们要么需要耗时的微调，要么不必要地强烈偏离输入图像，要么不支持多个同时进行的编辑。为了解决这些问题，我们引入了LEDITS++，这是一种高效、多用途且精确的文本图像操作技术。LEDITS++的新颖反转方法无需调优或优化，只需几步扩散就能产生高保真度的结果。其次，我们的方法支持多个同时编辑，并且与架构无关。第三，我们使用了一种新的隐式掩膜技术，将更改限制在相关的图像区域。作为我们详尽评估的一部分，我们提出了新颖的TEdBench++基准。我们的结果展示了LEDITS++的能力及其相对于以往方法的改进。|
|243|[DreamSync: Aligning Text-to-Image Generation with Image Understanding Feedback](https://arxiv.org/abs/2311.17946)|尽管取得了广泛的成功，文本到图像模型（T2I）仍然难以生成既符合用户输入文本又具有审美吸引力的图像。我们引入了DreamSync，这是一种设计上的模型无关训练算法，旨在提高T2I模型对文本输入的忠实度。DreamSync基于TIFA评估框架的一个最新洞察构建——大型视觉-语言模型（VLM）能够有效识别生成图像与文本输入之间的细粒度差异。DreamSync利用这一洞察，在不需要任何标注数据的情况下训练T2I模型；它利用模型自身的生成来改进T2I模型。首先，它促使模型为给定的输入文本生成多个候选图像。然后，它使用两个VLM来选择最佳生成：一个是视觉问答模型，测量生成图像与文本的一致性；另一个则评估生成的审美质量。选择后，我们使用LoRA迭代地微调T2I模型，引导其生成向选定的最佳生成靠拢。DreamSync不需要任何额外的人工注释、模型架构更改或强化学习。尽管其简单，DreamSync通过多项基准测试（在TIFA上+1.7%，DSG1K上+2.9%，VILA审美上+3.4%）和人类评估证明了其能同时提高两种基于扩散的T2I模型的语义一致性与审美吸引力。|
|244|[Visual Anagrams: Generating Multi-ViewOptical Illusions with Diffusion Models](https://arxiv.org/abs/2311.17919)|我们探讨了合成多视角光学幻觉的问题：这类图像在经过变换（如翻转或旋转）后会改变外观。我们提出了一种简单且无需额外训练的方法，能从现成的文本到图像扩散模型中获得这些幻觉效果。在反向扩散过程中，我们从图像的不同视角估计噪声，然后将这些噪声估计合并起来，并对图像进行去噪。理论分析表明，此方法特别适用于可以表示为正交变换的视角，其中置换是其子集。这引出了“视觉字谜”的概念——即在像素重新排列下改变外观的图像。这不仅包括旋转和翻转，也涵盖了更奇特的像素排列方式，如拼图式的重新排列。我们的方法自然也扩展到了具有两个以上视角的幻觉生成。我们提供了定性和定量的结果，展示了我们方法的有效性和灵活性。|
|245|[Style Aligned Image Generation via Shared Attention](https://arxiv.org/abs/2312.02133)|大规模文本到图像（T2I）模型在创意领域迅速崭露头角，能够根据文本提示生成视觉上引人入胜的输出。然而，控制这些模型以确保风格的一致性仍然具有挑战性，现有方法通常需要微调和人工干预来分离内容和风格。在本论文中，我们介绍了一项名为StyleAligned的新技术，旨在实现一系列生成图像之间的风格对齐。通过在扩散过程中采用最小的“注意力共享”，我们的方法在T2I模型内部维持了图像间的风格一致性。这种方法允许通过简单的反转操作，使用参考风格创建风格一致的图像。我们在多种风格和文本提示下的评估表明，我们的方法能够实现高质量的合成和保真度，强调了其在不同输入之间实现风格一致性的有效性。|
|246|[X-Adapter: Adding Universal Compatibility of Plugins for Upgraded Diffusion Model](https://arxiv.org/abs/2312.02238)|我们引入了X-Adapter，作为一个通用的升级适配器，使得预训练的即插即用模块（例如，ControlNet、LoRA）能够在无需进一步重新训练的情况下直接与升级后的文本到图像扩散模型（例如，SDXL）协同工作。我们通过训练一个额外的网络来实现这一目标，该网络使用新的文本-图像数据对来控制冻结的升级模型。具体而言，X-Adapter保持了一个冻结的旧模型副本，以保留不同插件的连接器。此外，X-Adapter添加了可训练的映射层，这些层桥接了不同版本模型的解码器，用于特征重映射。重映射的特征将被用作升级模型的引导。为了增强X-Adapter的引导能力，我们为升级模型采用了无文本训练策略。训练后，我们还引入了两阶段去噪策略来校准X-Adapter和升级模型的初始潜在向量。得益于我们的策略，X-Adapter展示了与各种插件的普遍兼容性，并且还允许不同版本的插件协同工作，从而扩展了扩散模型社区的功能。为了验证所提出方法的有效性，我们进行了广泛的实验，结果显示X-Adapter可能促进在升级的基础扩散模型中的更广泛应用。|
|247|[LivePhoto: Real Image Animation with Text-guided Motion Control](https://arxiv.org/abs/2312.02928)|尽管文本到视频生成领域最近取得了进展，但现有研究通常忽视了一个问题，即合成视频中仅空间内容而非时间运动受文本控制。针对这一挑战，本工作提出了一套实用系统，名为LivePhoto，它使用户能够使用文本描述为感兴趣的图像添加动画。我们首先建立了一个强大的基线，帮助一个训练有素的文本到图像生成器（例如，Stable Diffusion）将图像作为进一步的输入。然后，我们为改进的生成器配备了一个运动模块进行时间建模，并提出了一个精心设计的训练流程，以便更好地将文本与运动联系起来。特别地，考虑到（1）文本只能粗略描述运动（例如，不考虑移动速度）以及（2）文本可能包含内容和运动的描述，我们引入了运动强度估计模块和文本重新加权模块来减少文本到运动映射的模糊性。实证证据表明，我们的方法能够很好地将与运动相关的文本指令解码成视频，比如动作、相机移动，甚至是凭空变出新内容（例如，向空杯子倒水）。有趣的是，得益于提出的强度学习机制，我们的系统除了文本之外，还为用户提供了额外的控制信号（即，运动强度），以便于视频定制。|
|248|[LooseControl: Lifting ControlNet for Generalized Depth Conditioning](https://arxiv.org/abs/2312.03079)|我们提出了LooseControl，以实现针对扩散式图像生成的广义深度条件化。作为深度条件化图像生成的最先进（SOTA）技术，ControlNet能产生显著成果，但依赖于精确深度图的引导。在许多场景下，创建如此精确的深度图极具挑战性。本文介绍了一种深度条件化的广义版本，它开启了众多新的内容创作工作流程。具体而言，我们允许：(C1) 场景边界控制：仅通过边界条件松散地指定场景，(C2) 3D框控制：指定目标对象的布局位置，而非对象的确切形状和外观。借助LooseControl以及文本引导，用户只需指定场景边界和主要对象的位置，就能创建复杂的环境（例如，房间、街景等）。此外，我们还提供了两种编辑机制来优化结果：(E1) 3D框编辑：允许用户在冻结图像风格的同时，通过改变、添加或移除框来细化图像。这样除了编辑框引发的变化外，其他改动最小。(E2) 属性编辑：提出可能的编辑方向，以改变场景的某一特定方面，如整体对象密度或特定对象。广泛的测试和与基线的比较证明了我们方法的通用性。我们相信，LooseControl能成为一种重要的设计工具，便于轻松创建复杂的环境，并可扩展到其他形式的引导通道中。|
|249|[A Task is Worth One Word: Learning with Task Prompts for High-Quality Versatile Image Inpainting](https://arxiv.org/abs/2312.03594)|实现高质量且多用途的图像修复，即根据用户意图用合理的内容填充用户指定的区域，是一个重大挑战。现有方法在同时解决上下文感知的图像修复和文本引导的对象修复方面面临困难，因为这两者需要不同的最佳训练策略。为克服这一挑战，我们推出了PowerPaint，这是首个在两项任务中均表现出色的高质量、多用途修复模型。首先，我们引入了可学习的任务提示以及定制的微调策略，以便显式指导模型针对不同的修复目标集中注意力。这使得PowerPaint能够通过使用不同的任务提示来完成各种修复任务，从而达到业界领先的表现。其次，我们通过展示任务提示在PowerPaint中作为对象移除的负面提示的有效性，证明了任务提示的多用性。此外，我们利用提示插值技术实现了可控的形状引导对象修复。最后，我们在多种图像修复基准上对PowerPaint进行了广泛评估，以展示其在多用途图像修复方面的卓越性能。|
|250|[MotionCtrl: A Unified and Flexible Motion Controller for Video Generation](https://arxiv.org/abs/2312.03641)|视频中的运动主要由两部分组成：一是由摄像机移动引起的摄像机运动，二是由物体移动导致的物体运动。对摄像机运动和物体运动两者进行精确控制对于视频生成至关重要。然而，现有工作要么主要聚焦于一种类型的运动，要么未能清晰地区分这两种运动，从而限制了它们的控制能力和多样性。因此，本文提出了MotionCtrl，一个统一且灵活的视频生成运动控制器，旨在有效且独立地控制摄像机运动和物体运动。MotionCtrl的架构和训练策略经过精心设计，考虑了摄像机运动、物体运动以及不完美训练数据的固有特性。与以往方法相比，MotionCtrl提供了三项主要优势：1) 它能有效且独立地控制摄像机运动和物体运动，实现更精细的运动控制，并促进了两种类型运动的灵活多变组合。2) 其运动条件由摄像机姿态和轨迹决定，这些条件与外观无关且对生成视频中物体的外观或形状影响最小。3) 作为一个相对泛化的模型，一旦经过训练，它能够适应广泛的摄像机姿态和轨迹。通过大量的定性和定量实验，验证了MotionCtrl相较于现有方法的优越性。|
|251|[AnimateZero: Video Diffusion Models are Zero-Shot Image Animators](https://arxiv.org/abs/2312.03793)|近年来，大规模的文本到视频（T2V）扩散模型在视觉质量、动作及时间一致性方面取得了显著进展。然而，生成过程仍是一个黑箱，所有属性（如外观、动作）都是共同学习和生成的，除了粗略的文本描述外，缺乏精确的控制能力。受到图像动画技术的启发，该技术将视频解耦为特定的外观与其对应的运动，我们提出了AnimateZero来揭示预训练的文本到视频扩散模型——即AnimateDiff，并为其提供了更精确的外观和动作控制能力。为了实现外观控制，我们从文本到图像（T2I）生成过程中借用中间潜在变量及其特征，确保生成的第一帧与给定的生成图像完全相同。为了实现时间控制，我们将原始T2V模型中的全局时间注意力替换为我们提出的带有位置校正的窗口注意力机制，以确保其他帧能良好地与第一帧对齐。得益于所提出的方法，AnimateZero无需进一步训练就能成功控制生成过程。作为一个针对给定图像的零样本图像动画器，AnimateZero还启用了包括交互式视频生成和真实图像动画在内的多种新应用。详尽的实验验证了所提方法在T2V及相关应用中的有效性。|
|252|[PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding](https://arxiv.org/abs/2312.04461)|近期在文本到图像生成领域的进步在根据给定文本提示合成逼真的人像照片方面取得了显著进展。然而，现有的个性化生成方法无法同时满足高效率、良好的身份（ID）保真度和灵活的文本可控性要求。在此工作中，我们介绍了PhotoMaker，一种高效的个性化文本到图像生成方法，其主要功能是将任意数量的输入ID图像编码为堆叠的ID嵌入，以保留ID信息。这样的嵌入作为一个统一的ID表示，不仅能全面封装同一输入ID的特点，还能适应不同ID的特性以供后续整合。这为更多吸引人且具有实际价值的应用铺平了道路。此外，为了驱动我们的PhotoMaker训练，我们提出了一种面向ID的数据构建管道来组装训练数据。在通过提议的管道构建的数据库滋养下，我们的PhotoMaker展示出了比基于测试时微调方法更好的ID保持能力，同时提供了显著的速度提升、高质量的生成结果、强大的泛化能力和广泛的应用范围。|
|253|[Inversion-Free Image Editing with Natural Language](https://arxiv.org/abs/2312.04965)|尽管基于反转的编辑技术最近取得了进展，但对于扩散模型来说，文本引导的图像操作仍然具有挑战性。主要瓶颈包括：1) 反转过程耗时较长；2) 在保持一致性与准确性之间的平衡存在困难；3) 与一致性模型中使用的高效一致性采样方法不兼容。为了解决上述问题，我们首先自问：是否可以消除编辑过程中的反转步骤。我们证明，当初始样本已知时，一种特殊的方差调度可以使去噪步骤简化为多步一致性采样的相同形式。我们称这种模型为去噪扩散一致性模型（Denoising Diffusion Consistent Model，简称DDCM），并指出它暗示了一种无需在采样中明确执行反转的虚拟反转策略。我们进一步在一个无需调优的框架中统一了用于文本引导编辑的注意力控制机制。将这些结合，我们提出了无反转编辑（Inversion-Free Editing，简称InfEdit），它允许对刚性和非刚性的语义变化进行一致且忠实的编辑，适应复杂修改的同时不损害图像的完整性和无需显式反转。通过广泛的实验，InfEdit在多种编辑任务中表现出强大的性能，并且保持了无缝的工作流程（在单个A40上少于3秒），展示了其在实时应用中的潜力。|
|254|[Smooth Diffusion: Crafting Smooth Latent Spaces in Diffusion Models](https://arxiv.org/abs/2312.04410)|最近，扩散模型在文本到图像（T2I）生成方面取得了显著进展，能够合成保真度高且内容多样的图像。尽管有这样的进步，扩散模型中的潜在空间平滑性仍然没有得到充分研究。平滑的潜在空间保证了对输入潜在的微小扰动会导致输出图像发生稳定的变化。这种特性在诸如图像插值、反转和编辑等下游任务中被证明非常有用。在此研究中，我们通过观察由微小的潜在变量变化导致的明显视觉波动，揭示了扩散模型潜在空间的非平滑性问题。为解决这一问题，我们提出了一种新的扩散模型类别——Smooth Diffusion，它能够在保持高性能的同时实现平滑性。具体而言，我们引入了逐层变化正则化方法，旨在任何扩散训练阶段强制任意输入潜在变量的变化与输出图像变化之间的比例保持恒定。此外，我们设计了一种插值标准差（ISTD）指标，以有效评估扩散模型潜在空间的平滑程度。大量的定量和定性实验表明，Smooth Diffusion不仅在文本到图像生成方面，而且在多种下游任务中，都是一个更为理想的解决方案。Smooth Diffusion被实现为一个即插即用的Smooth-LoRA模块，以便与各种社区模型协同工作。|
|255|[UDiffText: A Unified Framework for High-quality Text Synthesis in Arbitrary Images via Character-aware Diffusion Models](https://arxiv.org/abs/2312.04884)|近年来，基于扩散模型的文本到图像(T2I)生成方法获得了显著的关注。尽管这些图像合成方法能够产生视觉上吸引人的结果，但它们在生成图像中的文本渲染时经常出现拼写错误。这些错误表现为字符缺失、错误或多余，从而严重限制了基于扩散模型的文本图像生成的性能。为了解决上述问题，本文提出了一种新的文本图像生成方法，利用了预训练的扩散模型（即，Stable Diffusion [27]）。我们的方法包括设计和训练一个轻量级的字符级文本编码器，该编码器替代原有的CLIP编码器，提供更鲁棒的文本嵌入作为条件指导。然后，我们在大规模数据集上微调扩散模型，在字符级分割图监督下融入局部注意力控制。最后，通过采用推理阶段的细化过程，我们在任意给定图像中合成文本时实现了显著高的序列准确性。定性和定量的结果都证明了我们方法相对于最先进技术水平的优越性。此外，我们展示了所提出的UDiffText的几个潜在应用，包括以文本为中心的图像合成、场景文本编辑等。|
|256|[DreaMoving: A Human Video Generation Framework based on Diffusion Models](https://arxiv.org/abs/2312.05107)|在本论文中，我们介绍了一个名为DreaMoving的框架，这是一个基于扩散的可控视频生成框架，旨在生成高质量的定制化人类行为视频。具体来说，给定目标身份和姿态序列，DreaMoving能够生成在任意场景下由姿态序列驱动的目标身份移动或舞蹈的视频。为此，我们提出了一种用于运动控制的Video ControlNet以及一种用于保持身份特征的内容引导器(Content Guider)。所提出的模型易于使用，并且可以适应大多数风格化的扩散模型以生成多样化的结果。|
|257|[FreeControl: Training-Free Spatial Control of Any Text-to-Image Diffusion Model with Any Condition](https://arxiv.org/abs/2312.07536)|近期的方法，如ControlNet，为用户提供了对文本到图像(T2I)扩散模型的细粒度空间控制。然而，针对每种空间条件、模型架构和检查点，都需要训练辅助模块，这与人类设计师在内容创作过程中希望向AI模型传达的多样化的意图和偏好相冲突。在这项工作中，我们提出了FreeControl，这是一种无需训练的可控T2I生成方法，能够同时支持多种条件、架构和检查点。FreeControl设计了结构引导以促进与引导图像的结构对齐，并设计了外观引导以允许使用相同种子生成的图像之间共享外观。广泛的定性和定量实验表明，FreeControl在各种预训练的T2I模型上表现出了卓越的性能。特别是，FreeControl方便地提供了对多种不同架构和检查点的无需训练的控制，允许使用大多数现有无训练方法无法处理的具有挑战性的输入条件，并且在合成质量上达到了基于训练方法的竞争水平。|
|258|[FreeInit: Bridging Initialization Gap in Video Diffusion Models](https://arxiv.org/abs/2312.07537)|尽管基于扩散的视频生成技术已经取得了快速进展，但现有模型的推理结果仍然表现出不尽如人意的时间一致性与不自然的动力学特性。在本文中，我们深入探究了视频扩散模型中的噪声初始化问题，并发现了导致不尽如人意推理质量的隐含训练-推理差距。我们的关键发现包括：1) 推理时初始潜在空间在时空频率分布上本质上与训练时不同；2) 去噪过程极大地受到初始噪声低频成分的影响。受这些观察启发，我们提出了一种简洁而有效的推理采样策略——FreeInit，它显著提高了扩散模型生成视频的时间一致性。通过在推理过程中迭代细化初始潜在空间的时空低频成分，FreeInit能够弥补训练与推理之间的初始化差距，从而有效改善生成结果中的主体外观与时间一致性。广泛实验表明，FreeInit一致地提升了各类文本到视频生成模型的生成效果，无需额外训练。|
|259|[SCEdit: Efficient and Controllable Image Diffusion Generation via Skip Connection Editing](https://arxiv.org/abs/2312.11392)|图像扩散模型已被应用于多种任务中，如文本到图像生成和可控图像合成。近期的研究引入了微调方法，对原始模型进行细微调整，在基础生成扩散模型的特定适应中取得了有希望的结果。我们并没有修改扩散模型的主要骨干，而是深入探讨了U-Net中跳过连接的作用，并发现跨编码器和解码器聚合长距离信息的层次特征对图像生成的内容和质量有着显著影响。基于这一观察，我们提出了一种高效的生成微调框架，名为SCEdit，它利用一个名为SC-Tuner的轻量级微调模块集成并编辑跳过连接。此外，所提出的框架通过使用可控SC-Tuner注入不同的条件，允许简单地扩展到可控图像合成，简化并统一了多条件输入的网络设计。我们的SCEdit由于其轻量级的微调器，仅向解码器块传递反向传播，大大减少了训练参数、内存使用和计算成本。在文本到图像生成和可控图像合成任务上进行的广泛实验，证明了我们方法在效率和性能方面的优越性。|
|260|[MagicScroll: Nontypical Aspect-Ratio Image Generation for Visual Storytelling via Multi-Layered Semantic-Aware Denoising](https://arxiv.org/abs/2312.10899)|视觉叙事常常利用非典型长宽比的图像形式，如卷轴画、连环漫画和全景图，来创造富有表现力和吸引力的故事。尽管生成式人工智能已经取得了巨大成功，并展现出重塑创意产业的潜力，但要生成具有任意尺寸、可控风格、概念和布局的连贯且吸引人的内容仍是一大挑战，而这一切对于视觉叙事至关重要。为了克服以往方法存在的重复内容、风格不一致及缺乏可控性等缺点，我们提出了MagicScroll，这是一个多层次、渐进式扩散模型的图像生成框架，具有创新的语义感知去噪过程。该模型能够在物体、场景和背景层面上，通过文本、图像和布局条件实现对生成图像的细粒度控制。我们还建立了首个针对视觉叙事的非典型长宽比图像生成基准，涵盖绘画、漫画和电影全景等媒介，并采用了定制化指标进行系统评估。通过对比和消融研究，MagicScroll展示出了在与叙述文本保持一致、提升视觉连贯性和吸引观众方面的良好成效。我们计划发布代码和基准，以期促进AI研究者与视觉叙事领域的创意实践者之间更好的合作。|
|261|[StreamDiffusion: A Pipeline-level Solution for Real-time Interactive Generation](https://arxiv.org/abs/2312.12491)|我们介绍StreamDiffusion，这是一种专为交互式图像生成设计的实时扩散处理管线。现有的扩散模型擅长根据文本或图像提示创建图像，但在实时互动方面往往存在不足。这一局限性在需要高吞吐量的场景中尤为明显，比如元宇宙、直播视频和广播等涉及连续输入的情况。为了解决这一问题，我们提出了一种新方法，将原有的顺序去噪过程转变为批处理去噪过程。Stream Batch消除了传统的等待与交互模式，实现了流畅且高吞吐量的数据流。为了处理数据输入频率与模型吞吐量之间的不匹配，我们设计了一个新颖的输入输出队列，以便并行化流处理过程。此外，现有的扩散处理管线使用了无分类器引导（Classifier-Free Guidance, CFG），这需要额外的U-Net计算。为了减少冗余计算，我们提出了一个新颖的剩余无分类器引导（Residual Classifier-Free Guidance, RCFG）算法，将负条件去噪步骤的数量减少到仅一步甚至为零。此外，我们引入了一个随机相似度滤波器（Stochastic Similarity Filter, SSF）来优化功耗。我们的Stream Batch方法在不同去噪级别上相比顺序去噪方法实现了约1.5倍的速度提升。所提出的RCFG方法比传统CFG的运行速度提高了最高至2.05倍。结合我们提出的策略和现有的成熟加速工具，使得图像到图像的生成在单个RTX4090上达到了最高91.07fps，相比Diffusers开发的AutoPipeline提升了超过59.56倍的吞吐量。此外，我们提出的StreamDiffusion还在单个RTX3060上减少了2.39倍、在单个RTX4090上减少了1.99倍的能量消耗。|
|262|[DreamTuner: Single Image is Enough for Subject-Driven Generation](https://arxiv.org/abs/2312.13691)|基于扩散的模型在文本到图像生成方面展示了令人印象深刻的能力，并有望应用于受试者驱动的个性化生成，这需要利用一到几张参考图像生成定制化的概念。然而，现有的基于微调的方法未能在受试者学习与保持预训练模型生成能力之间取得平衡。此外，其他利用额外图像编码器的方法由于编码压缩往往会导致受试者的重要细节丢失。为了解决这些挑战，我们提出了DreamTurner这一新颖方法，它从粗到细注入参考信息，以更有效地实现受试者驱动的图像生成。DreamTurner引入了一个受试者编码器用于粗略保持受试者身份，其中压缩的通用受试者特征在视觉-文本交叉注意力之前通过注意力层引入。然后，我们修改预训练文本到图像模型中的自注意力层为自-受试者-注意力层，以细化目标受试者的细节。在自-受试者-注意力中，生成的图像查询来自参考图像及其自身的详细特征。值得强调的是，自-受试者-注意力是一种有效、优雅且无需额外训练的方法，用于保持定制受试者的详细特征，可以作为推理期间即插即用的解决方案。最后，通过额外的受试者驱动微调，DreamTurner在受试者驱动的图像生成方面取得了显著的性能，其生成过程可以通过文本或其他条件（如姿势）控制。|
|263|[PIA: Your Personalized Image Animator via Plug-and-Play Modules in Text-to-Image Models](https://arxiv.org/abs/2312.13964)|最近在个性化文本到图像（T2I）模型上的进步已经彻底改变了内容创作，使非专业人士能够生成具有独特风格的惊艳图像。尽管前景可期，但通过文本在这些个性化图像中加入逼真的动态效果，在保留独特风格、高保真细节以及实现文本控制动态性方面带来了重大挑战。在本文中，我们介绍了PIA（Personalized Image Animator），它在与条件图像对齐、通过文本实现运动控制以及与多种个性化T2I模型的兼容性（无需特定调整）方面表现出色。为了实现这些目标，PIA建立在一个基础T2I模型之上，该模型配有训练有素的时间对齐层，使得任何个性化T2I模型都能无缝转换为图像动画模型。PIA的一个关键组成部分是条件模块的引入，该模块利用条件帧和帧间亲和力作为输入，在潜在空间中依据亲和力提示转移外观信息，指导单帧图像合成。这种设计缓解了外观相关的图像对齐内在挑战，并允许更专注于与运动相关的引导对齐。|
|264|[InstantID: Zero-shot Identity-Preserving Generation in Seconds](https://arxiv.org/abs/2401.07519)|在个性化图像合成方面，Textual Inversion、DreamBooth和LoRA等方法已经取得了重大进展。然而，它们的实际应用受到高存储需求、漫长的微调过程以及对多张参考图像需求的限制。相反，现有的基于ID嵌入的方法虽然只需一次前向推理，但也面临着挑战：它们要么需要对大量模型参数进行广泛的微调，要么与社区预训练模型不兼容，要么无法保持高度的面部保真度。为了解决这些局限性，我们引入了InstantID，一个基于扩散模型的强大解决方案。我们的即插即用模块仅使用单张面部图像就能熟练处理各种风格的图像个性化，同时确保高度保真。为此，我们设计了一个新颖的IdentityNet，通过施加强语义和弱空间条件，将面部和地标图像与文本提示相结合，引导图像生成。InstantID展现出卓越的性能和效率，在身份保存至关重要的实际应用中证明了其极高的价值。此外，我们的工作无缝集成到如SD1.5和SDXL等流行的预训练文本到图像扩散模型中，充当一个适应性强的插件。|
|265|[Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs](https://arxiv.org/abs/2401.11708)|扩散模型在文本到图像的生成与编辑方面展现出了卓越的性能。然而，现有方法在处理涉及多个带有多种属性及关系的对象的复杂文本提示时，常常面临挑战。在本文中，我们提出了一种全新的无需训练的文本到图像生成与编辑框架，名为“重新描述、规划与生成”（Recaption, Plan and Generate，简称RPG），利用多模态大规模语言模型（MLLM）强大的链式思维推理能力来增强文本到图像扩散模型的组合性。我们的方法借助MLLM作为全局规划者，将生成复杂图像的过程分解为子区域内的多个更简单的生成任务。我们提出了互补区域扩散，以实现按区域的组合生成。此外，我们在提出的RPG框架内以闭环方式集成了文本引导的图像生成与编辑，从而增强了泛化能力。广泛的实验表明，我们的RPG超越了包括DALL-E 3和SDXL在内的最先进文本到图像扩散模型，特别是在多类别对象组合和文本-图像语义对齐方面。值得注意的是，我们的RPG框架展现出与多种MLLM架构（如MiniGPT-4）和扩散模型主干（如ControlNet）的广泛兼容性。|
|266|[Diffuse to Choose: Enriching Image Conditioned Inpainting in Latent Diffusion Models for Virtual Try-All](https://arxiv.org/abs/2401.13795)|随着在线购物的增长，买家能够在自己的设置中虚拟可视化商品的能力——我们定义为“虚拟试穿一切”——变得至关重要。最近的扩散模型本质上包含了一个世界模型，使它们在图像修复的背景下适合执行此任务。然而，传统的基于图像条件的扩散模型往往无法捕捉产品的精细细节。相比之下，以个性化为导向的模型，如DreamPaint，擅长保留物品的细节，但并未针对实时应用进行优化。我们推出了“扩散以选择”，这是一种新颖的基于扩散的、图像条件下的修复模型，该模型能高效地平衡快速推理与保留给定参考物品中的高保真细节，同时确保对给定场景内容进行准确的语义操作。我们的方法基于将来自参考图像的细粒度特征直接融入主扩散模型的潜在特征图中，并结合使用感知损失进一步保留参考物品的细节。我们在内部及公开可用的数据集上进行了广泛测试，展示出“扩散以选择”相比现有的零样本扩散修复方法以及少数样本扩散个性化算法（如DreamPaint）更具优越性。|
|267|[Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild](https://arxiv.org/abs/2401.13627)|我们推出了SUPIR（Scaling-UP图像恢复），这是一种开创性的图像恢复方法，它利用了生成式先验和模型规模扩大的力量。通过采用多模态技术与先进的生成式先验，SUPIR在智能和逼真的图像恢复领域取得了显著进展。作为SUPIR内部的关键催化剂，模型规模化极大地增强了其功能，并为图像恢复展示了新的潜力。我们收集了一个包含2000万张高分辨率、高质量图像的数据集用于模型训练，每张图像都配有详细的文本注释。SUPIR提供了依据文本提示恢复图像的功能，拓宽了其应用范围和潜力。此外，我们引入了负质量提示以进一步提升感知质量。我们还开发了一种恢复导向的采样方法，以抑制在基于生成的恢复过程中遇到的保真度问题。实验显示了SUPIR卓越的恢复效果及其通过文本提示操控恢复的创新能力。|
|268|[Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation](https://arxiv.org/abs/2402.10210)|在生成式人工智能（GenAI）领域中，对扩散模型进行微调仍然是一个探索不足的前沿领域，尤其与大型语言模型（LLMs）微调取得的显著进展相比。尽管像Stable Diffusion（SD）和SDXL这样的尖端扩散模型依赖于有监督的微调，但它们的性能在接触到一定量的数据后必然会达到一个高原期。近期，已经采用强化学习（RL）通过人类偏好数据来微调扩散模型，但这至少需要为每个文本提示提供两张图片（“胜者”和“败者”图片）。在本文中，我们介绍了一种名为自对弈微调扩散模型的创新技术（SPIN-Diffusion），其中扩散模型与其早期版本进行竞争，促进了一个迭代自我改进的过程。我们的方法为传统的有监督微调和RL策略提供了替代方案，显著提高了模型的性能和对齐度。在Pick-a-Pic数据集上的实验显示，从第一轮迭代开始，SPIN-Diffusion就在人类偏好对齐和视觉吸引力方面超越了现有的有监督微调方法。到第二轮迭代时，它在所有指标上超过了基于RLHF（Reinforcement Learning from Human Feedback）方法的性能，且所需数据量更少。|
|269|[SDXL-Lightning: Progressive Adversarial Diffusion Distillation](https://arxiv.org/abs/2402.13929)|我们提出了一种扩散蒸馏方法，该方法基于SDXL，在一步/少步1024像素的文本到图像生成中达到了新的最佳水平。我们的方法结合了渐进式和对抗性蒸馏，以在质量和模式覆盖之间取得平衡。在本文中，我们讨论了理论分析、判别器设计、模型公式以及训练技术。我们开源了我们经过蒸馏的SDXL-Lightning模型，既提供了LoRA格式也提供了完整的UNet权重。|
|270|[EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions](https://arxiv.org/abs/2402.17485)|在本工作中，我们致力于提升说话头部视频生成的真实感与表现力，重点聚焦于音频线索与面部动作之间动态且细微的关系。我们指出了传统技术的局限性，这些技术往往未能捕捉到人类表情的全谱系及个体面部风格的独特性。为了解决这些问题，我们提出了EMO这一新颖框架，该框架采用直接的音频到视频合成方法，绕过了对中间三维模型或面部标志点的需要。我们的方法确保了视频中帧间过渡的平滑以及身份特征的一致保存，从而产生了高度表现力和逼真的动画效果。实验结果证明，EMO不仅能生成令人信服的说话视频，还能生成各种风格的唱歌视频，在表现力和真实感方面显著优于现有最先进的方法。|
|271|[Transparent Image Layer Diffusion using Latent Transparency](https://arxiv.org/abs/2402.17113)|我们介绍了LayerDiffuse，这是一种方法，使得大型预训练的潜在扩散模型能够生成透明图像。该方法不仅能够生成单个透明图像，还能生成多个透明图层。该方法学习了一种“潜在透明性”，它将alpha通道透明度编码到预训练的潜在扩散模型的潜在流形中。为了保持大型扩散模型的生产级质量，它通过将新增加的透明度作为潜在偏移量来调节，并对预训练模型的原始潜在分布做最小改动。这样一来，任何潜在扩散模型都可以通过使用调整后的潜在空间进行微调，从而转换成透明图像生成器。我们采用一种包含人为交互的收集方案，使用100万对透明图像图层对对该模型进行训练。我们展示了潜在透明性可以应用于不同的开源图像生成器，或者适应于多种条件控制系统，以实现诸如前景/背景条件的图层生成、联合图层生成、图层内容的结构化控制等应用。用户研究发现，在大多数情况下（97%），用户更偏好我们原生生成的透明内容，而不是之前采用的临时解决方案，如先生成后抠图。用户还反馈，我们生成的透明图像质量可与Adobe Stock等真实的商业透明资源相媲美。|
|272|[Trajectory Consistency Distillation: Improved Latent Consistency Distillation by Semi-Linear Consistency Function with Trajectory Mapping](https://arxiv.org/abs/2402.19159)|潜变量一致性模型（LCM）将一致性模型扩展到潜空间，并利用引导一致性蒸馏技术，在加速文本到图像合成方面取得了令人瞩目的性能。然而，我们观察到LCM在生成既清晰又富含精细细节的图像方面存在困难。因此，我们引入了轨迹一致性蒸馏（TCD），它包含了轨迹一致性函数和策略性随机采样。轨迹一致性函数通过轨迹映射扩大自我一致性边界条件的范围，减少了参数化和蒸馏错误，并赋予TCD以指数积分器辅助的半线性形式精确追踪概率流ODE整个轨迹的能力。此外，策略性随机采样提供了对随机性的显式控制，规避了多步一致性采样中固有的累积误差。实验表明，TCD不仅在低NFE（网络前向评估次数）下显著提高了图像质量，而且在高NFE下相比教师模型能产生更多细节的成果。|
|273|[ResAdapter: Domain Consistent Resolution Adapter for Diffusion Models](https://arxiv.org/abs/2403.02084)|近期文本到图像模型（如Stable Diffusion）及其相应的个性化技术（例如DreamBooth和LoRA）的发展，使得个人能够生成高质量且富有想象力的图像。然而，它们在生成超出其训练领域分辨率的图像时，往往会遇到局限。为克服这一局限，我们提出了Resolution Adapter（ResAdapter），这是一种针对扩散模型设计的领域一致性适配器，旨在生成无限制分辨率和宽高比的图像。与那些通过复杂后处理操作处理静态分辨率图像的其他多分辨率生成方法不同，ResAdapter直接生成动态分辨率的图像。特别是，在深入学习了纯分辨率先验之后，ResAdapter通过在通用数据集上的训练，能够在保留原始风格领域的同时，利用个性化的扩散模型生成无分辨率限制的图像。全面的实验表明，仅需0.5M参数的ResAdapter即可为任意扩散模型处理具有灵活分辨率的图像。更进一步的实验显示，ResAdapter能与其它模块（如ControlNet、IP-Adapter和LCM-LoRA）兼容，用于跨广泛分辨率范围的图像生成，并且可以整合进其它多分辨率模型（如ElasticDiffusion）中，以高效生成更高分辨率的图像。项目链接为这个https网址。|
|274|[Stable Diffusion 3: Research Paper](https://stability.ai/news/stable-diffusion-3-research-paper)|Stability AI 发布了 Stable Diffusion 3 的研究论文，介绍了其最新的文本生成图像模型。Stable Diffusion 3 使用多模态扩散变换器 (MMDiT) 架构，通过分别处理图像和语言表征来提高文本理解和拼写能力。测试结果显示，Stable Diffusion 3 在视觉美学、提示遵循和排版方面优于当前最先进的生成系统。新模型还采用了重新加权的修正流方法，使采样步骤更少且性能更优。|
|275|[ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment](https://arxiv.org/abs/2403.05135)|扩散模型在文本到图像生成领域已展现出卓越的性能。然而，大多数广泛使用的模型仍采用CLIP作为其文本编码器，这限制了它们理解密集提示的能力，包括包含多个物体、详细属性、复杂关系、长文本对齐等。在本文中，我们引入了一个高效的大规模语言模型适配器，称为ELLA，它为文本到图像扩散模型配备了强大的大规模语言模型（LLM），以增强文本对齐能力，而无需训练U-Net或LLM。为了无缝连接两个预训练模型，我们研究了一系列语义对齐连接器设计，并提出了一个新模块——时间步感知语义连接器（TSC），它动态地从LLM中提取依赖于时间步的条件。我们的方法在去噪过程的不同阶段适应语义特征，帮助扩散模型在采样时间步上解释冗长和复杂的提示。此外，ELLA可以方便地与社区模型和工具结合，以提高它们遵循提示的能力。为了评估文本到图像模型在处理密集提示方面的能力，我们引入了密集提示图基准（DPG-Bench），这是一个包含1000个密集提示的具有挑战性的基准测试。广泛的实验表明，与最先进的方法相比，ELLA在遵循密集提示方面具有优越性，特别是在涉及多样属性和关系的多物体组合方面表现尤为突出。|
|276|[Audio-Synchronized Visual Animation](https://arxiv.org/abs/2403.05659)|当前的视觉生成方法能够借助文本引导产生高质量的视频，然而有效控制物体动态仍是一个挑战。本工作探索利用音频作为线索来生成时间上同步的图像动画。我们引入了“音频同步视觉动画”（Audio Synchronized Visual Animation, ASVA），这一任务旨在使静态图像动起来，展示运动动态，并通过跨多个类别的音频片段在时间上进行引导。为此，我们推出了AVSync15数据集，它从VGGSound中精选出视频，这些视频展现了横跨15个类别的音频与视觉事件的同步。同时，我们提出了一种扩散模型AVSyncD，该模型能够依据音频生成动态动画。广泛的评估验证了AVSync15作为同步生成可靠基准的有效性，并展示了我们模型的卓越性能。我们进一步探索了AVSyncD在多种音频同步生成任务中的潜力，包括从无基础图像生成完整视频到使用各种声音控制物体运动。我们希望我们建立的基准能够为可控的视觉生成开辟新的途径。|
|277|[Bridging Different Language Models and Generative Vision Models for Text-to-Image Generation](https://arxiv.org/abs/2403.07860)|文本到图像生成领域随着文本到图像扩散模型的引入取得了重大进展。这些模型通常包括一个解释用户提示的语言模型和一个生成相应图像的视觉模型。随着语言模型和视觉模型在其各自领域不断进步，探索用更高级的组件替代文本到图像扩散模型中的部分构成，存在着巨大潜力。因此，一个更广泛的研究目标是研究如何将任意两个不相关的语言模型和生成性视觉模型整合用于文本到图像生成。在本文中，我们探讨了这一目标，并提出了LaVi-Bridge这一管道，它使得多样化预训练语言模型和生成性视觉模型的集成成为可能，用于文本到图像的生成。通过利用LoRA和适配器，LaVi-Bridge提供了一种灵活的即插即用方法，无需修改原始语言和视觉模型的权重。我们的管道兼容多种语言模型和生成性视觉模型，适应不同的结构。在此框架内，我们证明了融入更高级模块，如更先进的语言模型或生成性视觉模型，能显著提升文本对齐或图像质量等方面的能力。我们进行了大量评估以验证LaVi-Bridge的有效性。|
|278|[Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering](https://arxiv.org/abs/2403.09622)|视觉文本渲染对当代文本到图像生成模型提出了一个根本性的挑战，核心问题在于文本编码器的缺陷。为了实现精确的文本渲染，我们确定了文本编码器需要满足的两个关键要求：字符感知能力和与字形的对齐。我们的解决方案涉及通过使用精心策划的配对字形-文本数据集微调字符感知的ByT5编码器，从而打造出一系列定制化的文本编码器——Glyph-ByT5。我们提出了一种有效的方法，将Glyph-ByT5与SDXL集成，由此创建了用于设计图像生成的Glyph-SDXL模型。这显著提高了文本渲染的准确性，在我们的设计图像基准上，将准确率从不到20%提升到了接近90%。值得注意的是，Glyph-SDXL新获得的文本段落渲染能力，对于几十到几百个字符，能够实现高拼写准确率并自动完成多行布局。最后，通过对Glyph-SDXL进行微调，使用一组高质量、逼真的包含视觉文本的图像，我们在开放领域的真实图像中的场景文本渲染能力方面展示了显著的改进。这些引人注目的成果旨在鼓励进一步探索，为多样和富有挑战性的任务设计定制化的文本编码器。|
|279|[OMG: Occlusion-friendly Personalized Multi-concept Generation in Diffusion Models](https://arxiv.org/abs/2403.10983)|个性化是文本到图像生成领域中的一个重要主题，特别是具有挑战性的多概念个性化。当前的多概念方法在身份保留、遮挡处理以及前景与背景之间的和谐性方面遇到了困难。在此工作中，我们提出了OMG（Occlusion-friendly Multi-concept Generation），一个对遮挡友好的个性化生成框架，旨在无缝地将多个概念整合到单一图像中。我们提出了一种新颖的两阶段采样解决方案。第一阶段负责布局生成及收集视觉理解信息以应对遮挡问题。第二阶段利用收集到的视觉理解信息及设计的噪声融合技术，在考虑遮挡的情况下融合多个概念。我们还观察到，用于噪声融合的去噪起始时间步是保持身份特征和布局的关键。此外，我们的方法可以与多种单概念模型结合使用，如LoRA和InstantID，无需额外调整。特别地，此http链接上的LoRA模型可直接加以利用。广泛的实验表明，OMG在多概念个性化方面表现出优越的性能。|
|280|[Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance](https://arxiv.org/abs/2403.14781)|本研究中，我们介绍了一种利用三维人体参数化模型在潜在扩散框架下进行人像动画的方法，旨在提升当前人像生成技术中的形状对齐与运动引导能力。该方法采用SMPL（Skinned Multi-Person Linear）模型作为三维人体参数化模型，建立了一个统一的身体形状和姿势表示，从而精确捕捉来自源视频的复杂人体几何和运动特征。具体而言，我们融入了从SMPL序列中获得的渲染深度图像、法线贴图和语义地图，以及基于骨架的运动引导，以此丰富潜伏扩散模型的条件，使其包含全面的三维形状及精细的姿势属性。此外，我们采用了融合自注意力机制的多层运动融合模块，在空间域中融合形状和运动的潜在表示。通过将三维人体参数化模型表达为运动引导，我们能够在参考图像和源视频运动之间执行人体参数形状对齐。在基准数据集上进行的实验评估表明，本方法能生成高质量的人像动画，准确捕捉姿势和形状变化，并且在提议的野外数据集上展现出优越的泛化能力。|
|281|[VersaT2I: Improving Text-to-Image Models with Versatile Reward](https://arxiv.org/abs/2403.18493)|近期的文本到图像（T2I）模型得益于大规模和高质量数据的支撑，展示了令人印象深刻的性能。然而，这些T2I模型仍面临挑战，难以生成既具有审美吸引力、几何精确度高、忠于文本内容且低层次质量优良的图像。我们提出了VersaT2I，这是一个多功能训练框架，能够通过多重奖励机制提升任何T2I模型的表现。我们将图像质量分解为多个方面，包括美学、图文一致性、几何准确性、低层次质量等。随后，针对每一项质量指标，我们选取模型生成的在此方面表现优异的高质量图像作为训练集，利用低秩适应（LoRA）方法对T2I模型进行微调。此外，我们引入了一个门控函数来整合多个质量方面，从而避免不同质量方面间的冲突。我们的方法易于扩展，无需任何手动标注、强化学习或模型架构改动。广泛的实验表明，VersaT2I在多种质量标准下均超越了基线方法。|
|282|[Getting it Right: Improving Spatial Consistency in Text-to-Image Models](https://arxiv.org/abs/2404.01197)|当前文本到图像（T2I）模型的主要缺点之一在于它们无法始终如一地生成忠实遵循文本提示中指定的空间关系的图像。在本文中，我们全面探讨了这一局限性，并同时开发了数据集和方法，以实现最先进的性能。首先，我们发现当前的视觉语言数据集未能充分表征空间关系；为缓解这一瓶颈，我们创建了SPRIGHT——首个空间聚焦的大规模数据集，通过对来自4个广泛使用的视觉数据集中的600万张图像进行重新标注而成。通过三重评估和分析流程，我们发现SPRIGHT在捕捉空间关系方面大大超越了现有数据集。为了展示其有效性，我们仅利用SPRIGHT约0.25%的数据，便在生成空间准确性高的图像方面实现了22%的提升，同时也改善了FID和CMMD分数。其次，我们发现针对包含大量物体的图像进行训练会在空间一致性上带来显著改进。值得注意的是，通过在不到500张图像上进行微调，我们在T2I-CompBench上达到了空间得分0.2133的最先进水平。最后，通过一系列控制实验和消融研究，我们记录了多条发现，我们认为这些发现将增进对影响文本到图像模型空间一致性因素的理解。我们公开发布了数据集和模型，以促进该领域的进一步研究。|
|283|[InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation](https://arxiv.org/abs/2404.02733)|无需调优的扩散模型在图像个性化和定制领域展示了巨大的潜力。然而，尽管取得了这一显著进展，当前模型在生成风格一致的图像时仍面临几个复杂挑战。首先，风格的概念本质上是不确定的，涵盖了诸如颜色、材质、氛围、设计和结构等众多元素。其次，基于反转的方法容易导致风格退化，常引起精细细节的丢失。最后，基于适配器的方法经常需要为每张参考图像精心调整权重，以在风格强度和文本可控性之间取得平衡。在本文中，我们首先探讨了几个引人注目却常被忽视的观察结果。随后，我们引入了InstantStyle框架，该框架通过实施两个关键策略来应对这些问题：1) 一种直接机制，在特征空间中从参考图像中解耦风格和内容，基于同一空间中的特征可以相互增减的假设。2) 仅将参考图像特征注入特定风格的模块中，从而防止风格泄露，并避免了繁琐的权重调整需求，而这通常是参数更重设计的特点。我们的工作展现了卓越的视觉风格化成果，实现了风格强度与文本元素可控性之间的最佳平衡。|
|284|[Cross-Attention Makes Inference Cumbersomein Text-to-Image Diffusion Models](https://arxiv.org/abs/2404.02747)|本研究探讨了在文本条件性扩散模型推理过程中交叉注意力的作用。我们发现，经过几次推理步骤后，交叉注意力的输出会收敛到一个固定点。相应地，收敛的时间点自然将整个推理过程分为两个阶段：初始的语义规划阶段，在此期间，模型依赖于交叉注意力来规划面向文本的视觉语义；以及随后的保真度提升阶段，在此阶段，模型尝试根据之前规划的语义生成图像。令人惊讶的是，在保真度提升阶段忽略文本条件不仅降低了计算复杂度，而且还能保持模型性能。这产生了一种简单且无需额外训练的方法，称为TGATE，用于高效生成。该方法在交叉注意力输出收敛后将其缓存，并在剩余的推理步骤中保持固定不变。我们在MS-COCO验证集上的实证研究表明了其有效性。|
|285|[CoMat: Aligning Text-to-Image Diffusion Modelwith Image-to-Text Concept Matching](https://arxiv.org/abs/2404.03653)|扩散模型在文本到图像生成领域已取得巨大成功。然而，缓解文本提示与图像之间的不匹配仍是一项挑战。造成这种不匹配的根本原因尚未得到深入探究。我们观察到，这种不匹配是由于标记注意力激活不足所致。我们进一步将这一现象归因于扩散模型的训练范式导致的条件利用不足。为解决这一问题，我们提出了CoMat，这是一种端到端的扩散模型微调策略，包含了图像到文本的概念匹配机制。我们利用图像字幕模型来衡量图像与文本的对齐程度，并指导扩散模型重新关注被忽略的标记。此外，还提出了一种新颖的属性集中模块，以解决属性绑定问题。无需任何图像数据或人类偏好数据，我们仅使用2万个文本提示来微调SDXL，从而获得CoMat-SDXL。广泛的实验表明，CoMat-SDXL在两个文本到图像对齐基准测试中显著优于基线模型SDXL，并达到了当前最优性能。|
|286|[LCM-Lookahead for Encoder-based Text-to-Image Personalization](https://arxiv.org/abs/2404.03620)|近期在扩散模型领域的进步引入了快速采样方法，这些方法能够在仅一或几个去噪步骤中有效生成高质量图像。有趣的是，当这些快速方法从现有扩散模型中提炼时，它们通常能与原始模型保持一致，对于相似的提示和种子产生相近的输出。这些特性为利用快速采样方法作为一种快捷机制提供了机会，即通过它们创建去噪输出的预览，并通过该预览反向传播图像空间的损失。在本工作中，我们探索了利用此类快捷机制指导文本到图像模型针对特定面部身份个性化潜力的可能性。我们专注于基于编码器的个性化方法，并展示通过使用前瞻性的身份损失进行微调，我们能在不牺牲布局多样性或提示对齐的情况下实现更高的身份保真度。我们进一步探讨了注意力共享机制及一致数据生成在个性化任务中的应用，发现编码器训练能从这两者中获益。|
|287|[Identity Decoupling for Multi-Subject Personalization of Text-to-Image Models](https://arxiv.org/abs/2404.04243)|文本到图像的扩散模型在基于少数参考图像生成个性化主体方面已显示出显著的成功。然而，当前方法在同时生成多个主体时常常失败，导致混合身份并带有来自不同主体的属性。在本工作中，我们提出了MuDI，一个新颖的框架，通过有效地区分多个主体的身份来实现多主体个性化。我们的主要思想是利用基础模型（Segment Anything）生成的分割主体，既用于训练也用于推理，作为训练的数据增强形式以及生成过程的初始化。此外，我们进一步引入了一项新指标，以更好地评估我们方法在多主体个性化方面的性能。实验结果表明，我们的MuDI能够生成高质量的个性化图像，不会混杂身份，即使对于如图1所示的高度相似的主体也是如此。具体来说，在人工评估中，MuDI在无身份混杂的情况下成功个性化多个主体的成功率是现有基线的两倍，并且在超过70%的情况下优于最强的基线。|
|288|[Aligning Diffusion Models by Optimizing Human Utility](https://arxiv.org/abs/2404.04465)|我们提出了Diffusion-KTO，这是一种创新的方法，通过将对齐目标表述为最大化预期的人类效用来调整文本到图像的扩散模型。由于该目标独立应用于每一个生成实例，Diffusion-KTO不需要收集成本高昂的成对偏好数据，也不需要训练复杂的奖励模型。相反，我们的目标只需要简单的每张图像二元反馈信号，例如喜欢或不喜欢，这类信号是大量存在的。经过Diffusion-KTO微调后，文本到图像的扩散模型在人类判断和自动评估指标（如PickScore和ImageReward）上，相较于现有技术，包括有监督微调和Diffusion-DPO，展现出更优越的性能。总的来说，Diffusion-KTO释放了利用现成的每张图像二元信号的潜力，拓宽了将文本到图像的扩散模型与人类偏好对齐的应用范围。|
|289|[ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback](https://arxiv.org/abs/2404.07987)|为了增强文本到图像扩散模型的可控性，现有工作如ControlNet引入了基于图像的条件控制。在本文中，我们指出现有方法在生成与图像条件控制相符的图像方面仍面临重大挑战。为此，我们提出了ControlNet++，这是一种新颖的方法，通过明确优化生成图像与条件控制之间的像素级循环一致性来改善可控生成。具体而言，对于输入的条件控制，我们使用预训练的判别性奖励模型从生成的图像中提取相应的条件，然后优化输入条件控制与提取条件之间的一致性损失。一种直接的实现方式是从随机噪声中生成图像，然后计算一致性损失，但这种方法需要为多个采样时间步存储梯度，导致显著的时间和内存成本。为了解决这个问题，我们引入了一种高效的奖励策略，通过故意向输入图像添加噪声来刻意干扰图像，然后使用单步去噪图像进行奖励微调。这避免了与图像采样相关的大量成本，使得奖励微调更加高效。广泛的实验表明，ControlNet++在各种条件控制下显著提高了可控性。例如，对于分割掩模、线稿边缘和深度条件，它分别比ControlNet提高了7.9%的mIoU、13.4%的SSIM和7.6%的RMSE。|
|290|[ROMPT-TO-PROMPT IMAGE EDITINGWITH CROSS-ATTENTION CONTROL](https://prompt-to-prompt.github.io/ptp_files/Prompt-to-Prompt_preprint.pdf)|最近，大规模的文本驱动合成扩散模型因其生成高度多样化的图像的显著能力而备受关注，这些图像遵循给定的文本提示。因此，自然而然地在这些合成模型的基础上开发文本驱动的图像编辑功能。然而，编辑对这些生成模型来说是一个挑战，因为编辑技术的固有特性是要保留原始图像的一些内容，而在文本驱动模型中，即使是文本提示的微小修改也常常会导致完全不同的结果。最先进的方法通过要求用户提供一个空间掩码来定位编辑区域来缓解这一问题，从而忽略了掩码区域内的原始结构和内容。在本文中，我们提出了一种直观的提示到提示编辑框架，其中编辑仅由文本控制。我们深入分析了一个文本条件模型，观察到交叉注意力层是控制图像空间布局与提示中每个词之间关系的关键。基于这一观察，我们提出在扩散过程中，通过注入原始图像的注意力图来控制编辑图像的注意力图。我们的方法使我们能够通过仅编辑文本提示来监控合成过程，为基于标题的编辑应用程序铺平道路，如通过替换词进行局部编辑、通过添加说明进行全局编辑，甚至控制一个词在图像中反映的程度。我们在不同的文本到图像模型上展示了我们在不同图像和提示上的结果，展示了高质量的合成和对编辑提示的忠实度。|
|291|[Adversarial Video Generation on Complex Datasets](https://arxiv.org/abs/1907.06571)|自然图像的生成模型通过大力利用规模优势，已朝着高保真样本取得了进步。我们试图将这一成功带入视频建模领域，通过展示在复杂Kinetics-600数据集上训练的大型生成对抗网络（GANs），能够产生比以往工作显著更高复杂度和保真度的视频样本。我们提出的模型，名为Dual Video Discriminator GAN（DVD-GAN），通过其判别器的计算高效分解，实现了对更长和更高分辨率视频的支持。我们在视频合成和视频预测相关任务上进行了评估，并在Kinetics-600数据集上的预测任务上达到了新的Fréchet Inception距离（FID）状态-of-the-art水平，同时在UCF-101数据集上的视频合成任务上达到了最优的Inception得分，并为Kinetics-600数据集的视频合成立下了坚实的基线。|
|292|[Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2304.08818)|潜在扩散模型（LDMs）能够在压缩的低维潜在空间中训练扩散模型，从而在避免过度计算需求的同时实现高质量的图像合成。在这里，我们将LDM范式应用于高分辨率视频生成，这是一个特别资源密集型的任务。我们首先仅在图像上预训练一个LDM；然后，通过向潜在空间扩散模型引入时间维度并在编码的图像序列（即视频）上进行微调，将图像生成器转变为视频生成器。类似地，我们对扩散模型的上采样器进行时间对齐，使它们成为时间上一致的视频超分辨率模型。我们关注两个相关的现实世界应用：野外驾驶数据的仿真以及通过文本到视频建模的创意内容创作。特别是，我们在512x1024分辨率的真实驾驶视频上验证了我们的Video LDM，达到了state-of-the-art的性能。此外，我们的方法可以轻松利用现成的预训练图像LDM，因为在这种情况下我们只需要训练一个时间对齐模型。通过这样做，我们将公开可用的、state-of-the-art的文本到图像LDM“Stable Diffusion”转变为一个高效且表现力强的文本到视频模型，分辨率高达1280x2048。我们展示了以这种方式训练的时间层可以泛化到不同微调的文本到图像LDM上。利用这一特性，我们展示了个性化文本到视频生成的首个成果，为未来的內容创作开辟了令人兴奋的方向。|
|293|[An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)|尽管Transformer架构已成为自然语言处理任务的实际标准，但其在计算机视觉领域的应用仍然有限。在视觉领域中，注意力机制要么与卷积网络结合使用，要么用来替换卷积网络中的某些组件，同时保持其整体结构不变。我们表明，这种对卷积神经网络（CNNs）的依赖并非必要，一个直接应用于图像块序列的纯Transformer就可以在图像分类任务上表现出色。当在大量数据上进行预训练，并转移到多个中等规模或小型的图像识别基准测试（如ImageNet、CIFAR-100、VTAB等）时，视觉Transformer（Vision Transformer，ViT）相比最先进的卷积网络能够取得优异的结果，同时在训练过程中需要的计算资源大幅减少。|
|294|[Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)|面对带有不可解析后验分布的连续潜变量及大规模数据集时，如何在有向概率模型中进行有效的推理与学习？我们介绍了一种随机变分推理与学习算法，该算法能够应对大规模数据集，并且在某些较为宽松的可微性条件下，即便是在后验难以解析的情况下也能工作。我们的贡献主要体现在两方面。首先，我们证明了对变分下界的重新参数化能得到一个可以通过标准随机梯度方法直接优化的下界估计器。其次，我们针对每条数据含连续潜变量的独立同分布(i.i.d.)数据集展示，通过使用提议的下界估计器来拟合一个近似推理模型（也称作识别模型）至不可解的后验分布上，可以使后验推理变得尤为高效。理论上的优势在实验结果中得到了印证。|
|295|[Deep Unsupervised Learning using Nonequilibrium Thermodynamics](https://arxiv.org/abs/1503.03585)|机器学习中的一个核心问题涉及使用高度灵活的概率分布族来建模复杂数据集，同时确保学习、采样、推理和评估在分析上或计算上都是可处理的。在这里，我们开发了一种同时实现灵活性和可处理性的方法。其基本思想来源于非平衡统计物理学，即通过迭代的正向扩散过程系统地、缓慢地破坏数据分布中的结构。然后，我们学习一个反向扩散过程来恢复数据中的结构，从而得到一个高度灵活且可处理的数据生成模型。这种方法使我们能够快速学习、从深层生成模型中采样并对数千层或时间步的概率进行评估，同时也能够在学习到的模型下计算条件概率和后验概率。此外，我们还发布了一个算法的开源参考实现。|
|296|[Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)|我们展示了使用扩散概率模型合成高质量图像的结果，这是一类受到非平衡热力学考虑启发的潜在变量模型。我们的最佳成果是通过训练一个加权变分界限获得的，该界限是根据扩散概率模型与带有朗格维动态的去噪得分匹配之间的一个新颖联系而设计的。我们的模型自然地允许一种渐进式的有损解压缩方案，可以解释为自回归解码的一种泛化。在无条件的CIFAR10数据集上，我们取得了9.46的Inception得分和3.17的最先进的FID得分。在256x256尺寸的LSUN数据集上，我们获得了与ProgressiveGAN相当的样本质量。|
|297|[Diffusion Models Beat GANs on Image Synthesis](https://arxiv.org/abs/2105.05233)|我们展示了扩散模型能够在图像样本质量上超过当前最先进的生成模型。我们通过对一系列消融实验寻找更优架构，在无条件图像合成上实现了这一点。对于条件图像合成，我们通过分类器引导进一步提高了样本质量：这是一种简单、计算效率高的方法，利用分类器的梯度在多样性与保真度之间进行权衡。我们在ImageNet 128×128上取得了2.97的FID分数，在ImageNet 256×256上取得了4.59，在ImageNet 512×512上取得了7.72，并且即使每个样本仅使用25次前向传播，我们也与BigGAN-deep相匹敌，同时保持了更好的分布覆盖度。最后，我们发现分类器引导与上采样扩散模型很好地结合，进一步将FID提高到ImageNet 256×256上的3.94和ImageNet 512×512上的3.85。|
|298|[Elucidating the Design Space of Diffusion-Based Generative Models](https://arxiv.org/abs/2206.00364)|我们认为当前基于扩散的生成模型理论与实践不必要地复杂化了，并试图通过展示一个明确区分具体设计选择的设计空间来改善这一状况。这使我们能够识别出对采样过程、训练过程以及分数网络预处理的几项改动。这些改进加在一起，使得我们的新方法在类别条件设置下为CIFAR-10数据集取得了1.79的新状态-of-the-art FID分数，在无条件设置下为1.97，且采样速度大大加快（每张图像仅需35次网络评估），比之前的方案更快。为了进一步展示这些改动的模块化特性，我们证明了这些设计改动显著提升了之前工作中预训练得分网络的效率和质量，包括将先前训练的ImageNet-64模型的FID从2.07提升到了接近最优的1.55，经过我们提出的改进后重新训练，更是达到了新的最优FID分数1.36。|
|299|[Generating Long Videos of Dynamic Scenes](https://arxiv.org/abs/2206.03429)|我们提出了一种视频生成模型，该模型能精确重现物体运动、相机视角变化以及随时间产生的新内容。现有的视频生成方法往往无法在保持真实环境预期的一致性（如合理的动态效果和物体持久性）的同时，作为时间的函数生成新内容。一个常见的失败情况是，由于过度依赖于提供时间一致性上的归纳偏置，如单一的潜在代码支配整个视频的内容，导致视频中的内容从未发生变化。另一方面，若缺乏长期一致性，生成的视频可能会在不同场景间不切实际地突变。为了解决这些局限性，我们通过重新设计时间轴上的潜在表示并利用更长的视频数据学习长期一致性，优先考虑时间维度。为此，我们采用了一个两阶段的训练策略，分别使用低分辨率的较长视频和高分辨率的较短视频进行训练。为了评估我们模型的能力，我们引入了两个新的基准数据集，特别着重于长时间尺度的时间动态。|
|300|[Generating Videos with Scene Dynamics](https://arxiv.org/abs/1609.02612)|我们利用大量的未标注视频数据来学习场景动态的模型，旨在服务于视频识别任务（例如动作分类）和视频生成任务（例如未来预测）。我们提出了一种针对视频的生成对抗网络，采用了时空卷积架构，该架构能够将场景的前景与背景分离。实验表明，与简单的基线相比，该模型能够以全帧率生成长达一秒的短视频，表现更优。同时，我们展示了其在预测静态图像的合理未来场景方面的实用性。此外，实验和可视化结果显示，该模型在内部学习到了对于仅需最少监督即可识别动作的有用特征，这表明场景动态是进行表征学习的一个有前景的信号。我们相信，生成式视频模型能够对视频理解和模拟领域的众多应用产生重要影响。|
|301|[Hierarchical Text-Conditional Image Generation with CLIP Latents](https://arxiv.org/abs/2204.06125)|像CLIP这样的对比学习模型已被证明能够学习到既捕捉语义又捕捉风格的鲁棒性图像表示。为了将这些表示用于图像生成，我们提出了一种两阶段模型：一个基于给定文本描述生成CLIP图像嵌入的先验模型，以及一个以该图像嵌入为条件生成图像的解码器。我们展示出，明确地生成图像表示能够提升图像多样性，同时几乎不损失照片真实感和与描述的相似度。我们的基于图像表示条件的解码器还能够生成图像的变体，这些变体在保留图像语义和风格的同时，改变那些在图像表示中缺失的非必要细节。此外，CLIP的联合嵌入空间使得以语言引导的图像编辑能够在零样本的情况下完成。我们在解码器部分使用了扩散模型，并在先验模型部分试验了自回归模型和扩散模型，发现后者在计算上更加高效且能生成质量更高的样本。|
|302|[Imagen Video: High Definition Video Generation with Diffusion Models](https://arxiv.org/abs/2210.02303)|我们介绍了Imagen Video，这是一个基于视频扩散模型级联的文本条件性视频生成系统。给定一个文本提示，Imagen Video利用一个基础视频生成模型和一系列交错的空间与时间视频超分辨率模型来生成高清视频。我们阐述了如何将该系统扩展为高清文本到视频模型，其中包括设计决策，例如在特定分辨率下选择全卷积的时间和空间超分辨率模型，以及选择扩散模型的v-参数化。此外，我们确认并转移了之前关于基于扩散的图像生成工作的研究成果至视频生成场景。最后，我们对视频模型应用了渐进式蒸馏，并采用了无分类器指导以实现快速、高质量的采样。我们发现，Imagen Video不仅能生成高保真度的视频，而且还具有高度可控性和丰富的世界知识，包括生成多种艺术风格的多样化视频和文本动画的能力，以及具备3D物体理解能力。|
|303|[Improved Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2102.09672)|去噪扩散概率模型（Denoising Diffusion Probabilistic Models，简称DDPM）是一类生成模型，最近已被证明能够产生卓越的样本。我们展示，通过一些简单的修改，DDPM不仅能保持高样本质量，同时还能实现有竞争力的对数似然性能。此外，我们发现学习反向扩散过程中的方差，允许用少一个数量级的前向传播步骤进行采样，而样本质量的差异可以忽略不计，这对于这些模型的实际部署至关重要。我们还使用查准率和查全率来比较DDPM和GAN在覆盖目标分布上的表现。最后，我们展示了这些模型的样本质量和似然性能随着模型容量和训练计算量的平滑增加，这使得它们易于扩展。|
|304|[Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)|近期的工作表明，在大规模文本语料上进行预训练，然后针对特定任务进行微调，能在众多NLP任务和基准测试上取得显著进步。尽管在架构上通常不针对特定任务，但这种方法仍然需要数千至数万个示例的特定任务微调数据集。相比之下，人类通常仅从几个例子或简单指令就能执行新的语言任务——这是当前NLP系统仍大多难以做到的。在这里，我们展示了扩大语言模型规模极大地提升了任务无关的、少量样本（few-shot）的表现，有时甚至能与先前的最优微调方法相竞争。具体来说，我们训练了GPT-3，一个具有1750亿参数的自回归语言模型，比以往任何非稀疏语言模型大10倍，并测试了其在少量样本设置下的性能。对于所有任务，GPT-3的应用都不涉及任何梯度更新或微调，任务和少量样本演示纯粹通过与模型的文本交互来指定。GPT-3在许多NLP数据集上表现出色，包括翻译、问答和完形填空任务，以及一些需要即时推理或领域适应的任务，如单词解码、在一个句子中使用新词或进行三位数算术。同时，我们也识别出一些GPT-3的少量样本学习仍然挣扎的数据集，以及一些由于在大型网络语料上训练而面临方法论问题的数据集。最后，我们发现GPT-3能生成新闻文章样本，这些样本人类评估者很难与人类撰写的文章区分开来。我们讨论了这一发现及GPT-3整体对社会更广泛的影响。|
|305|[Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377)|本论文展示了一种称为掩码自编码器（Masked Autoencoders, MAE）的计算机视觉可扩展自我监督学习方法。我们的MAE方法十分简洁：对输入图像的随机块进行掩码处理，并重建缺失的像素。该方法基于两个核心设计。首先，我们构建了一种不对称的编码器-解码器架构，其中编码器仅作用于可见的图像块子集（不含掩码令牌），而解码器则轻量级，负责从潜在表示和掩码令牌中重构原始图像。其次，我们发现高比例地掩码输入图像，例如75%，可以生成一个非平凡且富有意义的自我监督任务。结合这两个设计，我们能够高效且有效地训练大型模型：不仅加速了训练过程（提速3倍或更多），还提高了准确性。这种可扩展的方法使得学习高容量且泛化能力强的模型成为可能：例如，一个基础版本的ViT-Huge模型仅使用ImageNet-1K数据就达到了最佳准确率（87.8%）。在下游任务中的迁移性能超越了有监督预训练方法，并展现出良好的扩展性趋势。|
|306|[MoCoGAN: Decomposing Motion and Content for Video Generation](https://arxiv.org/abs/1707.04993)|在视频中的视觉信号可以被区分为“内容”与“运动”两个层面。其中，“内容”指定了视频中包含的物体是什么，“运动”则描绘了这些物体是如何动态变化的。基于这样的理解，我们提出了一种名为“运动与内容分解的生成对抗网络”（MoCoGAN）的框架，用于视频生成。该框架的工作原理是将一系列随机向量转换成视频帧序列来生成视频。每一个随机向量都包含两部分：内容部分和运动部分。在生成过程中，内容部分保持不变，而运动部分则通过一个随机过程来实现，以此来捕捉动态变化。为了在无监督的情况下学习如何分离运动和内容，我们创新性地设计了一个对抗学习方案，该方案同时使用了图像判别器和视频判别器。我们在多个具有挑战性的数据集上进行了广泛实验，并通过与当前最先进方法的定性和定量比较，验证了MoCoGAN框架的有效性。此外，我们还展示MoCoGAN能够灵活地生成两类视频：一类是内容相同但运动模式不同，另一类是运动相同而内容各异的视频，这进一步体现了该框架的强大功能和应用潜力。|
|307|[NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion](https://arxiv.org/abs/2111.12417)|本文介绍了一个统一的多模态预训练模型，名为“女娲”（NÜWA），该模型能针对多种视觉合成任务生成新的视觉数据（如图像和视频）或对现有视觉数据进行操纵。为了同时涵盖不同场景下的语言、图像和视频，设计了一个3D变换器编码-解码器框架。这一框架不仅能将视频作为3D数据处理，还能分别将文本和图像作为1D和2D数据适应处理。此外，还提出了一种3D邻近注意力（3DNA）机制，旨在考虑视觉数据的本质特性并降低计算复杂度。我们在8个下游任务上评估了NÜWA的表现。与几个强大的基线模型相比，NÜWA在文本到图像生成、文本到视频生成、视频预测等多个任务上达到了当时最优的结果。更进一步，它还在文本引导的图像及视频操纵等任务上展现了令人惊讶的零样本学习能力。|
|308|[Patch n' Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution](https://arxiv.org/abs/2307.06304)|将图像统一缩放到固定分辨率再输入计算机视觉模型进行处理这一普遍且已被证明次优的做法，至今未被有效挑战。然而，诸如视觉变换器（Vision Transformer, ViT）之类的模型提供了灵活的序列化建模方式，进而能够处理不同长度的输入序列。我们借此优势提出了NaViT（原生分辨率ViT），它在训练过程中利用序列打包来处理任意分辨率和长宽比的输入。除了实现模型使用的灵活性，我们还展示了在大规模有监督和对比图像-文本预训练中的训练效率提升。NaViT可以高效地迁移到诸如图像分类、视频分类、对象检测和语义分割等标准任务上，并在鲁棒性和公平性基准测试中取得了改进效果。在推理阶段，输入分辨率的灵活性可用来平滑地权衡测试时的成本与性能。我们认为，NaViT标志着大多数计算机视觉模型所采用的标准CNN设计的输入和建模流程的转变，代表了视觉变换器(ViTs)的一个有前景的发展方向。|
|309|[Photorealistic Video Generation with Diffusion Models](https://arxiv.org/abs/2312.06662)|我们提出了W.A.L.T，这是一种基于变换器的方法，通过扩散建模实现照片级真实感视频生成。我们的方法包含两个关键设计决策。首先，我们使用因果编码器在统一的潜在空间中联合压缩图像和视频，使跨模态的训练和生成成为可能。其次，为了内存和训练效率，我们采用了针对联合空间和时空生成建模定制的窗口注意力架构。综合这些设计决策，使我们能够在不使用无分类器自由引导的情况下，在已建立的视频（UCF-101和Kinetics-600）和图像（ImageNet）生成基准上达到最先进的性能。最后，我们还为文本到视频生成任务训练了一个由三个模型组成的级联，包括一个基础的潜在视频扩散模型，以及两个视频超分辨率扩散模型，以生成每秒8帧、分辨率为512×896的视频。|
|310|[Recurrent Environment Simulators](https://arxiv.org/abs/1704.02254)|能够模拟环境如何响应行为而变化的模型可被代理用于高效规划与行动。我们在基于高维度像素观测的先前环境模拟器基础上进行了改进，引入了循环神经网络，这些网络能够对未来数百个时间步做出在时间和空间上连贯的预测。我们深入分析了影响性能的因素，提供了最为全面的尝试以增进对这类模型特性的理解。我们通过构建一个不需要在每个时间步生成高维度图像的模型，解决了计算效率低下的问题。我们展示，我们的方法可用于改善探索过程，并能适应多种多样的环境，具体包括10款Atari游戏、一个3D赛车环境以及复杂的3D迷宫。|
|311|[Scalable Diffusion Models with Transformers](https://arxiv.org/abs/2212.09748)|我们探索了一类基于变压器架构的新扩散模型。我们训练了基于图像的潜在扩散模型，用在潜在斑块上操作的变压器替代了常用的U-Net主干。我们通过衡量Gflops（即每秒十亿次浮点运算）来分析我们所提出的“扩散变压器”(DiTs)的可扩展性。我们发现，通过增加变压器的深度/宽度或增加输入令牌的数量从而具有更高Gflops的DiTs，其FID（Fréchet inception distance，一种评估生成样本质量的指标）始终更低。除了具备良好的可扩展性外，我们最大的DiT-XL/2模型在条件类别ImageNet 512x512和256x256基准测试中超过了所有先前的扩散模型，后者达到了最先进的FID分数2.27。|
|312|[SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations](https://arxiv.org/abs/2108.01073)|引导式图像合成使得普通用户能够以最小的努力创建和编辑逼真的照片。主要挑战在于平衡对用户输入（例如，手绘彩色笔划）的忠实度和合成图像的真实感。现有的基于GAN的方法试图通过条件GAN或GAN反转来实现这种平衡，这很有挑战性，并且通常需要针对个别应用的额外训练数据或损失函数。为了解决这些问题，我们引入了一种新的图像合成与编辑方法——基于扩散模型生成先验的随机微分编辑（SDEdit），该方法通过迭代地通过随机微分方程（SDE）去噪来合成逼真的图像。给定带有任意类型用户指导的输入图像，SDEdit首先向输入添加噪声，然后通过SDE先验对得到的图像进行后续去噪，以增强其真实感。SDEdit不需要特定任务的训练或反转，并能自然地实现真实感与忠实度之间的平衡。根据一项人类感知研究，在包括基于笔画的图像合成与编辑以及图像合成在内的多项任务中，SDEdit在真实感方面比最先进基于GAN的方法高出最多98.09%，在总体满意度得分上高出91.72%。|
|313|[Unsupervised Learning of Video Representations using LSTMs](https://arxiv.org/abs/1502.04681)|我们利用多层长短期记忆（LSTM）网络来学习视频序列的表示。我们的模型使用一个编码器LSTM将输入序列映射到一个固定长度的表示。这个表示随后被单个或多个解码器LSTM所解码，以执行不同的任务，比如重构输入序列，或是预测未来的序列。我们试验了两种类型的输入序列——图像像素块和使用预训练卷积网络提取的视频帧的高级表示（“感知”）。我们探索了不同的设计选择，比如解码器LSTM是否应该基于生成的输出进行条件化。我们定性地分析模型的输出，以观察模型将学到的视频表示向未来和过去外推的能力如何。我们尝试可视化和解释学习到的特征。我们通过对更长时间尺度的数据以及领域外数据运行模型来进行压力测试。我们进一步通过微调这些表示以解决一个监督学习问题——在UCF-101和HMDB-51数据集上的人体动作识别，来评估这些表示的效果。我们展示了这些表示有助于提高分类准确性，特别是在只有少量训练样本的情况下。即使是那些在不相关数据集（如300小时的YouTube视频）上预训练的模型，也能帮助提升动作识别的表现。|
|314|[VideoGPT: Video Generation using VQ-VAE and Transformers](https://arxiv.org/abs/2104.10157)|我们提出了VideoGPT：一种概念简单明了的架构，旨在将基于似然的生成建模扩展到自然视频的大规模应用上。VideoGPT采用VQ-VAE方法，通过使用3D卷积和轴向自注意力技术，学习原始视频的下采样离散潜表示。之后，一个类似于GPT的简单架构利用时空位置编码，自回归地对这些离散潜表示进行建模。尽管在构建和训练上的简洁性，我们的架构却能够在BAIR机器人数据集上的视频生成任务上，生成与当前最先进GAN模型相竞争的样本，并能从UCF-101和Tumbler GIF数据集（TGIF）中生成高质量的自然视频。我们期望提出的这一架构能够作为基于变换器的视频生成模型最小化实现的可复现参考。|
|315|[ViViT: A Video Vision Transformer](https://arxiv.org/abs/2103.15691)|我们展示了基于纯变换器的视频分类模型，这一灵感来源于近期变换器模型在图像分类领域的显著成功。我们的模型从输入视频中提取时空令牌，然后通过一系列变换器层对这些令牌进行编码。为了处理视频中遇到的长序列令牌问题，我们提出了几种高效变体，它们对输入的空间和时间维度进行因子分解。虽然已知基于变换器的模型仅在有大量训练数据集可用时才最为有效，但我们展示如何在训练过程中有效地对模型进行正则化，并利用预训练的图像模型，从而能够在相对较小的数据集上进行训练。我们进行了深入的消融研究，并在包括Kinetics 400和600、Epic Kitchens、Something-Something v2以及Moments in Time在内的多个视频分类基准测试上取得了最先进的成果，超越了基于深度3D卷积网络的先前方法。|
|316|[World Models](https://arxiv.org/abs/1803.10122)|我们探索构建针对流行强化学习环境的生成神经网络模型。我们的世界模型能够以无监督的方式快速训练，以学习环境的压缩空间和时间表示。通过将从世界模型中提取的特征作为代理的输入，我们可以训练出一个非常紧凑且简单的策略来解决所需的任务。我们甚至可以让代理完全在其由世界模型产生的幻觉梦境中进行训练，并将此策略转移回实际环境之中。|
|317|[Zero-Shot Text-to-Image Generation](https://arxiv.org/abs/2102.12092)|传统的文本到图像生成主要集中在为固定数据集的训练寻找更佳的建模假设上。这些假设可能涉及到复杂的架构、辅助损失，或在训练期间提供的额外信息，如物体部件标签或分割掩模。我们介绍了一种基于变压器的简单方法来应对这一任务，该变压器自回归地将文本和图像令牌作为单一的数据流进行建模。在拥有足够的数据和规模的情况下，我们的方法在零样本评估下能与先前的领域特定模型相竞争。|
|318|[Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models](https://arxiv.org/abs/2402.17177)|Sora是一款由OpenAI于2024年2月发布的文本到视频生成AI模型。该模型被训练用于根据文本指令生成逼真或富有想象力场景的视频，并展示出了模拟物理世界的能力。本论文基于公开的技术报告和逆向工程，全面回顾了该模型的背景、相关技术、应用、遗留挑战及文本到视频AI模型的未来方向。我们首先追溯Sora的发展历程，并探究用于构建这一“世界模拟器”的底层技术。随后，我们详细描述了Sora在电影制作、教育到市场营销等多个行业中应用的详细情况及其潜在影响。我们讨论了为了广泛部署Sora需要解决的主要挑战和限制，比如确保视频生成的安全性和无偏见性。最后，我们探讨了Sora及视频生成模型的未来发展，以及该领域的进步如何能够开启人机交互的新方式，提升视频生成的生产力和创造力。|
|319|[A General Language Assistant as a Laboratory for Alignment](https://arxiv.org/abs/2112.00861)|鉴于大型语言模型的广泛能力，朝着与人类价值观一致的通用型、基于文本的助手努力应该是可行的，这意味着它应是有益的、诚实的且无害的。作为朝此方向迈出的初步尝试，我们研究了简单的基线技术和评估方法，例如提示技术。我们发现，通过适度的干预所获得的好处会随着模型规模的增大而增加，并能广泛适用于多种对齐评估，同时不会损害大型模型的性能。接下来，我们调查了几种与对齐相关训练目标的扩展趋势，比较了模仿学习、二元辨别以及排序偏好建模。我们发现，排序偏好建模的表现远优于模仿学习，并且通常随模型尺寸的扩大展现出更优的扩展性。相比之下，二元辨别通常的表现和扩展性与模仿学习非常相似。最后，我们研究了一个“偏好模型预训练”阶段，旨在通过微调来适应人类偏好时提高样本效率。|
|320|[Improving Language Understanding  by Generative Pre-Training]()||
|321|[Language Models are Unsupervised Multitask Learners]()||
|322|[Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://arxiv.org/abs/2303.12712)|人工智能(AI)研究者一直在开发和完善大型语言模型(LLMs)，这些模型在各种领域和任务中展现出了非凡的能力，挑战了我们对学习和认知的理解。OpenAI最新开发的模型GPT-4，采用了前所未有的计算规模和数据量进行训练。在这篇论文中，我们报告了对GPT-4早期版本的调查，该版本当时仍在OpenAI的积极开发中。我们认为（这一早期版本的）GPT-4属于新一代LLMs的一部分（包括ChatGPT和Google的PaLM等），这些模型相比之前的AI模型展示了更普遍的智能。我们讨论了这些模型不断上升的能力及其影响。我们证明，除了掌握语言之外，GPT-4无需特别提示即可解决跨越数学、编程、视觉、医学、法律、心理学等多个领域的新颖且困难的任务。而且，在所有这些任务中，GPT-4的表现接近人类水平，往往远远超过先前的模型，如ChatGPT。鉴于GPT-4能力的广度和深度，我们认为它可以合理地被视为一个人工通用智能(AGI)系统的早期（但仍不完整）版本。在探索GPT-4的过程中，我们特别强调发现其局限性，并讨论了向更深层次和更全面的AGI版本推进面临的挑战，包括可能需要追求超越下一个词预测的新范式。我们以对近期技术飞跃的社会影响反思和未来研究方向的展望作为结论。|
|323|[Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)|仅仅增大语言模型的规模并不意味着它们能更好地遵循用户的意图。例如，大型语言模型可能生成不真实的、有害的或对用户无帮助的输出。换句话说，这些模型与用户并不对齐。在本文中，我们展示了一条通过使用人工反馈进行微调来使语言模型在广泛任务上与用户意图对齐的途径。我们从标注员编写的提示和通过OpenAI API提交的提示开始，收集了一组标注员演示的期望模型行为数据，我们用这些数据通过监督学习来微调GPT-3。然后，我们收集了一组模型输出的排名数据，用这些数据通过来自人工反馈的强化学习进一步微调监督模型。我们称最终的模型为InstructGPT。在我们的提示分布上的人类评估中，13亿参数的InstructGPT模型的输出相比于1750亿参数的GPT-3更受偏好，尽管参数量少了100倍。此外，InstructGPT模型在提高真实性、减少有害输出生成的同时，在公共NLP数据集上的性能退步也极小。尽管InstructGPT仍然会犯一些简单的错误，但我们的结果显示，通过人工反馈进行微调是使语言模型与人类意图对齐的一个有希望的方向。|
|324|[Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)|在这项工作中，我们开发并发布了Llama 2，这是一系列预训练和微调后的大型语言模型（LLMs）的集合，其规模从70亿到700亿参数不等。我们微调后的LLMs，称为Llama 2-Chat，专门针对对话应用场景进行了优化。相较于我们测试的大多数基准，我们的模型超越了开源聊天模型，并且根据我们在有用性和安全性方面的人类评估，它们可能成为闭源模型的合适替代品。我们详细介绍了我们对Llama 2-Chat进行微调及安全改进的方法，以便让社区能够基于我们的工作，为LLMs的负责任发展做出贡献。|
|325|[Deep reinforcement learning from human preferences](https://arxiv.org/abs/1706.03741)|为了让复杂的强化学习（RL）系统与现实世界环境有效互动，我们需要向这些系统传达复杂的目标。在本工作中，我们探讨了一种以非专家人群对轨迹片段对的偏好来定义目标的方法。我们展示，即使在无法直接访问奖励函数的情况下，这种方法也能有效解决复杂的RL任务，包括Atari游戏和模拟的机器人移动，并且仅需对我们代理与环境交互的不到百分之一的反馈。这大大降低了人类监督的成本，使其可以实际应用于最先进的RL系统中。为了展示我们方法的灵活性，我们证明只需大约一个小时的人力投入就能成功训练出复杂的新型行为。这些行为和环境的复杂程度远远超过了以往任何从人类反馈中学习到的。|
|326|[Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356)|我们研究了仅训练以预测互联网上大量音频转录的语音处理系统的能力。当扩展到68万小时的多语言和多任务监督时，得到的模型能很好地泛化到标准基准上，且经常在零样本迁移设置下与先前的全监督结果相竞争，而无需任何微调。与人类相比，这些模型接近其准确性和鲁棒性。我们正在发布模型和推理代码，作为进一步开展鲁棒性语音处理工作的基础。|
|327|[A Cookbook of Self-Supervised Learning](https://arxiv.org/abs/2304.12210)|自我监督学习，被誉为智能的暗物质，是推动机器学习发展的有前景之路。然而，就像烹饪一样，训练自我监督学习（SSL）方法是一门讲究且入门门槛高的精细艺术。尽管许多组成部分都为人所熟知，但成功训练一个SSL方法涉及从预文本任务到训练超参数的一系列令人眼花缭乱的选择。我们的目标是通过编写一本类似食谱风格的手册，奠定SSL研究的基础并介绍最新的SSL方法，从而降低进入SSL研究的门槛。我们希望赋予好奇的研究者们导航方法领域的工具，理解各种调节因素的作用，并掌握探索SSL能带来多大魅力所需的技能。|
|328|[Attention is Not All You Need: Pure Attention Loses Rank Doubly Exponentially with Depth](https://arxiv.org/abs/2103.03404)|基于注意力的架构在机器学习中已经变得无处不在，但我们对其有效性的原因理解仍然有限。这项工作提出了一种理解自注意力网络的新方法：我们表明，其输出可以分解为一系列较小项的和，每一项都涉及到跨层的一系列注意力头的操作。利用这种分解，我们证明自注意力具有强烈的“令牌均匀性”归纳偏置。具体来说，如果没有跳过连接或多层感知器（MLPs），输出会双指数地收敛到一个秩为1的矩阵。另一方面，跳过连接和MLPs阻止了输出的退化。我们的实验在标准Transformer架构的不同变体上验证了所识别的收敛现象。|
|329|[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)|我们介绍了一个名为BERT的新语言表示模型，其全称为“基于变换器的双向编码器表示”。与最近的语言表示模型不同，BERT设计用于通过在所有层中同时条件化左右上下文，从无标签文本中预训练深度双向表示。因此，预训练的BERT模型只需额外添加一个输出层，就可微调以创建一系列任务的最先进模型，如问答和语言推理，无需对任务特定架构进行重大修改。BERT在概念上简单且在经验上强大。它在包括将GLUE评分推至80.5%（绝对提高了7.7个百分点）、MultiNLI准确率至86.7%（绝对提高了4.6个百分点）、SQuAD v1.1问题回答测试F1分数至93.2（绝对提高了1.5分）以及SQuAD v2.0测试F1分数至83.1（绝对提高了5.1分）在内的十一个自然语言处理任务上获得了新的最佳成绩。|
|330|[Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2204.05862)|我们将偏好建模和基于人类反馈的强化学习（RLHF）应用于微调语言模型，使其成为有益且无害的助手。我们发现，这种对齐训练几乎提高了所有NLP评估的性能，并且完全兼容于像Python编程和摘要等专业技能的训练。我们探索了一种迭代在线训练模式，其中偏好模型和RL策略每周根据新鲜的人类反馈数据进行更新，有效提升了我们的数据集和模型。最后，我们研究了RLHF训练的鲁棒性，并发现了RL奖励与策略与其初始化之间的KL散度平方根之间存在大致线性关系。除了主要结果外，我们还对校准、竞争目标以及OOD检测的使用进行了周边分析，将我们的模型与人类写手进行了比较，并提供了使用近期相关工作中出现的提示从我们的模型中抽取的样本。|
|331|[Gemini: A Family of Highly Capable Multimodal Models]()||
|332|[Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)|我们提出了一种新的框架，通过对抗过程来估计生成模型，在这个过程中，我们同时训练两个模型：一个生成模型G，用于捕获数据分布；一个判别模型D，用于估计样本来自训练数据而非G的概率。训练G的过程是为了最大化D犯错的概率。这个框架对应于一个极小极大化的两人博弈。在任意函数G和D的空间中，存在一个唯一解，其中G恢复训练数据分布，而D在各处都等于1/2。如果G和D由多层感知器定义，则整个系统可以通过反向传播进行训练。在训练或生成样本时，不需要任何马尔可夫链或展开的近似推理网络。实验通过生成样本的定性和定量评估展现了该框架的潜力。|
|333|[HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/abs/2303.17580)|解决涉及不同领域和模态的复杂AI任务，是迈向人工通用智能的关键步骤。尽管目前存在众多针对不同领域和模态的AI模型，它们仍无法自主处理复杂的AI任务。鉴于大型语言模型（LLMs）在语言理解、生成、交互及推理方面展现出了卓越的能力，我们主张LLMs可以充当控制器的角色，利用语言作为通用接口来管理现有的AI模型，以解决复杂的AI任务。基于这一理念，我们提出了HuggingGPT，这是一个由LLM驱动的代理，它利用如ChatGPT之类的LLMs来连接机器学习社区（如Hugging Face）中的各种AI模型，以解决AI任务。具体而言，当接收到用户请求时，HuggingGPT使用ChatGPT进行任务规划，根据Hugging Face中提供的功能描述选择合适的模型，利用所选的AI模型执行每个子任务，并根据执行结果汇总响应。通过利用ChatGPT强大的语言能力以及Hugging Face中丰富的AI模型，HuggingGPT能够应对横跨不同模态和领域的广泛复杂AI任务，并在语言、视觉、语音等挑战性任务中取得令人瞩目的成果，为实现人工通用智能开辟了新途径。|
|334|[LIMA: Less Is More for Alignment](https://arxiv.org/abs/2305.11206)|大型语言模型的训练分为两个阶段：(1) 从原始文本中进行无监督预训练，以学习通用的目的表示；(2) 大规模的指令微调和强化学习，以便更好地适应最终任务和用户偏好。为了衡量这两个阶段的相对重要性，我们训练了一个名为LIMA的650亿参数的LLaMa语言模型。LIMA仅通过标准监督损失，在精心挑选的1000个提示和响应上进行微调，期间未采用任何强化学习或人类偏好建模。LIMA展现了极为强大的性能，仅从训练数据中的少数示例中就学会了遵循特定的响应格式，包括从规划旅行行程到推测替代历史等复杂查询。此外，该模型倾向于对未出现在训练数据中的新任务也能良好泛化。在一项控制性的人类研究中，与GPT-4相比，有43%的情况下LIMA的响应要么等同要么更受青睐；与Bard相比，这一比例高达58%；与通过人类反馈训练的DaVinci003相比，更是达到了65%。综上所述，这些结果强烈表明大型语言模型中的几乎所有知识都是在预训练阶段习得的，而只需要有限的指令微调数据即可教会模型产生高质量的输出。|
|335|[BuboGPT: Enabling Visual Grounding in Multi-Modal LLMs](https://arxiv.org/abs/2307.08581)|大型语言模型（LLMs）在通过语言与人类交互方面已经展现出了惊人的能力，特别是在使用指令跟随数据的情况下。最近LLMs的进展，如MiniGPT-4、LLLaVA和X-LLM，通过整合图像、视频和语音等多模态输入，进一步扩大了它们的能力。尽管这些LLMs在生成给定模态信号的精确和详细语言理解方面非常有效，但它们放弃了对输入特定部分进行定位的能力，因此只能构建粗粒度的映射。然而，文本与其他模态之间明确而丰富的对应不仅会改善用户体验，还有助于扩展多模态LLMs的应用场景。因此，我们提出了BuboGPT，一个具备视觉定位能力的多模态LLM，能够在视觉、音频和语言之间进行跨模态交互，提供对视觉对象和其他给定模态的细粒度理解。结果是，当BuboGPT为对象生成响应或描述时，能够指出该对象在图像中的具体位置。我们的贡献主要有两点：1) 基于SAM的现成视觉定位模块，该模块提取句子中的实体并在图像中找到对应的掩码。2) 一个两阶段的训练方案和指令数据集，以赋予联合的文本-图像-音频理解能力。我们的实验显示，BuboGPT在与人类交互过程中展现出了令人印象深刻的多模态理解和视觉定位能力。无论提供的模态组合是否对齐，它都能持续表现出色。|
|336|[ChatLaw: Open-Source Legal Large Language Modelwith Integrated External Knowledge Bases](https://arxiv.org/pdf/2306.16092)|基于大型语言模型（LLMs）的AI法律助理能够提供触手可及的法律咨询服务，但幻象问题却潜藏了潜在的法律风险。本文介绍了一款创新性的法律助理Chatlaw，它运用了混合专家（Mixture-of-Experts, MoE）模型与多智能体系统来增强AI驱动的法律服务的可靠性和准确性。通过将知识图谱与人工筛选相结合，我们构建了一个高质量的法律领域数据集来训练MoE模型。这一模型利用不同的专家来应对各类法律问题，从而优化法律回复的准确性。此外，模拟真实律所工作流程制定的标准操作程序（Standardized Operating Procedures, SOP），显著减少了法律服务中的错误和幻象现象。我们的MoE模型在Lawbench和统一法律职业资格考试中的准确率超出GPT-4达7.73%，并且分别高出11分，同时在实际案例咨询中也在多个维度上超越了其他模型，充分展示了我们在法律咨询方面的强大能力。|
|337|[MiniMax幕后故事和大模型扑克牌](https://www.xiaoyuzhoufm.com/episode/66671ad194977a26ef6b8ed6)|今天的嘉宾是MiniMax天使投资人、云启资本合伙人陈昱。MiniMax是中国6家大模型创业公司中，除月之暗面之外，另一家估值比较高的独角兽企业。这集我们聊了聊MiniMax的创业、融资和团队故事。此外，最近很多投资人都去美国参加了GenAI大会，陈昱在现场聊了聊他的观察。|
|338|[那些你不知道的 AI 产品，正在海外闷声赚大钱   对谈高宁: Linkloud 联创，OnBoard! 主播](https://www.xiaoyuzhoufm.com/episode/66895b3e0bc5d7cc70488284)|这是一期播客「OnBoard!」与「十字路口」的串台节目，因为我们注意到，已经有不少出海的 AI 公司赚到了第一桶金。因此，在这期播客，我们尝试提炼和总结这些公司的共性，希望能为大家拓宽思路，带来一些灵感。\n当我们提到「闷声赚大钱」的「大钱」，并不一定指巨额财富。我们也不打算在节目中透露它们的具体收入数字，因为我们认为，赚钱本身就是一个非常积极的信号。这意味着产品找到了市场契合度（PMF），找到了愿意付费的目标用户，这也意味着飞轮开始转动起来了。我们今天主要讨论的是华人创办的 AI 公司，这些公司有的总部在中国，有的在硅谷、新加坡等地。无论他们身处何地，他们都和我们处在同一个社交圈和文化体系中，这能给我们带来最直接的启发和参考。为什么这一期内容我会想到邀请高宁来聊呢？在我眼里，高宁就是 AI 行业的活字典，是一个行走的垂直行业大模型。他的信息量巨大，几乎没有他不知道的行业新闻和八卦。高宁是播客 OnBoard! 的主播，也是他和 Monica 启发了我和 Ronghui 开始制作「十字路口」这档播客。同时，高宁也是出海社群 Linkloud（公众号：Linkloud） 的联合创始人。创业前，高宁曾在高瓴创投工作。Linkloud 是目前中国 AI 出海最有分量的社群之一。高宁每个季度都会带领几十位 AI 领域的创始人和高管前往硅谷与日本进行游学参访，长期观察中国 AI 出海，是中美两国科技界和企业界进行 AI 交流的重要桥梁。|
|339|[Ilya Sutskever 塑造世界的AI科学家](https://www.bilibili.com/video/BV14b4y1u7o3/)|Ilya Sutskever，作为ChatGPT背后的主要人工智能科学家之一，回顾了他的创始愿景和价值观。在2016年至2019年期间，当他参与开发聊天语言模型时，与电影制作人Tonje Hessen Schei的对话中，他阐述了自己的个人哲学，并对这项已经在塑造我们世界的科技做出了惊人的预测。在当前全球就安全与监管问题进行辩论的背景下，反思他的理念，我们既考虑到了人工智能技术带来的机遇，也考虑到了其可能产生的后果。Ilya讨论了他最终目标——人工通用智能（AGI），即“一个能在任何工作或任务上媲美甚至超越人类的计算机系统”，并质疑AGI的军备竞赛对人类而言是好是坏。|
|340|[Sora首部剧情短片《Air Head》（气球脑袋）](https://www.bilibili.com/video/BV1nH4y1H7MB/)|OpenAI邀请导演和艺术家创作的【Sora初印象】短片系列的《气球脑袋》|
|341|[TensorFlow](https://www.tensorflow.org/)|一个面向所有人的端到端开源机器学习平台。探索TensorFlow灵活的生态系统，包括工具、库和社区资源。|
